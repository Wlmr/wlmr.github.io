<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-04-26T20:15:09+02:00</updated><id>http://localhost:4000/</id><title type="html">wlmr</title><subtitle>This is where I will keep useful info and share my opinions.</subtitle><entry><title type="html">Concurrency</title><link href="http://localhost:4000/2019/04/18/Realtidsprogrammering.html" rel="alternate" type="text/html" title="Concurrency" /><published>2019-04-18T00:00:00+02:00</published><updated>2019-04-18T00:00:00+02:00</updated><id>http://localhost:4000/2019/04/18/Realtidsprogrammering</id><content type="html" xml:base="http://localhost:4000/2019/04/18/Realtidsprogrammering.html">&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML&quot; async=&quot;&quot;&gt;&lt;/script&gt;

&lt;p&gt;Welcome to my lexicon on the concurrent programming lingo. It covers all you need to know for the course on the subject at Lund University, Sweden.&lt;/p&gt;

&lt;h3 id=&quot;general&quot;&gt;General&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;busy-wait&lt;/strong&gt; – when a thread over and over again checks if some boolean has changed and it can continue. This is extremely inefficient in comparison to a system where a thread is signaled when something has changed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;race condition&lt;/strong&gt; – occurs when critical sections are not locked. Several threads can then access the data at the same time. The result is then undefined as it depends on which thread entered when.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dead lock&lt;/strong&gt; – two or more threads, with resources locked, are waiting for other locks to be freed while the wanted lock is locked by another thread that wants the lock that the former threads are in control of. To obtain deadlocks &lt;strong&gt;4&lt;/strong&gt; conditions must be met:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;mutual exclusion – only one thread is allowed at a time.&lt;/li&gt;
  &lt;li&gt;hold and wait – entering a monitor from another monitor.&lt;/li&gt;
  &lt;li&gt;no resource preemption – threads can only exit voluntarily by &lt;strong&gt;wait()&lt;/strong&gt;, otherwise it can get stuck.&lt;/li&gt;
  &lt;li&gt;circular wait – if there are two or more threads that at some point is waiting for one another.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;starvation&lt;/strong&gt; – occurs if a thread is continously denied the resource it tries to access.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;live lock&lt;/strong&gt; – when two or more threads tries to access the same resource&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;priorites&lt;/strong&gt; – correctness of a program should never depend on priorites since these may not be obeyed on all platforms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;semphore&lt;/strong&gt; – way for thread to lock the door after itself after entering a critical section to guarantee exclusivity.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;counting semaphore – has a counter that increments when give is called and decrements when take is called.&lt;/li&gt;
  &lt;li&gt;multistep semaphore – counter that permits incrementations with more than one.&lt;/li&gt;
  &lt;li&gt;binary / mutex semaphore – guarantees mutual exclusion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;context switch&lt;/strong&gt; – when the system changes running thread/process the preemptied thread needs to stash its data away for later. Steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;SAVE&lt;/em&gt;
    &lt;ol&gt;
      &lt;li&gt;Turn off interrupts,&lt;/li&gt;
      &lt;li&gt;push PC, registers on stack,&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;SWITCH&lt;/em&gt;
    &lt;ol&gt;
      &lt;li&gt;save stack pointer in process record,&lt;/li&gt;
      &lt;li&gt;get new process record and restore stack pointer from it,&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;RESTORE&lt;/em&gt;
    &lt;ol&gt;
      &lt;li&gt;pop registers, PC from stack,&lt;/li&gt;
      &lt;li&gt;turn on interrupts.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scheduling&quot;&gt;Scheduling&lt;/h3&gt;

&lt;p&gt;The main goal of scheduling is to get a concurrent program that is also correct in terms of timing.&lt;/p&gt;

&lt;p&gt;In order to be able to analyze a program several simplifications must be made. E.g.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;threads must not depend on each other. I.e there can be no &lt;a href=&quot;#concurrency-in-java&quot;&gt;&lt;strong&gt;wait()&lt;/strong&gt; or &lt;strong&gt;notify()&lt;/strong&gt;&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;there must be a fixed number of threads,&lt;/li&gt;
  &lt;li&gt;all threads are periodic with known periods,&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;cyclic executive scheduling&lt;/strong&gt;
consists of:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Major cycle length&lt;/strong&gt; the period it takes until all threads to have been in business at least once. &lt;em&gt;least common multiple&lt;/em&gt; of the periods of all the threads will guarantee that we get the shortest possible major cycle length, and hence the most effective major cycle length.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Minor cycle length&lt;/strong&gt; should be &lt;em&gt;greatest common divisor&lt;/em&gt; of the periods of all the threads as this leads to the longest minor cycle possible.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Schedulable?&lt;/strong&gt; – simply try to fit all execution times within the corresponding threads period. Dividing and distributing an execution time is perfectly fine if left with no other option.&lt;/li&gt;
      &lt;li&gt;Doesn’t need a scheduler as it will just follow a fixed schedule calculated beforehand.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;WCET&lt;/strong&gt; – worst-case execution time
&lt;strong&gt;C&lt;/strong&gt; – execution time (WCET)
&lt;strong&gt;R&lt;/strong&gt; – worst-case response time, i.e. when control and execution is completed
&lt;strong&gt;T&lt;/strong&gt; – period
&lt;strong&gt;U&lt;/strong&gt; – C/T – CPU utilization&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rate Monotonic Scheduling–RMS&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;short period &amp;lt;-&amp;gt; high priority&lt;/li&gt;
  &lt;li&gt;can guarantee schedulability if sum of C/T for all n threads is below &lt;script type=&quot;math/tex&quot;&gt;n(2^{1/n} - 1)&lt;/script&gt;. N.B It might still be schedulable if above this bound.&lt;/li&gt;
  &lt;li&gt;as soon as there are threads ready to carry out their threads the one with the highest priority will. Even if a lower priority thread is being executed a higher-priority one will always force it to a halt by preemption as soon as it is ready.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fixed-priority scheduling&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Earliest Deadline First–EDF&lt;/strong&gt; – Highest priority is given to the thread that is closest to its deadline, this is checked every time a new thread is released.&lt;/p&gt;

&lt;h3 id=&quot;priority-inversion&quot;&gt;Priority inversion&lt;/h3&gt;

&lt;p&gt;Scenario: low priority thread: &lt;em&gt;L&lt;/em&gt;, mid prio thread: &lt;em&gt;M&lt;/em&gt;, high prio thread: &lt;em&gt;H&lt;/em&gt;, shared resource R.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;L&lt;/em&gt; enters R,&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;L&lt;/em&gt; is preempted by &lt;em&gt;M&lt;/em&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;M&lt;/em&gt; is preempted by &lt;em&gt;H&lt;/em&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;H&lt;/em&gt; tries to enter R but is locked out,&lt;/li&gt;
  &lt;li&gt;Since &lt;em&gt;H&lt;/em&gt; has nothing to do &lt;em&gt;M&lt;/em&gt; continues its execution,&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;H&lt;/em&gt; (and &lt;em&gt;L&lt;/em&gt;) has to wait until &lt;em&gt;M&lt;/em&gt; finishes. N.B. &lt;em&gt;H&lt;/em&gt; is blocked by lower prio thread (since &lt;em&gt;M&lt;/em&gt; is blocking &lt;em&gt;L&lt;/em&gt; which needs to release R in order for &lt;em&gt;H&lt;/em&gt; to continue.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To counter priority inversion the concept of priority inheritance is used.&lt;/p&gt;

&lt;h3 id=&quot;basic-priority-inheritance&quot;&gt;Basic priority inheritance&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;L&lt;/em&gt; holding a resource will temporarily be raised to the priority of the higher-priority thread requesting the resource.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;WCET&lt;/strong&gt; of &lt;em&gt;H&lt;/em&gt; = worst-case time to execute code in thread + for each used resource: maximum blocking time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transitive priority inheritance&lt;/strong&gt; can occur only in presence of nested critical sections. If &lt;em&gt;A&lt;/em&gt; is blocked by &lt;em&gt;C&lt;/em&gt; which in turn is blocked by &lt;em&gt;D&lt;/em&gt; it is necessary for &lt;em&gt;D&lt;/em&gt; to inherit &lt;em&gt;A&lt;/em&gt;’s priority. If not &lt;em&gt;D&lt;/em&gt; will be preempted by &lt;em&gt;B&lt;/em&gt; and forced to wait around for &lt;em&gt;B&lt;/em&gt; to finish.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;B_i = \sum_{k=1}^K usage(k,i)C(k)&lt;/script&gt; where usage(k,i) returns 1 if semaphore is used by at least one thread with a priority less than &lt;script type=&quot;math/tex&quot;&gt;T_i&lt;/script&gt; and at least one thread with a priority higher than or equal to the priority of &lt;script type=&quot;math/tex&quot;&gt;T_i&lt;/script&gt;. Otherwise it returns 0.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;priority-ceiling-protocol&quot;&gt;Priority-ceiling protocol&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Direct blocking&lt;/strong&gt; occurs when a &lt;em&gt;H&lt;/em&gt; thread is blocked from accessing a resource due to it being held by a &lt;em&gt;L&lt;/em&gt; thread. Direct blocking is necessary for mutual exclusion and is able to occur in any preemptive-scheduler protocol.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For every semaphore a thread is involved with only one of the lower-priority threads can be blocking within one critical region protected by one semaphore. for every semaphore.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Push through blocking&lt;/strong&gt; is a consequence of the priority inheritance protocol. The time that the thread could’ve been active but instead was preempted by lower-priority thread due to a temporarily raised priority.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Occurs when &lt;em&gt;M&lt;/em&gt;’s thread cannot run due to &lt;em&gt;L&lt;/em&gt;’s thread that has inherited a higher priority.&lt;/li&gt;
  &lt;li&gt;Can affect threads that has absolutely nothing to do with any shared resources.&lt;/li&gt;
  &lt;li&gt;A semaphore can induce push-through blocking for thread &lt;em&gt;M&lt;/em&gt; if it is accessed both by a thread with lower priority and a thread with higher priority. &lt;em&gt;M&lt;/em&gt; doesn’t have to have anything to do with the semaphore in question.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;resource-allocation-graphs&quot;&gt;Resource allocation graphs&lt;/h2&gt;
&lt;p&gt;The four components of a graph:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;thread vertex - one possible state for a specific thread. drawn using a circle with the thread name inside.&lt;/li&gt;
  &lt;li&gt;resource vertex - monitor or semaphore of some sort. Drawn using a square with the resource name inside.&lt;/li&gt;
  &lt;li&gt;assignment edge - directed edge from a resource to a thread means that the thread has locked that resource.&lt;/li&gt;
  &lt;li&gt;request edge - directed edge from a thread to a resource means that the thread wants to lock that resource.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If a thread tries locking many semaphores from inside each other, several vertices of this thread must be instanciated in the graph. Deadlock can occur if the graph contains cycles of edges that all are directed in the same direction, i.e.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DEADLOCK:&lt;/strong&gt; R1 -&amp;gt; A -&amp;gt; R2 -&amp;gt; B -&amp;gt; R1&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NOT DEADLOCK:&lt;/strong&gt; R1 -&amp;gt; A &amp;lt;- R2 -&amp;gt; B -&amp;gt; R1&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;concurrency-in-java&quot;&gt;concurrency in java&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;rule of thumb: syncronized&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;do not mix threads and monitors,&lt;/li&gt;
  &lt;li&gt;all public methods in monitor should be syncronized,&lt;/li&gt;
  &lt;li&gt;write a wrapper monitor if a class needs to be thread-safe,&lt;/li&gt;
  &lt;li&gt;do not use syncronized blocks.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;keywords&quot;&gt;keywords&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;volatile&lt;/strong&gt; guarantees that the variable that is declared volatile always is read from main memory, instead of being put in some CPU cache. This way every thread reads the same value, i.e. the one in main memory. Atomicity is ensured. N.B. without &lt;strong&gt;volatile&lt;/strong&gt; only reads and writes to reference variables and primitives (except long and double) are atomic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;syncronized&lt;/strong&gt; only allows for one thread at a time to gain access to the method which has been declared syncronized. As a matter of fact any other thread trying to access any of the synchronized methods in the class would be blocked. Can also be placed as a block of code inside a method. A syncronized method has &lt;strong&gt;three&lt;/strong&gt; compartments for the threads:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;exclusive area, where only one thread can be simultaneously.&lt;/li&gt;
  &lt;li&gt;monitor queue, where threads wait for the one in the exclusive area to finish or call &lt;strong&gt;wait()&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;condition queue, where threads that have called &lt;strong&gt;wait()&lt;/strong&gt; are put, usually waiting for a condition to be met.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;wait()&lt;/strong&gt; makes the thread executing within the monitor to step out of the exclusive area and into the condition queue, allowing for another thread to try its luck. &lt;strong&gt;wait()&lt;/strong&gt; should always be placed inside a while(someBool).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;wait(long timeout)&lt;/strong&gt; and &lt;strong&gt;wait(long timeout, int nanos)&lt;/strong&gt; for waiting x number of milliseconds and x number of nanoseconds respectively. These should be used with care, however, as &lt;strong&gt;notify()&lt;/strong&gt; from some obscure subclass can interfere. To avoid mentioned &lt;strong&gt;notify()&lt;/strong&gt; one can implement the while-loop as follows.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;synchronized monitorSleep(longtimeout) throws InterruptedException {
    long tf = System.currentTimeMillis()+timeout;
    while((timeout=tf-System.currentTimeMillis())&amp;gt;0) wait(timeout);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;notify()&lt;/strong&gt; will cause a thread in the condition queue to retry its condition. If this condition returns true the thread is moved to the monitor queue. Which thread is notified isn’t clear since java doesn’t do the scheduling, hence the following method should be used in its stead.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notifyAll()&lt;/strong&gt; does the same as &lt;strong&gt;notify()&lt;/strong&gt; but for every thread in the condition queue. &lt;strong&gt;USE THIS INSTEAD OF notify()&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;javalangthread&quot;&gt;java.lang.Thread&lt;/h3&gt;

&lt;p&gt;Using threads in java requires java.lang.Thread package. Threads are started using method start. A thread must have a runnable object (an object that implements the interface java.lang.Runnable). However, extending thread will take care of this since Thread already implements Runnable&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interrupt()&lt;/strong&gt; – changes a state in the thread that can be checked and reset with &lt;strong&gt;interrupted()&lt;/strong&gt;. All threads that need to be able to be killed must actively check the &lt;strong&gt;interrupted()&lt;/strong&gt;. E.g.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public void run() {
    while(!interrupted()) { 
        ...
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;sleep(long millis)&lt;/strong&gt; – makes the thread wait for x number of milliseconds. Telling the OS that it is OK to swap currentThread. Sleeps the currentThread no matter which thread you call sleep with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isAlive()&lt;/strong&gt; – false if the thread has terminated or not been started. True if it is active at time of check. If &lt;strong&gt;isAlive()&lt;/strong&gt; returns false right after a call to &lt;strong&gt;start()&lt;/strong&gt; the thread must have terminated. If it returns true on the other hand it means the thread cannot have been started before.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;join()&lt;/strong&gt; – waits for the thread to return false from &lt;strong&gt;isAlive()&lt;/strong&gt; before continuing.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Kompilatorer</title><link href="http://localhost:4000/2018/10/28/Kompilatorer.html" rel="alternate" type="text/html" title="Kompilatorer" /><published>2018-10-28T00:00:00+02:00</published><updated>2018-10-28T00:00:00+02:00</updated><id>http://localhost:4000/2018/10/28/Kompilatorer</id><content type="html" xml:base="http://localhost:4000/2018/10/28/Kompilatorer.html">&lt;h1 id=&quot;the-canonical-compiler&quot;&gt;the canonical compiler&lt;/h1&gt;

&lt;p&gt;In this post I will try to summarize the structure of a typical compiler. A compiler is a program that transforms high level source code into assembly code. Assembly code is the closest thing we have to binary that is still made up of text. Hence before the compiler all code was written in assembly code. To get a feel of how slow it is to write assembly code here’s an example showing how to print a string to stdout:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.global _start
.data
message: .ascii &quot;printing this is all the code does!\n&quot;
.text
_start:
movq $1, %rdi       # stdout file descriptor
movq $message, %rsi # message to print
movq $14, %rdx      # message length
movq $1, %rax       # sys_write
syscall
movq $0, %rdi       # exit code = 0
movq $60, %rax      # sys_exit
syscall
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The compiler is built up of well defined components, each one piping its output to the next module. As a structure for this post I will start with the first module and move through the compiler, finishing of with assembly code generation.&lt;/p&gt;

&lt;h2 id=&quot;the-different-modules&quot;&gt;The different modules&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;lexical analysis/scanning&lt;/li&gt;
  &lt;li&gt;syntactical analysis/parsing&lt;/li&gt;
  &lt;li&gt;semantical analysis&lt;/li&gt;
  &lt;li&gt;intermediate code generation&lt;/li&gt;
  &lt;li&gt;optimization&lt;/li&gt;
  &lt;li&gt;taget code generation&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;lexical-analysis--scanning&quot;&gt;lexical analysis / scanning&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This is the first stage and therefore the one that uses the source code as input. In the scanning stage the code is transformed into defined tokens. This can be done using regular expression. A integer could perhaps be defined by the regular expression: INTEGER = 0&lt;/td&gt;
      &lt;td&gt;[1-9][0-9]*. Saying that the number is either a 0 or a 1,2,3,4,5,6,7,8 or 9 followed by zero or more arbitrary ints.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Without introducing two rules this system could however lead to some ambiguities. E.g. what should be matched if the scanner finds the string “iffff”? Should it send back and IF-token or an ID? Introducing: &lt;strong&gt;longest match&lt;/strong&gt; and &lt;strong&gt;rule priority&lt;/strong&gt;. These are straightforward self-explanatory.&lt;/p&gt;

&lt;h4 id=&quot;errors&quot;&gt;errors&lt;/h4&gt;

&lt;p&gt;Errors in the code found in this stage are apropriatly refered to as lexical errors. These include all text that cannot be interpreted. E.g. “¤” in the code below:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int \¤ useless(int x){
    return x;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If no errors are found this module will output a bunch of token and feed them into the next module.&lt;/p&gt;

&lt;h3 id=&quot;syntactical-analysis--parsing&quot;&gt;syntactical analysis / parsing&lt;/h3&gt;

&lt;p&gt;In this section the tokens are transformed into an abstract syntax tree or AST for short.&lt;/p&gt;

&lt;p&gt;To create this tree we make use of Context-Free Grammars.&lt;/p&gt;

&lt;h4 id=&quot;cfg&quot;&gt;CFG&lt;/h4&gt;

&lt;p&gt;The Context-Free Grammar is a formal system made up of production rules, nonterminal symbols – one of them being the start symbol – and terminal symbols. Using this the parser recursively goes through the tokens. It usually looks something like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Exp -&amp;gt; Exp &quot;*&quot; Exp
Exp -&amp;gt; Exp &quot;+&quot; Exp
Exp -&amp;gt; INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using this notation in practice is as beautiful as it is powerful. This CFG is written in canonical form. There is also BNF – Backus-Naur Form – and EBNF – Extended Backus-Naur Form. In BNF the “|” operator is permitted, allowing for several productions to be place on one line:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Exp -&amp;gt; Exp &quot;*&quot; Exp | Exp &quot;+&quot; Exp | INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;EBNF Goes even further and introduces *, +, [] and ().
The “*” is called the Kleene-star and has the same meaning as in a regex, i.e. “zero or more” – i.e. a list. Also + is brought from the regex world. The [] creates an optional of whatever is inside the brackets.&lt;/p&gt;

&lt;h5 id=&quot;translation&quot;&gt;translation&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;repetition: 
  X -&amp;gt; AB*C
  becomes
  X -&amp;gt; ADC
  D -&amp;gt; CD
  D -&amp;gt; γ&lt;/li&gt;
  &lt;li&gt;alternative:
  X -&amp;gt; A(…)C
  becomes
  X -&amp;gt; ADC
  D -&amp;gt; (…)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;example&quot;&gt;example&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Program -&amp;gt; Func*
Func    -&amp;gt; Type IdDecl IdDecl* Block
Block   -&amp;gt; Stmt*;
Stmt    -&amp;gt; Decl | Assi | CallStmt | While | If | Else | Ret

...

Else    -&amp;gt; Block
Ret     -&amp;gt; Expr

...

Expr    -&amp;gt; Call | Binexpr | IdUse | IdDecl | Num

...

Type    -&amp;gt; BoolType | IntType

...

IdUse   -&amp;gt; &amp;lt;ID&amp;gt;
IdDecl  -&amp;gt; &amp;lt;ID&amp;gt;
Num     -&amp;gt; &amp;lt;Num&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The CFG works by swapping the left hand side for the right hand side. An example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int inc(int v1){
    return v1+1;
}

int div(int n, int d){
    return n/d;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The root of the AST would be a PROGRAM node as this is the start symbol. The root node can have zero or more Funcs. In this case the PROGAM has two Funcs so these become the first leaves. From the first Func grows four new branches. Type becomes an IntType, IdDecl becomes and ID as “inc” doesnt correspond to any of the other tokens in the scanner. The second IdDecl corresponds to the function arguments. This grows to a new leaf of ID. The Block will in a similar way grow further and further until only &lt;strong&gt;terminals&lt;/strong&gt; remain.&lt;/p&gt;

&lt;h4 id=&quot;ambiguities&quot;&gt;ambiguities&lt;/h4&gt;

&lt;p&gt;If it is possible to derive two different parse trees from the one sentence the CFG is ambiguous. How can we get rid of ambiguities and make the process deterministic? First of all we have to decide if we want an &lt;strong&gt;LL&lt;/strong&gt;- or an &lt;strong&gt;LR-parser&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;philosophy&quot;&gt;philosophy&lt;/h4&gt;

&lt;p&gt;If you think about it you quickly realize that nothing cool in our world is designed top-down. The human brain doesn’t consist of a conscience ruling over the rest of the brain. No, our conscienceness is merely another part of the brain. There is no ship bridge issuing commands. The brain is simply a massive net of neurons. The neuron has no intelligence on its own, it can only respond to stimuli by firing electrical impulses. It is together in great numbers that meaning and complex behaviour starts to erupt. Not only the brain – every part of man works this way – we are in fact no more than a collection of cells and bacteria. It was when AI begun to be modelled bottom-up that the area became something to be proud of. It is why communism – top-down – failed and it is why capitalism – bottom-up – works. This is why cryptocurrencies, and decentralized systems are so cool. Top-down never occurs in nature and is very limited. Have this in mind when you learn about LL-parsing and LR-parsing.&lt;/p&gt;

&lt;h4 id=&quot;ll&quot;&gt;LL&lt;/h4&gt;

&lt;p&gt;The __L__eft to right __L__eftmost derivation-parser builds the tree top-down. The parser is also defined by how many lookahead tokens it incorporates. An LL(1) has only one lookahead. The number of lookaheads define how many tokens ahead the parser should look at before using a production rule. When designing a LL(1)-grammar there are two pitfalls to look out for namely left-recursion and common prefix. We will return to these in the construction section.&lt;/p&gt;

&lt;h5 id=&quot;construction&quot;&gt;construction&lt;/h5&gt;

&lt;p&gt;When constructing a LL(1)-parser we follow the following algorithm:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;write the grammar on canonical form&lt;/li&gt;
  &lt;li&gt;compute Nullable, FIRST and FOLLOW&lt;/li&gt;
  &lt;li&gt;construct a LL-table using the results from the previous step&lt;/li&gt;
  &lt;li&gt;if no conflicts occur the grammar is LL(1) and can be implemented using a recursive decent.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The nonsense you were told to compute in step two turns out to be vital to the construction and is described below.&lt;/p&gt;

&lt;p&gt;For each production p: X -&amp;gt; γ we want to check the following.
&lt;strong&gt;First(γ)&lt;/strong&gt; – the set of tokens that occur first in a sentence derived from γ.
&lt;strong&gt;Nullable(γ)&lt;/strong&gt; – is a function that tells you if it is possible to derive ε from γ.
&lt;strong&gt;FOLLOW(X)&lt;/strong&gt; – the set of tokens that occur directly after an X-sentence.&lt;/p&gt;

&lt;p&gt;The table should have a column for every possible terminal and a row for every nonterminal. E.g.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p_0: Stmt -&amp;gt; Expr
p_1: Expr -&amp;gt; Expr &quot;*&quot; Expr
p_2: Expr -&amp;gt; Expr &quot;+&quot; Expr
p_5: Expr -&amp;gt; ID
p_6: Expr -&amp;gt; INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;LL-table&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ID&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;”+”&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;”*”&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;INT&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;stmt&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;p_0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;p_0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;expr&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;p_1,p_2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;p_1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We don’t have to continue further than to expr as we already have collisions in the table. The collision is caused by the previously mentioned common prefix and left-recursion problems.&lt;/p&gt;

&lt;h5 id=&quot;solving-left-recursion&quot;&gt;solving left recursion&lt;/h5&gt;

&lt;p&gt;As the LL-parser moves through the source code from left to right, substituting as soon as it finds a suitable match it can get stuck in endless recursion, substituting a nonterminal for itself. E.g.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p_0: Stmt -&amp;gt; Expr
p_1: Expr -&amp;gt; Expr &quot;*&quot; Expr
p_2: Expr -&amp;gt; Expr &quot;+&quot; Expr
p_5: Expr -&amp;gt; ID
p_6: Expr -&amp;gt; INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In p_1: Expr -&amp;gt; Expr “*” Expr -&amp;gt; (((Expr “*” Expr) “*” Expr) “*” Expr) “*” Expr -&amp;gt; …&lt;/p&gt;

&lt;p&gt;As an LL-parser always choses the leftmost substitution it can end up deep in the depths of recursion.&lt;/p&gt;

&lt;p&gt;To get rid of this endless recursion we rewrite the rules by creating the nonterminals Term and Factor. This way, Expr can’t be substituted into itself. The rule here is to avoid productions of the type X -&amp;gt; Xab. By introducing new variables this procedure becomes quite simple. This design is, however, still not working as we still have to deal with the problem of common prefix.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p_0: Stmt -&amp;gt; Expr
p_1: Expr -&amp;gt; Term &quot;+&quot; Expr
p_2: Term -&amp;gt; Factor &quot;*&quot; Term
p_3: Term -&amp;gt; Factor
p_4: Factor -&amp;gt; ID
p_5: Factor -&amp;gt; INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;solving-common-prefix&quot;&gt;solving common prefix&lt;/h5&gt;

&lt;p&gt;Common prefix occurs when two or more productions of the same nonterminal starts with the same symbol. LL(1) cannot handle this, LL(2) can handle if the only first token is the same, LL(3) can handle if the two first tokens are the same, etc. In our grammar rule p_2 &amp;amp; p_3 contains a common prefix. By concatenating the two rules and introducing “Factors” as either being ε or ‘”*” Term’ we solve this.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p_0: Stmt -&amp;gt; Expr
p_1: Expr -&amp;gt; Term Terms
p_2: Terms -&amp;gt; &quot;+&quot; Expr
p_3: Terms -&amp;gt; ε
p_4: Term -&amp;gt; Factor Factors
p_5: Factors -&amp;gt; &quot;*&quot; Term
p_6: Factors -&amp;gt; ε
p_7: Factor -&amp;gt; ID
p_8: Factor -&amp;gt; INT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ladies and gentlemen, I present to you a grammatically correct LL(1)-grammar.&lt;/p&gt;

&lt;h4 id=&quot;lr&quot;&gt;LR&lt;/h4&gt;

&lt;p&gt;Moving on the the cool stuff. LR builds the tree from the bottom.&lt;/p&gt;

&lt;p&gt;By splitting the compiler into different parts only a little bit of it has to be changed to compile to another machine (&lt;strong&gt;Frame Layout&lt;/strong&gt; and &lt;strong&gt;Instruction Selection modules&lt;/strong&gt;). To change source code language only the modules up to &lt;strong&gt;Translate&lt;/strong&gt; needs to be altered.&lt;/p&gt;

&lt;h3 id=&quot;different-stages&quot;&gt;Different stages:&lt;/h3&gt;

&lt;p&gt;front end&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lexical analysis – Breaking the source code down into tokens&lt;/li&gt;
  &lt;li&gt;Syntactic analysis – Analyze the phrase structure of the program. Building an AST out of the different tokens.&lt;/li&gt;
  &lt;li&gt;Semantic analysis – Checking types and names, to make sure all variable usages has been declared, and also assigns values to the&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;mid&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Frame Layout&lt;/li&gt;
  &lt;li&gt;Translate&lt;/li&gt;
  &lt;li&gt;Cononicalize&lt;/li&gt;
  &lt;li&gt;Instruction Selection&lt;/li&gt;
  &lt;li&gt;Control Flow Analysis&lt;/li&gt;
  &lt;li&gt;Dataflow Analysis&lt;/li&gt;
  &lt;li&gt;Register Allocation&lt;/li&gt;
  &lt;li&gt;Code Emission&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;front-end&quot;&gt;Front end&lt;/h3&gt;

&lt;p&gt;independent of code language (can be reused for different languages)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lexical analyzer (scanning)&lt;/strong&gt; – read the high level code and form different &lt;strong&gt;tokens&lt;/strong&gt;. SOURCE CODE TEXT -&amp;gt; TOKENS&lt;/p&gt;

&lt;p&gt;Example of different tokens matched with regex&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;IF      - if&lt;/li&gt;
  &lt;li&gt;THEN    - then&lt;/li&gt;
  &lt;li&gt;FOR     - for&lt;/li&gt;
  &lt;li&gt;ID      - \w+&lt;/li&gt;
  &lt;li&gt;INT     - [1-9]&lt;/li&gt;
  &lt;li&gt;FLOAT   - [1-9]*[0-9]+ .[0-9]+&lt;/li&gt;
  &lt;li&gt;STRING  - “[a-zA-Z]”&lt;/li&gt;
  &lt;li&gt;CHAR    - [a-zA-Z]&lt;/li&gt;
  &lt;li&gt;PLUS    - +&lt;/li&gt;
  &lt;li&gt;INCR    - ++&lt;/li&gt;
  &lt;li&gt;NE      - !=&lt;/li&gt;
  &lt;li&gt;SEMI    - ;&lt;/li&gt;
  &lt;li&gt;COMMA   - ,&lt;/li&gt;
  &lt;li&gt;LPAREN  - (&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tokens can also be matched using FSM - finite state machines or FA – finite automata – as they are refered to in the textbook.
The finite automaton used must however be deterministic, i.e. one input answers to one edge and one edge only.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rules for lexer:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;longest match – so that the lexer doesnt generate four ID/variable tokens of the word “word”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Regex to DFA:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Syntactic analyzer (parsing)&lt;/strong&gt; – form a tree of all the &lt;strong&gt;tokens&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Semantic analyzer&lt;/strong&gt; – make sure all methods have correct number of parameters and so on. This generates an attrubuted tree.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;intermidiate code generator&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;back-end&quot;&gt;Back end&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Machine code generation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;source prog -&amp;gt; compiler -&amp;gt; assembly program -&amp;gt; assembler -&amp;gt; object program + library -&amp;gt; linker -&amp;gt; executable code&lt;/p&gt;

&lt;p&gt;stack – used i c-languages&lt;/p&gt;

&lt;p&gt;heap –&lt;/p&gt;

&lt;h2 id=&quot;java&quot;&gt;java&lt;/h2&gt;

&lt;p&gt;A.java -&amp;gt; javac -&amp;gt; A.class&lt;/p&gt;

&lt;p&gt;.class-files can be run in the java virtual machine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;jvm&lt;/strong&gt; – written i c++&lt;/p&gt;

&lt;h3 id=&quot;180910&quot;&gt;180910&lt;/h3&gt;

&lt;p&gt;NFA – nondeterministic finite automata&lt;/p&gt;

&lt;p&gt;Regex Vs. context-free grammar – With CFG recursion is simple to describe.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CFG example:&lt;/strong&gt;
P =&lt;/p&gt;

&lt;p&gt;###180911&lt;/p&gt;

&lt;h4 id=&quot;ambiguities-1&quot;&gt;ambiguities&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;bin expressions&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;priorities – by creating new non
      change:
      E -&amp;gt; E “+” E
      E -&amp;gt; E “&lt;em&gt;” E
      E -&amp;gt; INT | “(“ E “)”
      to:
      E -&amp;gt; E “+” T
      E -&amp;gt; T
      T -&amp;gt; T “&lt;/em&gt;” F
      T -&amp;gt; F
      F -&amp;gt; INT
      F -&amp;gt; “(“ E “)”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;associativity&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;transforming-to-equivalent-grammar&quot;&gt;Transforming to equivalent grammar&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;canonical form
      Expr -&amp;gt; Expr “+” Term
      Expr -&amp;gt; Term
      Term -&amp;gt; Term “*” Factor
      Term -&amp;gt; Factor
      Factor -&amp;gt; INT
      Factor -&amp;gt; “(“ Expr “)”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;BNF
      Expr -&amp;gt; Expr “+” Ter    Expr -&amp;gt; Expr “+” Term&lt;/li&gt;
  &lt;li&gt;EBNF&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ll-parsing&quot;&gt;LL-parsing&lt;/h4&gt;
&lt;p&gt;a.k.a:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Leftmost-derivation&lt;/li&gt;
  &lt;li&gt;Top down&lt;/li&gt;
  &lt;li&gt;Recursive-descent&lt;/li&gt;
  &lt;li&gt;Predictive parsing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;LL-problems&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;common prefix – when several productions of the same nonterminal&lt;/li&gt;
  &lt;li&gt;left recursion –&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name></name></author><summary type="html">the canonical compiler</summary></entry><entry><title type="html">Digitalteknik</title><link href="http://localhost:4000/2018/09/03/Digitalteknik.html" rel="alternate" type="text/html" title="Digitalteknik" /><published>2018-09-03T00:00:00+02:00</published><updated>2018-09-03T00:00:00+02:00</updated><id>http://localhost:4000/2018/09/03/Digitalteknik</id><content type="html" xml:base="http://localhost:4000/2018/09/03/Digitalteknik.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;2018-09-03-Digitalteknik&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h2 id=&quot;fsm-a.k.a.-flying-spaghetti-monster-or-finite-state-machine&quot;&gt;fsm a.k.a. flying spaghetti monster or finite state machine&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;finite state graph&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the states are circles called vertices&lt;/li&gt;
&lt;li&gt;the transitions are arrows called edges&lt;/li&gt;
&lt;li&gt;one edge for each input&lt;/li&gt;
&lt;li&gt;one output combination for each input&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;switchfunktion&lt;/strong&gt; – function of binary input signals with binary output signal. The function must be able to be specified in a table.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sekvenskrets&lt;/strong&gt; – realization of wanted behaviour with binary inputs and binary output where the realization must contain some kind of memory element. Behaviour is specified in a state transition graph. The graph together with specified behaviour is called a finite state machine or automata.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set of states S&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;a start state&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set of inputs Ι&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set of outputs Ζ&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;output function λ(s,i)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;next state function δ(s,i)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;KLOCKSTYRD&lt;/strong&gt; – will update every second wether or not the state has changed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HÄNDELSESTYRD&lt;/strong&gt; – will update every time unit as long as there is input to be processed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;trellis&lt;/strong&gt; – google a picture&lt;/p&gt;
&lt;h2 id=&quot;sequential-circuits&quot;&gt;Sequential Circuits&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;boolean function&lt;/strong&gt; – mapping from n binary inputs to one binary output&lt;/p&gt;
&lt;h2 id=&quot;algebraic-structures&quot;&gt;Algebraic structures&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Euclid’s algorithm&lt;/strong&gt; – how to find the remainder \( R_d(n) = n \% d \).&lt;/p&gt;
&lt;p&gt;rewrite \( n / d \) as &lt;span class=&quot;math display&quot;&gt;\[ n = qd + r , \quad 0 \leq r &amp;lt; d\]&lt;/span&gt; where \( q \) is the quotient, \( r \) the reminder and \(d\) the divisor.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;divide \(n\) with \(d\)&lt;/li&gt;
&lt;li&gt;\( floor(n/d) \) is the integer part of the result&lt;/li&gt;
&lt;li&gt;\( n - floor(n/d) = r \)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;if \( R_d(n) = 0 \) then \( n | d \)&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">2018-09-03-Digitalteknik fsm a.k.a. flying spaghetti monster or finite state machine finite state graph the states are circles called vertices the transitions are arrows called edges one edge for each input one output combination for each input switchfunktion – function of binary input signals with binary output signal. The function must be able to be specified in a table. sekvenskrets – realization of wanted behaviour with binary inputs and binary output where the realization must contain some kind of memory element. Behaviour is specified in a state transition graph. The graph together with specified behaviour is called a finite state machine or automata. set of states S a start state set of inputs Ι set of outputs Ζ output function λ(s,i) next state function δ(s,i) KLOCKSTYRD – will update every second wether or not the state has changed. HÄNDELSESTYRD – will update every time unit as long as there is input to be processed. trellis – google a picture Sequential Circuits boolean function – mapping from n binary inputs to one binary output Algebraic structures Euclid’s algorithm – how to find the remainder \( R_d(n) = n \% d \). rewrite \( n / d \) as \[ n = qd + r , \quad 0 \leq r &amp;lt; d\] where \( q \) is the quotient, \( r \) the reminder and \(d\) the divisor. divide \(n\) with \(d\) \( floor(n/d) \) is the integer part of the result \( n - floor(n/d) = r \) if \( R_d(n) = 0 \) then \( n | d \)</summary></entry><entry><title type="html">Digital signalbehandling</title><link href="http://localhost:4000/2018/08/14/Digital_signalbehandling.html" rel="alternate" type="text/html" title="Digital signalbehandling" /><published>2018-08-14T00:00:00+02:00</published><updated>2018-08-14T00:00:00+02:00</updated><id>http://localhost:4000/2018/08/14/Digital_signalbehandling</id><content type="html" xml:base="http://localhost:4000/2018/08/14/Digital_signalbehandling.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;2018-08-14-Digital_signalbehandling&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h2 id=&quot;tidsdomänen&quot;&gt;Tidsdomänen&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;differensekvationen&lt;/strong&gt; – Beskriver hur utsignalen, i tidsdomämen, beror av indata och möjligen även tidigare utdata.&lt;/p&gt;
&lt;p&gt;Generella fallet: \[ y(n) + \sum_{k=1}^N a_k y(n-k) = \sum_{k=0}^N b_k x(n - k) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;impulssvar eller \( h(n) \)&lt;/strong&gt; – Beskrivningen av hur systemet förstärker input och hur snabbt den tonar bort.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;härled differensekvation&lt;/strong&gt; – om \( h(n) = \begin{Bmatrix} 3 &amp;amp; 2 &amp;amp; 1 \end{Bmatrix} \) så kan man tänka på att \( h(0) \) är hur maskinen förstärker det senaste invärdet. Därför går \( h(n) \) att skriva om till \( y(n) = h(0)x(n)+h(1)x(n-1)+h(2)x(n-2) \)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;härled systemfunktionen&lt;/strong&gt; – systemfunktionen är z-transformen av impulssvaret. Transformera!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;härled Fouriertransformen&lt;/strong&gt; – Fouriertransformen är som z-transformen. Man behöver bara byta ut \(z^{-n}\) mot \( e^{-j2 \pi Ft} \)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;härled linjär autokorrektion&lt;/strong&gt; – \( r_{xx} (k)=x(k) * x(-k) \). Man får \( x(-k) \) genom att snurra \( x(n) \) runt y-axeln.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;härled utsignal vid viss insignal&lt;/strong&gt; – om det är två diskreta vektorer – falta! Annars kan det ofta vara smidigare att första z-transformera, multiplicera och sedan iverstransformera.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;linjär-faltning&quot;&gt;Linjär faltning&lt;/h2&gt;
&lt;p&gt;Som att ta impulssvaret \( h(n) \) och dra detta igenom input \( x(n) \) med \( h(0) \) i bräschen. Vid \( y(0) \) har bara \( x(0) \) hunnit skickas in. Detta multipliceras med \( h(0) \)–beskrivningen av hur systemet svarar på input. I nästa tidssteg kommer även \( x(1) \) ha skickats in i systemet, detta värde multipliceras nu med \( h(0) \). \( x(0) \) är inte helt borta ty \( length(h(n))&amp;gt;1 \) och multipliceras nu med \( h(1) \). Varje inputvärde klingar ut enligt \( h(n) \). Först ljuder det enligt \( h(0) \). I nästa t kommer samma inputvärde att ha avtagit och nu förstärkas enl. \( h(1) \). Att det avtar förutsätter givetvis att systemet är stabilt – impulssvaret skulle lika gärna kunna förstärka varje indata och samtidigt skicka in tidigare utdata som indata (läs: feedback). faltningens \( n = 0 \) ges av det element där \( h(0) \text{ och } x(0) \) summerades. \( n = 0 \) är understruket i signalerna.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ x(n) = \begin{Bmatrix} 2 &amp;amp; \underline{4} &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 \end{Bmatrix} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\[ h(n) = \begin{Bmatrix} \underline{3} &amp;amp; 2 &amp;amp; 1 \end{Bmatrix} \]&lt;/p&gt;
&lt;p&gt;\[y(n) = \sum_k h(n - k) x(k) \]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Exempel:&lt;/em&gt; \[y(0) = h(0)x(0)+h(-1)x(1)+h(-2)x(2) \]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;properties&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;commutativity – spelar ingen roll vilken som är till vänster eller höger om tecknet.&lt;/li&gt;
&lt;li&gt;associativity – givet en faltning av tre signaler spelar det ingen roll vilka två som faltas först.&lt;/li&gt;
&lt;li&gt;distributivity – faltningen mellan en signal och en summa av två signaler kan utvidgas genom att istället räkna på faltningen mellan signalen och den ena signalen i summan pluss faltningen mellan signalen och den andra signalen i summan.&lt;/li&gt;
&lt;li&gt;input-output – faltning mellan impulssvar och input ger utsignalen.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;seriekoppling&lt;/em&gt; – utsignalen av två impulssvar efter varandra är faltningen av dessa samt \( x(n) \).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;parallellkoppling&lt;/em&gt; – utsignalen av två parallellkopplade impulssvar är faltningen mellan insignalen och summan av de två impulssvaren.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;korrelation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;linjär korrelation&lt;/strong&gt; \[ r_{yx} (k)=y(k) * x(-k) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;linjär autokorrelationen&lt;/strong&gt; \[ r_{xx}(k)=x(k) * x(-k) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;\( x(-n) \) ?&lt;/strong&gt; \[ x(n) = \begin{Bmatrix} 2 &amp;amp; \underline{4} &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 \end{Bmatrix} \]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spegelvänd nu vektorn runt x(0) och fyll i alla värden som finns&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ x(-n) = 
  \begin{Bmatrix}
    2 &amp;amp; 4 &amp;amp; 6 &amp;amp; \underline{4} &amp;amp; 2 
  \end{Bmatrix} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cirkulär faltning mod m&lt;/strong&gt; – Som vanlig faltning fast med loopade signaler.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Skär bort överskott eller lägg till nollor i “slutet” på signalerna så att de är m långa (beroende av modulo m).&lt;/li&gt;
&lt;li&gt;Tidsförskjut de två signalerna så att \( n=0 \) är först i ledet. Dessa signaler är cykliska så värdet från det första elementet kommer igen efter det sista, osv..&lt;/li&gt;
&lt;li&gt;Ställ upp faltningstabell och fyll i. Skillnaden från vanlig faltning är att dessa signaler är periodiska och därför måste man lägga till så många kolumner till vänster om \( x(0) \) att alla \( h(n) \) har varit med och bidragit för varje \( n \).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;cirkulär korrelation modulo n&lt;/strong&gt; –&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Spegelvänd den ena signalen runt \( n = 0 )\ &lt;strong&gt;EFTER ATT DU JUSTERAT LÄNGDEN&lt;/strong&gt; och fortsätt sedan enl. stegen för cirkulär faltning.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;transformer&quot;&gt;Transformer&lt;/h2&gt;
&lt;p&gt;Transformer är inget konstigare än geniala funktioner. Mer specifikt kommer kursen endast berörar transformer som mappar tidsdomänen på den komplexa frekvensdomänen. Transformer är användbara eftersom vissa operationer som är tidsödande i tidsdomänen motsvaras av enkla operationer i den komplexa frekvensdomänen. De ger också upphov till flera analysverktyg men också möjlighet att förändra system till sin fördel. När man är färdig måste man alltid inverstransformera för att komma tillbaka till tidsdomänen.&lt;/p&gt;
&lt;h3 id=&quot;z-transformen-hz&quot;&gt;Z-transformen H(z)&lt;/h3&gt;
&lt;p&gt;Transformen för diskreta signaler. Från z-transformen av differensekvationen leder broar i alla möjliga riktningar. Nedan följer några av fördelarna.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;faltning blir multiplikation&lt;/li&gt;
&lt;li&gt;analys och förändring av poler och nollställen nära till hands&lt;/li&gt;
&lt;li&gt;systemdiagram kan ritas upp&lt;/li&gt;
&lt;li&gt;Fouriertransformen ligger ett variabelbyte bort&lt;/li&gt;
&lt;li&gt;differensekvationen ges genom inverstransformering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;systemfunktionen H(z)&lt;/strong&gt; – z-transformen av impulssvaret. z-transformen går generellt mellan \( (-\infty , \infty) \) men för kausala system endast ner till 0. \[ H(z) = \sum_{-\infty}^{\infty} h(n)z^{-n} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;systemdiagram&lt;/strong&gt; – ritning av hur utdata förhåller sig till indata i frekvensdomänen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;härleda differensekvation&lt;/strong&gt; – Kom ihåg att \( Y(z) = H(z)X(z) \). Systemdiagram är alltid “z-transformerade”. Bilda hjälpfunktioner inne i diagrammet och härled hur de förhåller sig till varandra. När du har \( Y(z) = H(z)X(z) \) måste inverstransformera för att få differensekvationen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;härleda impulssvar&lt;/strong&gt; – När man har \( Y(z) = H(z)X(z) \) löser man ut \( H(z) \) och inverstransformerar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;härleda amplitudfunktionen&lt;/strong&gt; – Finn pol-/nollställen för \( H(z) \) och skissa amplituden över olika frekvenser.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;härled y(n) med begynnelsevilkor&lt;/strong&gt; – Här använder man den s.k. ensidiga z-transformen. Denna variant börjar först sin summering vid \( n = 0 \). Så länge systemet i fråga inte är kausalt och genererar utdata redan när n är mindre än noll kommer dock tidsskifte att leda till ett annorlunda resultat&lt;/p&gt;
&lt;p&gt;\[ Y(n-k) \Leftrightarrow z^{-k} [ Y^+ (z) + \sum_{n=1}^k x(-n) z^n ] \] \[ = [ y(-k)+y(-k+1)z^{-1} +…+ y(-1) z^{-k+1} + z^{-k} Y^+ (z) ] \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;generell lösning för enkelsidig z-transform&lt;/strong&gt; \[ Y^+ (z) = \frac{B_1 (z)}{A(z)} + \frac{N_1 (z)}{Q(z)} + \frac{N_0 (z)}{A(z)} \]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( y_{st} = \text{ stationary solution } = \frac{N_1 (z)}{Q(z)} \)&lt;/li&gt;
&lt;li&gt;\( y_{tr} = \text{ transient solution } = \frac{B_1 (z)}{A(z)} \)&lt;/li&gt;
&lt;li&gt;\( y_{zi} = \text{ zero input solution } = \frac{N_0 (z)}{A(z)} \)&lt;/li&gt;
&lt;li&gt;\( y_{zs} = \text{ zero state solution } = y_{st} + y_{tr} \)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;exempeluppgift&lt;/em&gt; \[ y(n) = 0.5 y(n - 1) + x(n) \] \[ x(n) = ( \frac{1}{3})^n u(n) \] \[ y(-1) = 1 \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;bestäm y(n) då insignalen är en sinusvåg&lt;/strong&gt; – Bör delas upp i två fall: kausal resp. oändlig input. I det förra fallet används z-transformen: Som vanligt kommer z-transformen \( Y(z) \) vara en produkt av \( H(z) X(z) = \frac{N(z)}{D(z)} X(z) \). Genom partialbråksuppdelning erhålls summan \( \frac{N_1 (z)}{D(z)} + \frac{C_0 + C_1 z^{-1}}{1-2 \cos ( \omega_0) z^{-1} + z^{-2}} \). Efter inv. trans. är svaret funnet. Den vänstra termen är en transient lösning medan den andra är stationär. Den stationära lösningen kommer vara av typen \( A \cos ( \omega_0 n) + B \sin ( \omega_0 n) \) och är också lösningen till fallet då input är av oändlig längd.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;inverstransformering&lt;/strong&gt; – Tips och tricks samlade nedan.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;komplexkonjugerande poler leder till kombination av sinus resp. cosinus-termer och man bör därför i täljaren lägga till \( 1 - z^{-1} = 1 - z^{-1} + \alpha \cos ( \omega_0 ) z^{-1} - \alpha \cos ( \omega_0 ) z^{-1} \). Därefter delar man fördelaktigt upp täljaren i termer som behövs för att inverstransformera fram cosinus och resten. Typ så här \[ 1 - \alpha \cos ( \omega_0) z^{-1} \text{ (cosinus) \] Resten multiplicerar vi med \( \frac{ r \sin ( \omega_0 ) }{ r \sin ( \omega_0 ) } \) och får då en term som kan inverstransformeras till en sinusterm med en lustig konstant framför.&lt;/li&gt;
&lt;li&gt;då polerna är funna kan faktorerna skrivas \( 1 - p_1 z^{-1} \) Där \( p_1 = pol \)&lt;/li&gt;
&lt;li&gt;om input består av två termer underlättar det att låta \( y = y_1 + y_2 \) där \( y_i \) är utsignalen för den i:te termen i insignalen.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;fouriertransformen-hω&quot;&gt;Fouriertransformen H(ω)&lt;/h3&gt;
&lt;p&gt;Verktyg för att ta reda på vilka frekvenser en signal består av. Lite som att blanda färg – fast baklänges. Fouriertransformen är z-transformen beräknad på enhetscirkeln. I utbyte mot att den existerar har den två krav: att impulssvaret är kausalt och stabilt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DTFT&lt;/strong&gt; – Discrete-time Fourier transform. Typen av Fourieranalys som bör användas då input är diskret. Funktionen som produceras är dock kontinuerlig.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DFT&lt;/strong&gt; – Discrete Fourier transform. DTFT fast med diskret utdata. Eftersom funktionen är periodisk blir en tidsfördröjning med -1 i DFT detsamma som att skjuta fram varje värde ett steg till höger. Då DFT är cyklisk är \( x(-1) \) detsamma som \( x(N) \) och det sista värdet i den ursprungliga sekvensen tar plats på \( n=0 \).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;HOWTO:&lt;/em&gt;&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Låt&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ x(n) = 
  \begin{Bmatrix}
    2 &amp;amp; 4 &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 
  \end{Bmatrix} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot; type=&quot;1&quot;&gt;
&lt;li&gt;Välj längd N och beräkna DTFT vid frekvenserna&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ \omega = 2 \pi 
  \begin{Bmatrix}
    0 &amp;amp; \frac{1}{N} &amp;amp; \frac{2}{N} &amp;amp; \frac{3}{N} &amp;amp; ... &amp;amp; \frac{N-1}{N} 
  \end{Bmatrix} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&quot;3&quot; type=&quot;1&quot;&gt;
&lt;li&gt;Med dessa värden genereras nu den “diskreta fouriertransformen” för k genom att summera över alla n mellan 0 och N-1&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;\[ X_{DFT} (k) = \sum_{n=0}^{N-1} x(n) e^{-j 2 \pi \frac{k}{N} N} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FFT&lt;/strong&gt; – Fast Fourier transform. Algorithm for calculating a sequence of the DFT.&lt;/p&gt;
&lt;p&gt;\[ X( \omega ) = X(z | z = e^{j \omega} ) \]&lt;/p&gt;
&lt;h2 id=&quot;sampling&quot;&gt;Sampling&lt;/h2&gt;
&lt;p&gt;Används för att diskretisera analoga signaler genom att läsa av signalen vid varje \( t = n T_s = n \frac{1}{F_s} \). För att få med alla frekvenser från den analoga signalen krävs enl. &lt;strong&gt;Nyqvist-Shannons samplingsteorem&lt;/strong&gt; att man samplar med mer än dubbelt så hög frekvens som den högsta i signalen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HOWTO SAMPLE&lt;/strong&gt; Vi vill sampla \( x(t) = \cos (2 \pi 400 t) \) med sampeltakten 1000 Hz.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Då 2π svarar mot ett varv, alt. en svängning, vet vi att signalens frekvens är 400 Hz.&lt;/li&gt;
&lt;li&gt;Vi substituerar nu \( t = \frac{1}{F_s} \) som ger \[ x(n) = \cos (2 \pi 0.4 n) = \cos (2 \pi (0.4 + k)n) \]&lt;/li&gt;
&lt;li&gt;Det sista ledet fick följa med då det introducerar &lt;strong&gt;vikning&lt;/strong&gt;. Efter sampling kommer en mängd olika frekvenser \( (F_0 / F_s) + k = f_0 \) motsvaras av en och samma frekvens. Detta betyder att om man inte samplar med tillräckligt hög frekvens kan vissa höga frekvenser vikas ner till lägre toner. Ifall den normaliserade frekvensens absolutbelopp är större än 0.5 kommer frekvensen inte representeras korrekt i den samplade signalen. Genom att subtrahera heltal från den normaliserade frekvensen tills dess att den befinner sig mellan -0.5 och 0.5 finner man den frekvens som kommer representera den faktiska frekvensen.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Om vi både har cos och sin i signalen bör man använda Eulers formler för att göra om signalen till enbart cosinus.&lt;/li&gt;
&lt;li&gt;Sinustermer ger upphov till fasskifte på π/2.&lt;/li&gt;
&lt;li&gt;Om man efter sampling vill lista alla möjliga egentliga frekvenser som kunnat ge upphov till den man fick får man &lt;strong&gt;INTE&lt;/strong&gt; glömma att beräkna alla de negativa heltalsmultiplarna.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Filma hjul&lt;/strong&gt; – Viktigt att tänka på är vilken period hjulet har. Har hjulet fyra ekrar kommer hjulet verka ha 1/4 periodtid, eftersom hjulet verkar vara tillbaka i ursprungsläget när alla ekrar snurrat 1/4ω. Detta leder till att frekvensområdet krymps och infinner sig halvvägs till de närmaste ekrarna och heltalet k multipliceras nu med 1/4.&lt;/p&gt;
&lt;p&gt;\[ f_0 = \frac{F}{F_s} \pm \frac{1}{4} k , \quad -1/8 \leq f \leq 1/8 \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HOWTO RECONSTRUCT&lt;/strong&gt; Vi har nu en funktion som beror av en normaliserad frekvens som kan vara resultatet av vikning och vill nu återskapa en signalen från våra sampel. Det finns nu tre möjligheter: återskapa genom att multiplicera frekvensen med sampeltakten eller passa på att greja lite till med signalen m.h.a. decimering eller interpolering!!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nedsampling/decimeras&lt;/strong&gt; – reducerar sampeltakten i en signal med faktor \( D \) genom att bara ta med var D:te element. Våra nya frekvenser ges av&lt;/p&gt;
&lt;p&gt;\[ f’ = \frac{F}{F_s} D \pm k , \quad -0.5 &amp;lt; f’ &amp;lt; 0.5 \]’&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;uppsamplas/interpoleras&lt;/strong&gt; – ökar sampeltakten med faktor \( I \) i en signal genom att lägga in \( I \) nollor mellan varje egentligt signalvärde. Den interpolerade sekvensen förhåller sig på följande sätt till den ursprungliga sekvensen \( Y( \omega ) = X( I \omega) \). Detta betyder att alla frekvenser mellan -0.5&lt;em&gt;I och 0.5&lt;/em&gt;I i \( X( \omega) \) kommer komma med i \( Y( \omega) \) men med frekvenserna dividerade med I.&lt;/p&gt;
&lt;p&gt;\[ f’ = \frac{ \pm \frac{F}{F_s} \pm k}{I} , \quad -0.5 &amp;lt; f’ &amp;lt; 0.5 \]’&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;terminologi&lt;/em&gt; + \( F_0 \) – analoga signalens frekvens (Hz) + \( T_s \) – perioden mellan varje sampel (sec) + \( F_s \) – sampeltakten (Hz) + \( f’ \) – den uppfattade frekvensen efter sampling&lt;/p&gt;
&lt;h2 id=&quot;analys&quot;&gt;Analys&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;pol-/nollställe-diagram&lt;/strong&gt; – Analysverktyg som visar hur systemet kommer behandla olika z. För z i nollställen kommer \( H(z) = 0 \). På motsvarande sätt kommer \( H(z) = \infty \) när z är på en pol. Genom att faktorisera \( H(z) = \frac{B(z)}{A(z)} \) och sedan finna rötterna till de båda funktionerna finner vi också poler och nollställen för systemfunktionen. Rötterna till \( B(z) \) ger oss våra nollställen och \( A(z) \) våra poler. Tänk på att förlänga kvoten med z för att få nämnaren på kvadratisk form. När rötterna är funna är det alltid fördelaktigt att skriva om \( H(z) \) så att pol- och nollställen blir synliga.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;poler&lt;/strong&gt; – befinner sig polen inuti enhetscirkeln har man inget att frukta. Detta gör så att signalen dör så småningom och är därför stabilt. Om den ligger på enhetscirkeln är det värre ty då tonar aldrig signaler ut och det blir instabilt. Poler utanför enhetscirkeln leder till förstärkt feedback vilket i sin tur leder till väldigt instabila system. Har man två komplexkonjugerande poler kommer signalen att svaja. I förhållande till enhetscirkeln gäller följande: Innanför: minskande svaj, på: evigt svaj, utanför: växande svaj. Om polen ligger till vänster om origo kommer tecknet alternera.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nollställen&lt;/strong&gt; – Dessa dödar den normaliserade frekvensen de befinner sig på men även frekvenser runt omkring nollställen blir försvagade. För att bara slå ut precis en viss frekvens kan man därför med fördel placera poler på samma frekvens men liiiite närmare origo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;maximum phase system&lt;/strong&gt; – H(z) där alla nollställen ligger utanför enhetscirkeln.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;minimum phase system&lt;/strong&gt; – H(z) där alla nollställen ligger inuti enhetscirkeln.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mixed phase system&lt;/strong&gt; – H(z) med nollställen både inuti och utanför enhetscirkeln.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kausalt system&lt;/strong&gt; – om antalet poler är större än eller lika med antalet nollställen.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;frekvensrespons eller \( H(\omega) \)&lt;/strong&gt; – Funktion som innehåller info om både amplitud och fas. Dess absolutbelopp ger upphov till amplitudfunktionen och dess argument är fasfunktionen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;amplitudfunktionen eller \( |H(\omega)| \)&lt;/strong&gt; – För att se vilka frekvenser en signal förstärker eller dödar. \[ |H( \omega_0 ) = \frac{ |V_1| }{ |U_1| |U_2| } \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fasfunktionen eller \( arg(H(\omega)) \)&lt;/strong&gt; – För att se hur insignalen fasförskjuts för olika frekvenser. Går att skissa m.h.a. pol-/nollställe-diagram genom att summera \( arg(V_i) - arg(U_i) \) där \( V_i \) är avståndet från den aktuella frekvensen till nollställe och \( U_i \) är motsvarande för poler.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;raka linjer&lt;/strong&gt; – linjär fasförskjutning innebär att om det existerar poler finns de i origo. Hack i grafen förekommer på nollställen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;¬raka linjer&lt;/strong&gt; – resultatet av poler utanför origo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;linjär fasförskjutning&lt;/strong&gt; – När alla frekvenser förändras med en konstant förskjutning. Filtret \( H( \omega ) = A( \omega) e^{j \Phi( \omega )} \) kommer göra precis det. Förändringen bestäms av \( \Phi(\omega) \). Alla symmetriska och antisymmetriska, d.v.s. \( \begin{Bmatrix} 2 &amp;amp; 1 &amp;amp; 0 &amp;amp; -1 &amp;amp; -2 \end{Bmatrix} \) impulssvar genererar linjär fas. För att undvika fasförskjutning ö.h.t. krävs antingen att h(n) är statiskt, d.v.s. att det inte består av minneselement, eller att det inte är ett kausalt impulssvar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stabilitet&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;alla poler i origo&lt;/li&gt;
&lt;li&gt;alla poler inom enhetscirkeln&lt;/li&gt;
&lt;li&gt;finit impulssvar&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;systemtyper&quot;&gt;Systemtyper&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;LTI&lt;/strong&gt; – Linjära tidsinvarianta system. Dessa kommer i två varianter beskrivna nedan.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FIR-system&lt;/strong&gt; – Finite impulse response&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;impulssvaret är av finit längd&lt;/li&gt;
&lt;li&gt;alltid stabilt&lt;/li&gt;
&lt;li&gt;alla poler i origo&lt;/li&gt;
&lt;li&gt;kan ha en fasförskjutning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;IIR-system&lt;/strong&gt; – Infinite impulse response (feedbacksystem)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;oändligt impulssvar&lt;/li&gt;
&lt;li&gt;stabilt iff alla poler ligger innanför enhetscirkeln&lt;/li&gt;
&lt;li&gt;kan inte ha fasförskjutning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;matematik&quot;&gt;Matematik&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Euler’s formler&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ \cos x = \frac{e^{ix} + e^{-ix}}{2}, \quad \sin x = \frac{e^{ix} - e^{-ix}}{2i} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;geometrisk summa&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ \sum_{k=m}^n a^k = \frac{a^{n+1} - a^m}{a-1} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;geometrisk serie&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ \sum_{k=0}^{\infty} a^k = \frac{a^0}{1-a} \quad |a| &amp;lt; 1 &amp;gt;\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;partialbråksuppdelning&lt;/strong&gt; – Hur partialbråket kommer se ut beror på faktorer i nämnaren hos den ursprungliga kvoten. När de olika termerna är uppställda på andra sidan likhetstecknet multipliceras högersidan med vänstersidans nämnare. Sedan får man A, B osv.. genom gausselimination.&lt;/p&gt;
&lt;p&gt;\[ \frac{2x^2 +x -3}{(x+1)^2 (x+2)} = \frac{A}{x+1} + \frac{B}{(x+1)^2} + \frac{C}{x+2} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nämnarfaktorer -&amp;gt; partialbråkstermer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( (x+a) \to \frac{A}{x+a} \)&lt;/li&gt;
&lt;li&gt;\( (x+a)^n \to \frac{A_1}{x+a} + … + \frac{A_n}{(x+a)^n} \)&lt;/li&gt;
&lt;li&gt;\( (x^2 + ax + b) \to \frac{A_1 x + B_1}{x^2 +ax + b} \)&lt;/li&gt;
&lt;li&gt;\( (x^2 + ax + b) \to \frac{A_1 x + B_1}{x^2 +ax + b} + … + \frac{A_n x + B_n}{(x^2 +ax + b)^n} \)&lt;/li&gt;
&lt;/ul&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">2018-08-14-Digital_signalbehandling Tidsdomänen differensekvationen – Beskriver hur utsignalen, i tidsdomämen, beror av indata och möjligen även tidigare utdata. Generella fallet: \[ y(n) + \sum_{k=1}^N a_k y(n-k) = \sum_{k=0}^N b_k x(n - k) \] impulssvar eller \( h(n) \) – Beskrivningen av hur systemet förstärker input och hur snabbt den tonar bort. härled differensekvation – om \( h(n) = \begin{Bmatrix} 3 &amp;amp; 2 &amp;amp; 1 \end{Bmatrix} \) så kan man tänka på att \( h(0) \) är hur maskinen förstärker det senaste invärdet. Därför går \( h(n) \) att skriva om till \( y(n) = h(0)x(n)+h(1)x(n-1)+h(2)x(n-2) \) härled systemfunktionen – systemfunktionen är z-transformen av impulssvaret. Transformera! härled Fouriertransformen – Fouriertransformen är som z-transformen. Man behöver bara byta ut \(z^{-n}\) mot \( e^{-j2 \pi Ft} \) härled linjär autokorrektion – \( r_{xx} (k)=x(k) * x(-k) \). Man får \( x(-k) \) genom att snurra \( x(n) \) runt y-axeln. härled utsignal vid viss insignal – om det är två diskreta vektorer – falta! Annars kan det ofta vara smidigare att första z-transformera, multiplicera och sedan iverstransformera. Linjär faltning Som att ta impulssvaret \( h(n) \) och dra detta igenom input \( x(n) \) med \( h(0) \) i bräschen. Vid \( y(0) \) har bara \( x(0) \) hunnit skickas in. Detta multipliceras med \( h(0) \)–beskrivningen av hur systemet svarar på input. I nästa tidssteg kommer även \( x(1) \) ha skickats in i systemet, detta värde multipliceras nu med \( h(0) \). \( x(0) \) är inte helt borta ty \( length(h(n))&amp;gt;1 \) och multipliceras nu med \( h(1) \). Varje inputvärde klingar ut enligt \( h(n) \). Först ljuder det enligt \( h(0) \). I nästa t kommer samma inputvärde att ha avtagit och nu förstärkas enl. \( h(1) \). Att det avtar förutsätter givetvis att systemet är stabilt – impulssvaret skulle lika gärna kunna förstärka varje indata och samtidigt skicka in tidigare utdata som indata (läs: feedback). faltningens \( n = 0 \) ges av det element där \( h(0) \text{ och } x(0) \) summerades. \( n = 0 \) är understruket i signalerna. \[ x(n) = \begin{Bmatrix} 2 &amp;amp; \underline{4} &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 \end{Bmatrix} \] \[ h(n) = \begin{Bmatrix} \underline{3} &amp;amp; 2 &amp;amp; 1 \end{Bmatrix} \] \[y(n) = \sum_k h(n - k) x(k) \] Exempel: \[y(0) = h(0)x(0)+h(-1)x(1)+h(-2)x(2) \] properties commutativity – spelar ingen roll vilken som är till vänster eller höger om tecknet. associativity – givet en faltning av tre signaler spelar det ingen roll vilka två som faltas först. distributivity – faltningen mellan en signal och en summa av två signaler kan utvidgas genom att istället räkna på faltningen mellan signalen och den ena signalen i summan pluss faltningen mellan signalen och den andra signalen i summan. input-output – faltning mellan impulssvar och input ger utsignalen. seriekoppling – utsignalen av två impulssvar efter varandra är faltningen av dessa samt \( x(n) \). parallellkoppling – utsignalen av två parallellkopplade impulssvar är faltningen mellan insignalen och summan av de två impulssvaren. korrelation linjär korrelation \[ r_{yx} (k)=y(k) * x(-k) \] linjär autokorrelationen \[ r_{xx}(k)=x(k) * x(-k) \] \( x(-n) \) ? \[ x(n) = \begin{Bmatrix} 2 &amp;amp; \underline{4} &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 \end{Bmatrix} \] Spegelvänd nu vektorn runt x(0) och fyll i alla värden som finns \[ x(-n) = \begin{Bmatrix} 2 &amp;amp; 4 &amp;amp; 6 &amp;amp; \underline{4} &amp;amp; 2 \end{Bmatrix} \] cirkulär faltning mod m – Som vanlig faltning fast med loopade signaler. Skär bort överskott eller lägg till nollor i “slutet” på signalerna så att de är m långa (beroende av modulo m). Tidsförskjut de två signalerna så att \( n=0 \) är först i ledet. Dessa signaler är cykliska så värdet från det första elementet kommer igen efter det sista, osv.. Ställ upp faltningstabell och fyll i. Skillnaden från vanlig faltning är att dessa signaler är periodiska och därför måste man lägga till så många kolumner till vänster om \( x(0) \) att alla \( h(n) \) har varit med och bidragit för varje \( n \). cirkulär korrelation modulo n – Spegelvänd den ena signalen runt \( n = 0 )\ EFTER ATT DU JUSTERAT LÄNGDEN och fortsätt sedan enl. stegen för cirkulär faltning. Transformer Transformer är inget konstigare än geniala funktioner. Mer specifikt kommer kursen endast berörar transformer som mappar tidsdomänen på den komplexa frekvensdomänen. Transformer är användbara eftersom vissa operationer som är tidsödande i tidsdomänen motsvaras av enkla operationer i den komplexa frekvensdomänen. De ger också upphov till flera analysverktyg men också möjlighet att förändra system till sin fördel. När man är färdig måste man alltid inverstransformera för att komma tillbaka till tidsdomänen. Z-transformen H(z) Transformen för diskreta signaler. Från z-transformen av differensekvationen leder broar i alla möjliga riktningar. Nedan följer några av fördelarna. faltning blir multiplikation analys och förändring av poler och nollställen nära till hands systemdiagram kan ritas upp Fouriertransformen ligger ett variabelbyte bort differensekvationen ges genom inverstransformering systemfunktionen H(z) – z-transformen av impulssvaret. z-transformen går generellt mellan \( (-\infty , \infty) \) men för kausala system endast ner till 0. \[ H(z) = \sum_{-\infty}^{\infty} h(n)z^{-n} \] systemdiagram – ritning av hur utdata förhåller sig till indata i frekvensdomänen. härleda differensekvation – Kom ihåg att \( Y(z) = H(z)X(z) \). Systemdiagram är alltid “z-transformerade”. Bilda hjälpfunktioner inne i diagrammet och härled hur de förhåller sig till varandra. När du har \( Y(z) = H(z)X(z) \) måste inverstransformera för att få differensekvationen. härleda impulssvar – När man har \( Y(z) = H(z)X(z) \) löser man ut \( H(z) \) och inverstransformerar. härleda amplitudfunktionen – Finn pol-/nollställen för \( H(z) \) och skissa amplituden över olika frekvenser. härled y(n) med begynnelsevilkor – Här använder man den s.k. ensidiga z-transformen. Denna variant börjar först sin summering vid \( n = 0 \). Så länge systemet i fråga inte är kausalt och genererar utdata redan när n är mindre än noll kommer dock tidsskifte att leda till ett annorlunda resultat \[ Y(n-k) \Leftrightarrow z^{-k} [ Y^+ (z) + \sum_{n=1}^k x(-n) z^n ] \] \[ = [ y(-k)+y(-k+1)z^{-1} +…+ y(-1) z^{-k+1} + z^{-k} Y^+ (z) ] \] generell lösning för enkelsidig z-transform \[ Y^+ (z) = \frac{B_1 (z)}{A(z)} + \frac{N_1 (z)}{Q(z)} + \frac{N_0 (z)}{A(z)} \] \( y_{st} = \text{ stationary solution } = \frac{N_1 (z)}{Q(z)} \) \( y_{tr} = \text{ transient solution } = \frac{B_1 (z)}{A(z)} \) \( y_{zi} = \text{ zero input solution } = \frac{N_0 (z)}{A(z)} \) \( y_{zs} = \text{ zero state solution } = y_{st} + y_{tr} \) exempeluppgift \[ y(n) = 0.5 y(n - 1) + x(n) \] \[ x(n) = ( \frac{1}{3})^n u(n) \] \[ y(-1) = 1 \] bestäm y(n) då insignalen är en sinusvåg – Bör delas upp i två fall: kausal resp. oändlig input. I det förra fallet används z-transformen: Som vanligt kommer z-transformen \( Y(z) \) vara en produkt av \( H(z) X(z) = \frac{N(z)}{D(z)} X(z) \). Genom partialbråksuppdelning erhålls summan \( \frac{N_1 (z)}{D(z)} + \frac{C_0 + C_1 z^{-1}}{1-2 \cos ( \omega_0) z^{-1} + z^{-2}} \). Efter inv. trans. är svaret funnet. Den vänstra termen är en transient lösning medan den andra är stationär. Den stationära lösningen kommer vara av typen \( A \cos ( \omega_0 n) + B \sin ( \omega_0 n) \) och är också lösningen till fallet då input är av oändlig längd. inverstransformering – Tips och tricks samlade nedan. komplexkonjugerande poler leder till kombination av sinus resp. cosinus-termer och man bör därför i täljaren lägga till \( 1 - z^{-1} = 1 - z^{-1} + \alpha \cos ( \omega_0 ) z^{-1} - \alpha \cos ( \omega_0 ) z^{-1} \). Därefter delar man fördelaktigt upp täljaren i termer som behövs för att inverstransformera fram cosinus och resten. Typ så här \[ 1 - \alpha \cos ( \omega_0) z^{-1} \text{ (cosinus) \] Resten multiplicerar vi med \( \frac{ r \sin ( \omega_0 ) }{ r \sin ( \omega_0 ) } \) och får då en term som kan inverstransformeras till en sinusterm med en lustig konstant framför. då polerna är funna kan faktorerna skrivas \( 1 - p_1 z^{-1} \) Där \( p_1 = pol \) om input består av två termer underlättar det att låta \( y = y_1 + y_2 \) där \( y_i \) är utsignalen för den i:te termen i insignalen. Fouriertransformen H(ω) Verktyg för att ta reda på vilka frekvenser en signal består av. Lite som att blanda färg – fast baklänges. Fouriertransformen är z-transformen beräknad på enhetscirkeln. I utbyte mot att den existerar har den två krav: att impulssvaret är kausalt och stabilt. DTFT – Discrete-time Fourier transform. Typen av Fourieranalys som bör användas då input är diskret. Funktionen som produceras är dock kontinuerlig. DFT – Discrete Fourier transform. DTFT fast med diskret utdata. Eftersom funktionen är periodisk blir en tidsfördröjning med -1 i DFT detsamma som att skjuta fram varje värde ett steg till höger. Då DFT är cyklisk är \( x(-1) \) detsamma som \( x(N) \) och det sista värdet i den ursprungliga sekvensen tar plats på \( n=0 \). HOWTO: Låt \[ x(n) = \begin{Bmatrix} 2 &amp;amp; 4 &amp;amp; 6 &amp;amp; 4 &amp;amp; 2 \end{Bmatrix} \] Välj längd N och beräkna DTFT vid frekvenserna \[ \omega = 2 \pi \begin{Bmatrix} 0 &amp;amp; \frac{1}{N} &amp;amp; \frac{2}{N} &amp;amp; \frac{3}{N} &amp;amp; ... &amp;amp; \frac{N-1}{N} \end{Bmatrix} \] Med dessa värden genereras nu den “diskreta fouriertransformen” för k genom att summera över alla n mellan 0 och N-1 \[ X_{DFT} (k) = \sum_{n=0}^{N-1} x(n) e^{-j 2 \pi \frac{k}{N} N} \] FFT – Fast Fourier transform. Algorithm for calculating a sequence of the DFT. \[ X( \omega ) = X(z | z = e^{j \omega} ) \] Sampling Används för att diskretisera analoga signaler genom att läsa av signalen vid varje \( t = n T_s = n \frac{1}{F_s} \). För att få med alla frekvenser från den analoga signalen krävs enl. Nyqvist-Shannons samplingsteorem att man samplar med mer än dubbelt så hög frekvens som den högsta i signalen. HOWTO SAMPLE Vi vill sampla \( x(t) = \cos (2 \pi 400 t) \) med sampeltakten 1000 Hz. Då 2π svarar mot ett varv, alt. en svängning, vet vi att signalens frekvens är 400 Hz. Vi substituerar nu \( t = \frac{1}{F_s} \) som ger \[ x(n) = \cos (2 \pi 0.4 n) = \cos (2 \pi (0.4 + k)n) \] Det sista ledet fick följa med då det introducerar vikning. Efter sampling kommer en mängd olika frekvenser \( (F_0 / F_s) + k = f_0 \) motsvaras av en och samma frekvens. Detta betyder att om man inte samplar med tillräckligt hög frekvens kan vissa höga frekvenser vikas ner till lägre toner. Ifall den normaliserade frekvensens absolutbelopp är större än 0.5 kommer frekvensen inte representeras korrekt i den samplade signalen. Genom att subtrahera heltal från den normaliserade frekvensen tills dess att den befinner sig mellan -0.5 och 0.5 finner man den frekvens som kommer representera den faktiska frekvensen. Om vi både har cos och sin i signalen bör man använda Eulers formler för att göra om signalen till enbart cosinus. Sinustermer ger upphov till fasskifte på π/2. Om man efter sampling vill lista alla möjliga egentliga frekvenser som kunnat ge upphov till den man fick får man INTE glömma att beräkna alla de negativa heltalsmultiplarna. Filma hjul – Viktigt att tänka på är vilken period hjulet har. Har hjulet fyra ekrar kommer hjulet verka ha 1/4 periodtid, eftersom hjulet verkar vara tillbaka i ursprungsläget när alla ekrar snurrat 1/4ω. Detta leder till att frekvensområdet krymps och infinner sig halvvägs till de närmaste ekrarna och heltalet k multipliceras nu med 1/4. \[ f_0 = \frac{F}{F_s} \pm \frac{1}{4} k , \quad -1/8 \leq f \leq 1/8 \] HOWTO RECONSTRUCT Vi har nu en funktion som beror av en normaliserad frekvens som kan vara resultatet av vikning och vill nu återskapa en signalen från våra sampel. Det finns nu tre möjligheter: återskapa genom att multiplicera frekvensen med sampeltakten eller passa på att greja lite till med signalen m.h.a. decimering eller interpolering!! nedsampling/decimeras – reducerar sampeltakten i en signal med faktor \( D \) genom att bara ta med var D:te element. Våra nya frekvenser ges av \[ f’ = \frac{F}{F_s} D \pm k , \quad -0.5 &amp;lt; f’ &amp;lt; 0.5 \]’&amp;gt; uppsamplas/interpoleras – ökar sampeltakten med faktor \( I \) i en signal genom att lägga in \( I \) nollor mellan varje egentligt signalvärde. Den interpolerade sekvensen förhåller sig på följande sätt till den ursprungliga sekvensen \( Y( \omega ) = X( I \omega) \). Detta betyder att alla frekvenser mellan -0.5I och 0.5I i \( X( \omega) \) kommer komma med i \( Y( \omega) \) men med frekvenserna dividerade med I. \[ f’ = \frac{ \pm \frac{F}{F_s} \pm k}{I} , \quad -0.5 &amp;lt; f’ &amp;lt; 0.5 \]’&amp;gt; terminologi + \( F_0 \) – analoga signalens frekvens (Hz) + \( T_s \) – perioden mellan varje sampel (sec) + \( F_s \) – sampeltakten (Hz) + \( f’ \) – den uppfattade frekvensen efter sampling Analys pol-/nollställe-diagram – Analysverktyg som visar hur systemet kommer behandla olika z. För z i nollställen kommer \( H(z) = 0 \). På motsvarande sätt kommer \( H(z) = \infty \) när z är på en pol. Genom att faktorisera \( H(z) = \frac{B(z)}{A(z)} \) och sedan finna rötterna till de båda funktionerna finner vi också poler och nollställen för systemfunktionen. Rötterna till \( B(z) \) ger oss våra nollställen och \( A(z) \) våra poler. Tänk på att förlänga kvoten med z för att få nämnaren på kvadratisk form. När rötterna är funna är det alltid fördelaktigt att skriva om \( H(z) \) så att pol- och nollställen blir synliga. poler – befinner sig polen inuti enhetscirkeln har man inget att frukta. Detta gör så att signalen dör så småningom och är därför stabilt. Om den ligger på enhetscirkeln är det värre ty då tonar aldrig signaler ut och det blir instabilt. Poler utanför enhetscirkeln leder till förstärkt feedback vilket i sin tur leder till väldigt instabila system. Har man två komplexkonjugerande poler kommer signalen att svaja. I förhållande till enhetscirkeln gäller följande: Innanför: minskande svaj, på: evigt svaj, utanför: växande svaj. Om polen ligger till vänster om origo kommer tecknet alternera. nollställen – Dessa dödar den normaliserade frekvensen de befinner sig på men även frekvenser runt omkring nollställen blir försvagade. För att bara slå ut precis en viss frekvens kan man därför med fördel placera poler på samma frekvens men liiiite närmare origo. maximum phase system – H(z) där alla nollställen ligger utanför enhetscirkeln. minimum phase system – H(z) där alla nollställen ligger inuti enhetscirkeln. mixed phase system – H(z) med nollställen både inuti och utanför enhetscirkeln. kausalt system – om antalet poler är större än eller lika med antalet nollställen. frekvensrespons eller \( H(\omega) \) – Funktion som innehåller info om både amplitud och fas. Dess absolutbelopp ger upphov till amplitudfunktionen och dess argument är fasfunktionen. amplitudfunktionen eller \( |H(\omega)| \) – För att se vilka frekvenser en signal förstärker eller dödar. \[ |H( \omega_0 ) = \frac{ |V_1| }{ |U_1| |U_2| } \] fasfunktionen eller \( arg(H(\omega)) \) – För att se hur insignalen fasförskjuts för olika frekvenser. Går att skissa m.h.a. pol-/nollställe-diagram genom att summera \( arg(V_i) - arg(U_i) \) där \( V_i \) är avståndet från den aktuella frekvensen till nollställe och \( U_i \) är motsvarande för poler. raka linjer – linjär fasförskjutning innebär att om det existerar poler finns de i origo. Hack i grafen förekommer på nollställen. ¬raka linjer – resultatet av poler utanför origo. linjär fasförskjutning – När alla frekvenser förändras med en konstant förskjutning. Filtret \( H( \omega ) = A( \omega) e^{j \Phi( \omega )} \) kommer göra precis det. Förändringen bestäms av \( \Phi(\omega) \). Alla symmetriska och antisymmetriska, d.v.s. \( \begin{Bmatrix} 2 &amp;amp; 1 &amp;amp; 0 &amp;amp; -1 &amp;amp; -2 \end{Bmatrix} \) impulssvar genererar linjär fas. För att undvika fasförskjutning ö.h.t. krävs antingen att h(n) är statiskt, d.v.s. att det inte består av minneselement, eller att det inte är ett kausalt impulssvar. stabilitet alla poler i origo alla poler inom enhetscirkeln finit impulssvar Systemtyper LTI – Linjära tidsinvarianta system. Dessa kommer i två varianter beskrivna nedan. FIR-system – Finite impulse response impulssvaret är av finit längd alltid stabilt alla poler i origo kan ha en fasförskjutning IIR-system – Infinite impulse response (feedbacksystem) oändligt impulssvar stabilt iff alla poler ligger innanför enhetscirkeln kan inte ha fasförskjutning Matematik Euler’s formler \[ \cos x = \frac{e^{ix} + e^{-ix}}{2}, \quad \sin x = \frac{e^{ix} - e^{-ix}}{2i} \] geometrisk summa \[ \sum_{k=m}^n a^k = \frac{a^{n+1} - a^m}{a-1} \] geometrisk serie \[ \sum_{k=0}^{\infty} a^k = \frac{a^0}{1-a} \quad |a| &amp;lt; 1 &amp;gt;\] partialbråksuppdelning – Hur partialbråket kommer se ut beror på faktorer i nämnaren hos den ursprungliga kvoten. När de olika termerna är uppställda på andra sidan likhetstecknet multipliceras högersidan med vänstersidans nämnare. Sedan får man A, B osv.. genom gausselimination. \[ \frac{2x^2 +x -3}{(x+1)^2 (x+2)} = \frac{A}{x+1} + \frac{B}{(x+1)^2} + \frac{C}{x+2} \] nämnarfaktorer -&amp;gt; partialbråkstermer \( (x+a) \to \frac{A}{x+a} \) \( (x+a)^n \to \frac{A_1}{x+a} + … + \frac{A_n}{(x+a)^n} \) \( (x^2 + ax + b) \to \frac{A_1 x + B_1}{x^2 +ax + b} \) \( (x^2 + ax + b) \to \frac{A_1 x + B_1}{x^2 +ax + b} + … + \frac{A_n x + B_n}{(x^2 +ax + b)^n} \)</summary></entry><entry><title type="html">Sannolikhetsteori och statistikteori</title><link href="http://localhost:4000/2018/08/13/Sannolikhetsteori_och_statistikteori.html" rel="alternate" type="text/html" title="Sannolikhetsteori och statistikteori" /><published>2018-08-13T00:00:00+02:00</published><updated>2018-08-13T00:00:00+02:00</updated><id>http://localhost:4000/2018/08/13/Sannolikhetsteori_och_statistikteori</id><content type="html" xml:base="http://localhost:4000/2018/08/13/Sannolikhetsteori_och_statistikteori.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;2018-08-13-Sannolikhetsteori_och_statistikteori&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h2 id=&quot;del-1-sannolikhet-eller-hur-man-beskriver-slumpen&quot;&gt;DEL 1: Sannolikhet eller hur man beskriver slumpen&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;utfall&lt;/strong&gt; – resultatet av ett slumpmässigt försök&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;utfallsrummet&lt;/strong&gt; – mängden möjliga utfall&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;händelse&lt;/strong&gt; – samling utfall&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;relativ frekvens&lt;/strong&gt; – kvoten mellan antalet erhållet utfall och hela antalet utförda kast&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;disjunkta händelser&lt;/strong&gt; – kan inte inträffa samtidigt&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kolmogorovs axiomsystem&lt;/strong&gt;&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Händelsen P(A) måste ligga mellan 0 &amp;amp; 1&lt;/li&gt;
&lt;li&gt;P(utfallsrummet) = 1&lt;/li&gt;
&lt;li&gt;om A &amp;amp; B är parvis oförenliga gäller \( P(A) + P(B) = P(A \cup B) \)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;komplementsatsen&lt;/strong&gt; P(A*) = 1 - P(A)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Additionssatsen&lt;/strong&gt; P(A or B) = P(A) + P(B) - P(A and B)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;oberoende händelser&lt;/strong&gt; – \( P(A \cap B) = P(A)P(B) \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Booles olikhet&lt;/strong&gt; – \( P(A \cup B) \leq P(A) + P(B) \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;De morgans lagar&lt;/strong&gt; – bra att veta att även boolsk algebra är distributiv.&lt;/p&gt;
&lt;p&gt;\[ A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \] \[ A \cap (B \cup C) = (A \cap B) \cup (A \cap C) \]&lt;/p&gt;
&lt;h4 id=&quot;kombinatorik&quot;&gt;Kombinatorik&lt;/h4&gt;
&lt;p&gt;Förutsättningar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n element&lt;/li&gt;
&lt;li&gt;k av dessa plockas&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Klassiska sannolikhetsdefinitionen&lt;/strong&gt; Vid likformigt sannolikhetmått är sannolikheten för en händelse lika med kvoten mellan antalet för händelsen gynsamma fall och antalet möjliga fall.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning med återläggning och hänsyn till ordning&lt;/strong&gt; \[n^k\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning med hänsyn till ordning&lt;/strong&gt; \[n*(n-1)(n-2) \cdots (n-k)\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning utan hänsyn till ordning&lt;/strong&gt; \[\binom{n}{k}\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning&lt;/strong&gt; Urna med kulor av två olika färger. Hur stor är chansen att erhålla k vita? Enl. __Klas. sann._ ges svaret av \[ g/m \] \[ m = \binom{v+s}{n} \] \[ g = \binom{v}{k} \binom{s}{n-k} \] Alltså produkten av sätten att få k stycken vita och alla möjligheter att få resterande svarta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning med återläggning&lt;/strong&gt; Samma som ovan men med återläggning. \[ m = (v+s)^n \] \[ g = \binom{n}{k} v^k s^{n-k}\]&lt;/p&gt;
&lt;p&gt;Alltså antalet olika kombinationer det finns av k stora samlingar bland n multiplicerat med sannolikheten för k vita multiplicerat med n-k svarta. Allt detta dividerat med m.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Betingade sannolikheten&lt;/strong&gt; – sannolikheten att något inträffar givet en annan händelse.&lt;/p&gt;
&lt;p&gt;\[P(B|A) = \frac{P(A \cap B)}{P(A)}\]&lt;/p&gt;
&lt;p&gt;Ger alltså ett samband mellan betingning och snitt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lagen om total sannolikhet&lt;/strong&gt; – genom att summera de olika produkter som ges av sannolikheten för varje möjligt utfall \( H_i \) multiplicerat med sannolikheten att A händer om vi faktiskt fått \( H_i \) får vi den totala sannolikheten att A händer.&lt;/p&gt;
&lt;p&gt;\[P(A) = \sum_{i=1}^{n} P(H_i)P(A|H_i)\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bayes sats&lt;/strong&gt; – när man behöver vända på en betingad sannolikhet. Nämnaren i bråket är alltså högerledet i lagen om total sannolikhet.&lt;/p&gt;
&lt;p&gt;\[P(H_i|A) = \frac{P(H_i)P(A|H_i)}{\sum_{j=1}^{n} P(H_j)P(A|H_j)}\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Oberoende händelser&lt;/strong&gt; – \( P(B|A) = P(B) \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sannolikheten att minst en inträffar&lt;/strong&gt; \[A_1 , A_2 , … , A_n \text{ är oberoende }, \quad P(A_i)=p_i\] \[1-(1-p_1)(1-p_2)…(1-p_n) = 1-(1-p)^n\]&lt;/p&gt;
&lt;h3 id=&quot;endimensionella-stokastiska-variabler&quot;&gt;1. Endimensionella stokastiska variabler&lt;/h3&gt;
&lt;p&gt;Den stokastiska variabeln är bron mellan matematiken och slumpen men är inget mer än en reellvärd funktion definierad på ett utfallsrum. Betecknas i texten som versaler från slutet av alfabetet som X, Y, eller Z.&lt;/p&gt;
&lt;h4 id=&quot;diskret-stokastisk-variabel&quot;&gt;diskret stokastisk variabel&lt;/h4&gt;
&lt;p&gt;En s.v. är __diskret_ om den kan anta ett ändligt eller uppräkneligt oändligt antal olika värden. funktionen över värdemängden kallas sannolikhetsfunktionen.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Enpunktsfördelning&lt;/strong&gt; – all massa i ett värde \[p_X(a) = 1\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Tvåpunktsfördelning&lt;/strong&gt; – om X endast antar två värden a &amp;amp; b med sannolikheterna p respektive 1- p. ex: krona/klave då X tar värdena a = 1 och b = 0 sägs X vara Bernoulli-fördelad.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Likformig fördelning&lt;/strong&gt; – X antar värden 1,2,..,m och alla dessa med samma sannolikhet. \[p_X(k)=1/m, k = 1,2,…,m.\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;För-första-gången-fördelning&lt;/strong&gt; – När samma oberoende försök görs om och om tills ett visst resultat erhålls. Antalet försök t.o.m. resultatet är då en s.v. med ffg-fördelning. \[ p_X(k)=(1-p)^{k-1}p, k=1,2,…,\] \[ X \in ffg(p) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Geometrisk fördelning&lt;/strong&gt; – genom att skippa resultatrundan som räknas in i ffg-fördelningen tillhör X Ge(p). \[p_X(k) = (1 - p)^kp, k = 0,1,2,…,\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Binomialfördelning&lt;/strong&gt; – slumpmässigt försök med en händelse A där P(A) = p upprepas n oberoende ggr. \[ p_X(k) = \binom{ n }{ k } p^k ( 1 - p )^{ n - k } \] \[ X \in Bin(n,p) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hypergeometrisk fördelning&lt;/strong&gt; – uppträdde vid dragning utan återläggning ur urna med vita och svarta kulor. \[ p_X(k) = \frac{\binom{v}{k} \binom{s}{n-k}}{\binom{v+s}{n}}\] \[ X \in Hyp(N,n,p)\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Poisson-fördelning&lt;/strong&gt; – beskriver antalet företelser som inträffar oberoende av varandra. \[ p_X(k) = \frac{ \mu^k }{ k! }e^{ -e } \] \[ X \in Po(\mu)\]&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;kontinuerlig-stokastisk-variabel&quot;&gt;kontinuerlig stokastisk variabel&lt;/h4&gt;
&lt;p&gt;Sannolikhetsfunktionen kallas nu täthetsfunktion och betecknas med f.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Likformig fördelning&lt;/strong&gt; – X antar alla värden mellan a och b med samma sannolikhet \[ f_X(x) = 1/(b-a) \text{ om } a &amp;lt; x &amp;lt; b &amp;gt;\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Exponentialfördelning&lt;/strong&gt; – beskriver tiderna mellan händelserna i en poissonprocess. \[ f_X(x) = \lambda e^{-\lambda x} \quad E(X) = 1 / \lambda, \quad D(X) = 1 / \lambda \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Normalfördelningen&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Weibull-fördelning&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gammafördelning&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;fördelningsfunktion&lt;/strong&gt; – Funktion som för varje möjligt utfall beräknar sannolikheten att utfallet blir just detta eller lägre.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;funktioner av stokastisk variabel&lt;/strong&gt; – När man vill veta hur en s.v., Y som beror av g(x), ser ut. Nedan följer generellt tillvägagångssätt för att beskriva \( f_y (y) \) i termer av den kända \( f_x (y) \). Med exemplet: \( g(x) = |X| \)&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Beskriv: \( F_y (y) = P( Y \leq y) \)&lt;/li&gt;
&lt;li&gt;Byt ut Y mot g(X): \( P( g(X) \leq y) \)&lt;/li&gt;
&lt;li&gt;Lös ut X: \( P( -y \leq X \leq y) = F_X (y) - F_X (-y) \)&lt;/li&gt;
&lt;li&gt;\(f_Y (y) = f_X (y) + f_X (-y) \)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;intensitet&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;flerdimensionella-stokastiska-variabler&quot;&gt;2. Flerdimensionella stokastiska variabler&lt;/h3&gt;
&lt;h4 id=&quot;note-to-self&quot;&gt;Note to self:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\[ p_{X,Y}(i,j) = p_X(i)p_Y(j) = P(j|i)P(i) \] OBS! Dont forget the last P(i)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;största-och-minsta-värdet&quot;&gt;Största och minsta värdet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Z = max(X,Y) \[F_Z(z) = F_X(z)F_Y(z)\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Z = min(X,Y) \[F_Z(z) = 1-[1-F_X(z)][1-F_Y(z)]\]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gör först om till fördelningsfunktion om täthetsfunktion&lt;/p&gt;
&lt;h4 id=&quot;summan-av-s.v.&quot;&gt;Summan av s.v.&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\[f_Z(z) = \int_{\infty}^{\infty} f_X(x)f_Y(z-x)dx\]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;väntevärden&quot;&gt;3. Väntevärden&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note to self:&lt;/strong&gt; konstanter inuti väntevärdesfunktioner ser dumt ut så flytta ut dem.&lt;/p&gt;
&lt;h4 id=&quot;väntevärdetexμ&quot;&gt;Väntevärdet/E(X)/μ&lt;/h4&gt;
&lt;p&gt;Är ett typ av lägesmått, precis som medianen. E(X) är väntevärdet för X. E(X) berättar om vad det väntade (__E__xpected) resultatet blir.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DEF:&lt;/strong&gt; \[ E(X) = \sum_kkp_X(k) \] \[ E(X) = \int\limits_{-\infty}^{\infty} x f_X(x)dx \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Y = g(X)&lt;/strong&gt; – Väljer du att interfacea funktionen med en ny variabel som beror av X med samma gamla fördelning så kan man trixa enl. följande \[ E(Y) = \sum_kg(k)p_X(k)\] \[ E(X) = \int\limits_{-\infty}^{\infty} g(x) f_X(x)dx \]&lt;/p&gt;
&lt;p&gt;\[ E(X+Y) = E(X)+E(Y) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;X &amp;amp; Y oberoende&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ E(XY) = E(X)E(Y)\]&lt;/p&gt;
&lt;p&gt;Samling X med samma väntevärde µ \[ E(\sum_{i=1}^n X_i)=n\mu \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Betingade väntevärden&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ E(X|Y=k) = \sum_{j=0}^\infty jp_{X|Y=k}(j)\]&lt;/p&gt;
&lt;p&gt;\[ E(X|Y=y) = \int_{-\infty}^\infty xf_{X|Y=y}(x)dx\]&lt;/p&gt;
&lt;h4 id=&quot;variansenvxσ&quot;&gt;Variansen/V(X)/σ²&lt;/h4&gt;
&lt;p&gt;Variansen är en typ av spridningsmått. Vid beräkning av varians av en summa olika s.v. bör man &lt;strong&gt;ALDRIG&lt;/strong&gt; anta att inblandade s.v. är oberoende. GLÖM MED ANDRA ORD INTE KOVARIANSEN.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DEF:&lt;/strong&gt; \[ V(X) = E[(X-\mu)^2] \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Schysta satser:&lt;/strong&gt; &lt;span class=&quot;math display&quot;&gt;\[ V(X) = E(X^2)-[E(X)]^2 \]&lt;/span&gt; \[ V(aX+b) = a^2V(X) \] \[ V(X + Y) = V(X) + V(Y) + 2C(X,Y) \]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Om oberoende: \( V(X + Y) = V(X) + V(Y) \)&lt;/li&gt;
&lt;li&gt;Om oberoende och med samma σ: \( V(\sum_{i=1}^nX_i) = n\sigma^2 \)&lt;/li&gt;
&lt;li&gt;Om oberoende och med samma σ samt µ: \( V(\bar{X})=\sigma^2/n \)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tänk på att använda formelsamlingen för att snabbt fastställa variansen för de olika fördelningarna.&lt;/p&gt;
&lt;h4 id=&quot;standardavvikelse-dx-eller-σ&quot;&gt;Standardavvikelse D(X) eller σ&lt;/h4&gt;
&lt;p&gt;Schyst mått då man får samma dimension som väntevärdet \[ D(X) = \sqrt{V(X)} \] \[ D(aX + b) = |a|D(X) \] Om oberoende: \[ D(X + Y) = \sqrt{D^2(X) + D^2(Y)} \]&lt;/p&gt;
&lt;h4 id=&quot;variationskoefficienten&quot;&gt;Variationskoefficienten&lt;/h4&gt;
&lt;p&gt;uttrycks i procent \[ R(X) = D(X)/E(X) \]&lt;/p&gt;
&lt;h4 id=&quot;fel&quot;&gt;fel&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;systematiskt fel/bias&lt;/strong&gt; är differansen mellan mätvärdets väntevärde och det korrekta värdet. (ett tal)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slumpmässigt fel&lt;/strong&gt; menas differensen mellan mätvärdet och dess väntevärde. (s.v. med E(X) = 0)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;beroendemått&quot;&gt;Beroendemått&lt;/h4&gt;
&lt;h5 id=&quot;kovarians&quot;&gt;Kovarians&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Kovariansen C(X,Y) mellan X &amp;amp; Y bör bli positiv om det finns ett beroende sådant att det finns en tendens hos variablerna att samtidigt avvika åt samma håll från sina väntevärden.&lt;/li&gt;
&lt;li&gt;\( C(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] \)&lt;/li&gt;
&lt;li&gt;\( C(X,Y) = E(XY)-E(X)E(Y) \)&lt;/li&gt;
&lt;li&gt;Om C(X,Y) = 0 är X och Y okorrelerade.&lt;/li&gt;
&lt;li&gt;\( X \text{ &amp;amp; } Y \text{ oberoende} \to \text{okorrelerade} \)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;korrelationskoefficienten&quot;&gt;Korrelationskoefficienten&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;DEF: \[ \rho(X,Y) = \frac{C(X,Y)}{D(X)D(Y)} \]&lt;/li&gt;
&lt;li&gt;Kovarians fast dimensionslös&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;stora-talens-lag&quot;&gt;Stora talens lag&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ju fler oberoende s.v. med samma µ desto närmre kommer medelvärdet att gå mot µ.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;betingade-väntevärden-och-varianser&quot;&gt;Betingade väntevärden och varianser&lt;/h4&gt;
&lt;h4 id=&quot;gauss-approximationsformler&quot;&gt;Gauss approximationsformler&lt;/h4&gt;
&lt;p&gt;Har du någonsin känt dig inkapabel? Då är taylorutveckling något för dig! Allt för ofta vill man ha en schyst funktion mitt i väntevärdet men hur räknar man ut E(Y) då!? Du behöver inte vara helt körd i skallen, det kan vara så att du råkat ut för någon av de många fallgropar som kantar väntevägen!&lt;/p&gt;
&lt;h5 id=&quot;en-variabel&quot;&gt;En variabel&lt;/h5&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;taylorutveckla: \[ g(X) \approx g(\mu) + (X - \mu)g’(\mu) \]&lt;/li&gt;
&lt;li&gt;g(X) har nu approximativa väntevärdet g(µ) samt [g’(E(X))]²V(X) som varians. Med en rak linje blir det enkelt att räkna med µ och σ².&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&quot;flera-variabler&quot;&gt;Flera variabler&lt;/h5&gt;
&lt;h6 id=&quot;abandon-all-hope-ye-who-enter-here&quot;&gt;Abandon all hope, ye who enter here&lt;/h6&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;taylorutveckla: \[ g(X,Y) \approx g(\mu_X,\mu_Y)+(X-\mu_X)g’_X(\mu_X,\mu_Y)+(Y-\mu_Y)g’_Y(\mu_X,\mu_Y) \]&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;normalfördelningen&quot;&gt;4. Normalfördelningen&lt;/h3&gt;
&lt;h5 id=&quot;notes-to-self&quot;&gt;Notes to self:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ca en tredjedel av massan hamnar utanför en standardavvikelse.&lt;/li&gt;
&lt;li&gt;normalfördelningar bevaras alltid under linjära transformationer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ f_X(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \]&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;standardiserad-fördelning&quot;&gt;Standardiserad fördelning&lt;/h4&gt;
&lt;p&gt;Täthetsfunktion: φ Fördelningsfunktion: Φ&lt;/p&gt;
&lt;p&gt;\[ \Phi(-x) = 1 - \Phi(x) \]&lt;/p&gt;
&lt;h4 id=&quot;allmän-fördelning&quot;&gt;Allmän fördelning&lt;/h4&gt;
&lt;p&gt;\[ X \in N(\mu,\sigma) \quad iff \quad Y = (X-\mu)/\sigma \in N(0,1) \] \[ f_X(x) = \frac{1}{\sigma}\varphi(\frac{x-\mu}{\sigma}) \] \[ F_X(x) = \Phi(\frac{x-\mu}{\sigma}) \]&lt;/p&gt;
&lt;h4 id=&quot;linjärkombinationer&quot;&gt;Linjärkombinationer&lt;/h4&gt;
&lt;p&gt;Om \[ X \in N(\mu,\sigma) \] så gäller att \[ Y=aX+b \in N(a\mu + b, |a|\sigma) \]&lt;/p&gt;
&lt;p&gt;Om \[ X_1,X_2,..,X_n \] är oberoende N(µ,σ) och \[ \bar{X} \] är medelvärdet så gäller att \[ \bar{X} \in N(\mu,\sigma/\sqrt{n}) \]&lt;/p&gt;
&lt;h3 id=&quot;de-tre-vännerna-och-binomialfördelning&quot;&gt;5. De tre vännerna och Binomialfördelning&lt;/h3&gt;
&lt;h4 id=&quot;binomialaren-fördelningen-med-återläggning&quot;&gt;binomialaren (fördelningen med återläggning)&lt;/h4&gt;
&lt;p&gt;E(X) = np V(X) = npq&lt;/p&gt;
&lt;p&gt;Om oberoende \[ X \in Bin(n_1,p) \quad \&amp;amp; Y \in Bin(n_2,p) \] \[ X + Y \in Bin(n_1+n_2,p) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Obs! Glöm inte att Binomialfördelningen är diskret, håll därför koll på gränserna (&amp;gt; != &amp;gt;=)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kan approximeras till&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;poissonfördelning&lt;/strong&gt; – om p är litet &lt;strong&gt;normalfördelning&lt;/strong&gt; – om npq &amp;gt; 10 kan man approximera med N(np,sqrt(npq)). Resultatet blir noggrannare om man vid beräkning av fördelningsfunktion adderar 1/2 till gränsen/gränserna.&lt;/p&gt;
&lt;p&gt;Skillnad mellan två binomialfördelade s.v. approximeras till \[ Y_1 - Y_2 \in N(p_1 - p_2, \sqrt{ \frac{p_1 (1-p_2)}{n_1} + \frac{ p_2 (1- p_1)}{n_2}} ) \]&lt;/p&gt;
&lt;h4 id=&quot;hypergeometriske-utan-återläggning&quot;&gt;Hypergeometriske (utan återläggning)&lt;/h4&gt;
&lt;p&gt;E(X) = np V(X) = ((N-n)/(N-1))np(1-p)&lt;/p&gt;
&lt;p&gt;Kan aproximeras som&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;strong&gt;binomialapproximation&lt;/strong&gt; om n/N är liten&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;normalapproximation&lt;/strong&gt; om n är stort&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;poisson-fördelningen&quot;&gt;Poisson-fördelningen&lt;/h4&gt;
&lt;p&gt;E(X) = µ V(X) = µ&lt;/p&gt;
&lt;p&gt;\[ X_1 \in Po( \theta_1 ) \quad and \quad X_2 \in Po( \theta_2 ) \quad then \quad X_1+X_2 \in Po(\theta_1+\theta_2) \]&lt;/p&gt;
&lt;p&gt;Kan approximeras som&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;strong&gt;normalfördelning&lt;/strong&gt; om µ är stort&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;multinomial&quot;&gt;Multinomial&lt;/h4&gt;
&lt;h3 id=&quot;markovkedjor&quot;&gt;Markovkedjor&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Stokastiska processer vars nästa värde endast beror på nuvarande värde.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;övergångsmatris används för att skriva upp “hoppsannolikheterna”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;övergångssannolikheter av N:te ordningen härleds genom att matrismultiplicera övergångsmatrisen med sig själv n ggr. alltså sannolikheten att mellanlanda i ett tillstånd.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;För att simulera sannolikheterna att systemet börjar i de olika tillstånden används matrismultiplikation med en radvektor &lt;span class=&quot;math display&quot;&gt;\[ p^{(0)}=(p_1^{(0)},p_2^{(0)},...) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\[ \begin{pmatrix} 1 &amp;amp; 2 \end{pmatrix} * \begin{pmatrix} 1to1 &amp;amp; 1to2 \\ 2to1 &amp;amp; 2to2 \end{pmatrix} \]&lt;/p&gt;
&lt;h5 id=&quot;terminologi&quot;&gt;terminologi&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;tillstånd&lt;/strong&gt; – markovkedja är alltid i ett tillstånd. Den lämnar detta enl. övergångsmatrisen&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ändlig&lt;/strong&gt; – ändligt antal tillstånd i kedjan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;beständigt&lt;/strong&gt; – om tillstånd där \( p_{ii} = 1 \) (Gäller alla olika ordningars övergångsmatriser)&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;kolla första ordningens sannolikhet att kedjan väljer att hoppa till tillståndet det redan var i, sedan andra ordningens och tredje ordningens. Fortsätt tills du hittat ett samband mellan sannolikheterna, ex. i form av en geometrisk serie. Blir summan 1 har du ett &lt;strong&gt;beständigt tillstånd&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Använd sedan faktumet att om &lt;strong&gt;två tillstånd kommunicerar tvåsidigt är de båda antinge beständiga eller båda inte&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Använd sedan faktumet att om alla \( p_{ij} = 0 \) så är j inte beständigt (går ju inte att komma dit (om man inte börjar där men inte sedan kan man ändå inte komma dit igen)).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;obeständigt&lt;/strong&gt; – tillstånd om P(i-&amp;gt;i) less than 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Om två tillstånd kommunicerar tvåsidigt är de båda antingen beständinga eller inte.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;irreducibel&lt;/strong&gt; – om alla tillstånd kommunicerar tvåsidigt med varandra, indirekta anslutningar räknas också.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;rita upp markovkedjan och följ pilarna&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;stationär fördelning&lt;/strong&gt; – sannolikheterna att systemet befinner sig i de olika tillstånden.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;skapa sannolikhetsvektorn \( \pi = ( \pi_1, \pi_2,..) \)&lt;/li&gt;
&lt;li&gt;lös ekv. \( \pi = \pi P \) (P är övergångsmatrisen)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;\[ p^{(n)}=( p_1^{(n)}, p_2^{(n)} ,…) \to \pi, \quad \text{ när } n \to \infty \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;asymptotisk fördelning&lt;/strong&gt; – om man i en ändlig kedja kan finna ett \( r&amp;gt;0 \) så beskaffat att alla element i någon kolonn i matrisen P^r är positiva, existerar det en &lt;strong&gt;asymptotisk&lt;/strong&gt; fördelning&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;periodiska tillstånd&lt;/strong&gt; – om det alltid krävs ett visst antal hopp för att komma tillbaka till ett tillstånd är tillståndet periodiskt. t.ex. om processen bara kan nå tillbaka till Ei efter 3,6,9,… steg har Ei perioden 3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aperiodiska tillstånd&lt;/strong&gt; – om det alltid går att komma tillbaka till ett tillstånd direkt..&lt;/p&gt;
&lt;h2 id=&quot;del-2-statistik-eller-vilka-slutsatser-man-kan-dra-av-ett-datamaterial&quot;&gt;DEL 2: Statistik eller vilka slutsatser man kan dra av ett datamaterial&lt;/h2&gt;
&lt;h3 id=&quot;terminologi-1&quot;&gt;terminologi&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;parameterrummet&lt;/strong&gt; – de värden den sökta parametern kan tänkas anta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprov&lt;/strong&gt; – betecknas med lilla x = (x1,x2,…,xn) för n dimensionella s.v.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprovsvariansen&lt;/strong&gt; – \( s^2 = \frac{1}{n-1} \sum_{j=1}^n (x_j - \bar{x})^2 \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kovariansen&lt;/strong&gt; – mellan x- och y-värdena i en datamängd \( ( x_1 , y_1 ),( x_2 , y_2 ),…,( x_n , y_n ) \) \[ c_{xy} = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;korrelationskoefficienten&lt;/strong&gt; – \( r = \frac{c_{xy}}{s_xs_y} \)&lt;/p&gt;
&lt;h3 id=&quot;punktskattning&quot;&gt;7. Punktskattning&lt;/h3&gt;
&lt;p&gt;Lär dig uppskatta saker!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;punktskattning&lt;/strong&gt; – den observerade sannolikheten – ett utfall av stickprovsvariabeln \[ \theta_{obs}^*(x_1,x_2,…,x_n) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprovsvariabeln&lt;/strong&gt; – en s.v. som punktskattningen är ett utfall av \[ \theta^*(X_1,X_2,…,X_n) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;väntevärdesriktig&lt;/strong&gt; – punktskattning vars tillhörande stickprovsvariabel har väntevärdet θ. dvs om \[ E(\theta^*) = \theta \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MSE&lt;/strong&gt; – mean square error – medelkvadratfelet för en punktskattning – mått på slumpmässigt fel \[ MSE = E(( \theta^* - \theta)^2) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;effektiv skattning&lt;/strong&gt; – om variansen för \( V( \theta^* ) \leq V( \hat{\theta} ) \) så är \( \theta^* \) effektivare än den andra.&lt;/p&gt;
&lt;h4 id=&quot;skattning-av-μ-σ&quot;&gt;Skattning av μ &amp;amp; σ&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;µ&lt;/strong&gt; – stickprovsmedelvärdet \[ \bar{x} \] är en väntevärdesriktig och konsistent skattning av µ och gäller för alla fördelningar&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;σ^2&lt;/strong&gt; – stickprovsvariansen s^2 är en väntevärdesriktig skattning av σ^2 som gäller för alla fördelningar och ser ut så här om μ är känd \[ \frac{ 1 }{ n } \sum_i^n (x_i - \mu)^2 \] Annars skattas μ med medelvärdet av mätdata och man får efter lite väntevärdesriktighetsjustering \[ \frac{ 1 }{ n - 1 } \sum_i^n (x_i - \bar{x})^2 \]&lt;/p&gt;
&lt;h4 id=&quot;skattningsfunktioner&quot;&gt;Skattningsfunktioner&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Maximum-likelihood-metoden – ML-metoden&lt;/strong&gt; – Om man vill skatta en parameter till en täthets/sannolikhetsfunktion. Genom att sätta in varje mätdata i sin sannolikhetsfunktion och sedan multiplicera alla dessa får vi sannolikheten att utfallen blev just mätdatan. Vi utnyttjar nu att sannolikhetsfunktionen är som störst när avståndet mellan väntevärdet och mätdatan är som minst genom att derivera över den okända parametern och söka maxpunkt.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Skapa \[ L(\theta) = P(X_1 = x_1, X_2 = x_2,…,X_n = x_n;\theta) \] alt. \[ L(\theta) = f_{X_1,X_2,…,X_n}(x_1,x_2,…,x_n;\theta) \] (A.k.a. likelihood-funktionen)&lt;/li&gt;
&lt;li&gt;Finn funktionens maxpunkt genom ex. derivering över theta.&lt;/li&gt;
&lt;li&gt;Funktionens största värde är det mest sannolika scenariot.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Minsta-kvadrat-metoden – MK-metoden&lt;/strong&gt; – Om man vill skatta en parameter till en täthets/sannolikhetsfunktion. När man vet hur parametern förhåller sig till mätdatan kan man ställa upp en summa där varje term motsvarar \( (x_i - g( \theta ) )^2 \). Genom att finna derivatans minimum får vi reda på det värde på θ som gör differanserna så små som möjligt. Så hur går man då tillväga? Jo genom att skapa funktionen \( Q( \theta )) \) och sedan derivera denna och finna minimum för&lt;/p&gt;
&lt;p&gt;\[ Q(\theta) = \sum_{i=1}^n [x_i - \mu_i (\theta)]^2 \] \[ \frac{dQ}{d \theta} Q( \theta ) \]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Viss mätdata sämre än resten? Använd vikter framför termerna i \( Q ( \theta ) \) så att de sämre mätningarna får mindre betydelse.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Flera parametrar? Lös partialderivatorna och sedan ekvationssystemet.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;normalfördelningen-1&quot;&gt;Normalfördelningen&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Två stickprov med samma σ&lt;/strong&gt; – M.h.a. ML-skattning får vi som väntat \( ( \mu_1 )&lt;em&gt;{obs}^* = \bar{x} \) samt \( \mu_2 )&lt;/em&gt;{obs}^* = \bar{y} \). variansen, å andra sidan, skattas av \[ s^2 = \frac{ \sum_{i_1}^{n_1} (x_i - \bar{x} )^2 +\sum_{i_1}^{n_2} (y_i - \bar{y} )^2 }{ (n_1 - 1 ) + (n_2 - 1 ) } \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;n stickprov med samma σ&lt;/strong&gt; – En skattning som gäller oavsett hur många stickprov man blandar in ges av \[ s^2 = \frac{ Q_1 + … + Q_n }{ (n_1 - 1) + … + (n_2 - 1) } \] \( Q_i \) är kvadratsumman kring medelvärdet.&lt;/p&gt;
&lt;h3 id=&quot;intevallskattning&quot;&gt;8. Intevallskattning&lt;/h3&gt;
&lt;p&gt;När man vill veta hur stor sannolikhet det är att en okänd parameter ligger inom ett visst interval.&lt;/p&gt;
&lt;h4 id=&quot;tillämpning-på-normalfördelningen&quot;&gt;Tillämpning på normalfördelningen&lt;/h4&gt;
&lt;h4 id=&quot;ett-stickprov&quot;&gt;Ett stickprov&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;µ okänd σ känd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[\mu* = \bar{x} \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;μ känd σ okänd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ (\sigma^2)_{obs}^* = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&quot;konfidensintervall-för-väntevärdet&quot;&gt;Konfidensintervall för väntevärdet&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;σ känd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;En lämplig skattning av µ är aritmetiska medelvärdet av X.&lt;/p&gt;
&lt;p&gt;\[ \bar{X} \in N(\mu,D) \] \[ D = \sigma/\sqrt{n} \] \[ I_\mu = (\bar{x}-\lambda_{\alpha/2}D,\bar{x}+\lambda_{\alpha/2}D) \]&lt;/p&gt;
&lt;p&gt;Allt detta följer av att:&lt;/p&gt;
&lt;p&gt;\[ \frac{\bar{X}-\mu}{D} \in N(0,1) \]&lt;/p&gt;
&lt;p&gt;Följaktligen gäller med sannolikheten 1-alfa att:&lt;/p&gt;
&lt;p&gt;\[ -\lambda_{\alpha/2} &amp;lt; \frac{\bar{X}-\mu}{D} &amp;lt; \lambda_{\alpha/2} &amp;gt;\]&lt;/p&gt;
&lt;p&gt;Om vi har ett intervall:&lt;/p&gt;
&lt;p&gt;\[ I_\mu = (16 \pm 2.58 * 0.155) \]&lt;/p&gt;
&lt;p&gt;där&lt;/p&gt;
&lt;p&gt;\[ D = 1.2/\sqrt{60} = 0.155 \]&lt;/p&gt;
&lt;p&gt;och man istället vill ha en mindre standardavvikelse, säg 0.5, så kan man sätta upp följande ekvation:&lt;/p&gt;
&lt;p&gt;\[ 2 * 2.58 * 1.2/\sqrt{n} = 0.5 \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;σ okänd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I detta fallet gäller en helt galen lösning eftersom man behöver skatta σ&lt;/p&gt;
&lt;p&gt;\[ I_\mu = (\bar{x}-t_{\alpha/2}(f)d,\bar{x}+t_{\alpha/2}(f)d) \] \[ d = s/\sqrt{n}, \quad f = n-1 \]&lt;/p&gt;
&lt;h5 id=&quot;konfidensintervall-för-standardavvikelsen&quot;&gt;Konfidensintervall för standardavvikelsen&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;μ känd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Aint gonna happen gurl&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;μ okänd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ I_\sigma = (k_1s,k_2s) \] \[ k_1 = \sqrt{(f/\chi_{\alpha/2}^2(f)} \] \[ k_2 = \sqrt{(f/\chi_{1-\alpha/2}^2(f)} \] \[ f = n-1 \]&lt;/p&gt;
&lt;h4 id=&quot;två-stickprov&quot;&gt;Två stickprov&lt;/h4&gt;
&lt;p&gt;När man vill mäta skillnaden mellan två stickprov. Om de två stickproven parvis korrelerar bör metoden tillhörande stickprov i par användas.&lt;/p&gt;
&lt;p&gt;Om σ1 och σ2 är kända:&lt;/p&gt;
&lt;p&gt;\[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-\lambda_{\alpha/2}D,\bar{x}-\bar{y}+\lambda_{\alpha/2}D) \] \[ D = \sqrt{ \sigma_{1}^{2} / n_1 + \sigma_{2}^{2} / n_2} \]&lt;/p&gt;
&lt;p&gt;Om σ1 = σ2 = σ:&lt;/p&gt;
&lt;p&gt;\[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-t_{\alpha/2}(f)d,\bar{x}-\bar{y}+t_{\alpha/2}(f)d) \] \[ d = \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2}} \]&lt;/p&gt;
&lt;h4 id=&quot;stickprov-i-par&quot;&gt;Stickprov i par&lt;/h4&gt;
&lt;p&gt;När det utförs två mätningar på n olika objekt, t.ex. före och efter något har hänt. Då alla objekt kan skilja sig åt är det svårt att göra skattningar om de enskilda objekten men på samma gång perfekt läge för att skatta skillnaden mellan mätningarna.&lt;/p&gt;
&lt;p&gt;Skapa \( z = y - x \) och använd z för skattning av standardavvikelse.&lt;/p&gt;
&lt;h3 id=&quot;hypotesprövning&quot;&gt;9. Hypotesprövning&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;nollhypotes&lt;/strong&gt; – hypotesen att det inte föreligger något fenomen som kräver en förklaring. Betecknas: \( H_0 \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mothypotes&lt;/strong&gt; – hypotes som kan vara sann om inte nollhypotesen är det. Betecknas: \( H_i \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;signifikansnivå/felrisk&lt;/strong&gt; – sannolikheten att nollhypotesen förkastas trots att den är sann. (Ju lägre desto bättre).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;signifikant* – 0.05&lt;/li&gt;
&lt;li&gt;signifikant** – 0.01&lt;/li&gt;
&lt;li&gt;signifikant*** – 0.001&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;testvariabel/teststorhet&lt;/strong&gt; – observation av stickprovsvariabel. Tackvare normalapproximation lämpar sig ofta testvariabler på formen \( ( \theta^* - \theta_0 )/D \). Där \( \theta^* \) är det skattade väntevärdet, \( \theta_0 \) är väntevärdet som gäller för nollhypotesen och \( D \) är standardavvikelsen för skattningen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;signifikanstest&lt;/strong&gt; 1. Om \(t_{obs} \in \text{jätteosannolikt område} \) förkasta \( H_0 \) 2. Om \( t_{obs} \) å andra sidan är ett sannolikt utfall, även i vanliga fall så bör \( H_0 \) inte förkastas.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;direkt- och P-värdesmetoden&lt;/strong&gt; – anta \( H_0 \) och beräkna sannolikheten att man får det utfall man fått eller något värre. “Värre” betyder alla utfall som är ännu mindre sannolika om \( H_0 \) stämmer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;konfidensmetoden&lt;/strong&gt; – genom att beräkna konfidensintervall för variabel och sedan förkasta nollhypotesen om värdet hamnar utanför.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Testkvantitet&lt;/strong&gt; – använd testvariabel och tabell och se om testvariabeln är större eller mindre än en viss α-kvantil.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;styrkefunktionen&lt;/strong&gt; \( h(\theta) = P(H_0 \text{ förkastas}) \) om θ är det rätta värdet.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bör vara stort för alla θ som tillhör mothypotesen&lt;/li&gt;
&lt;li&gt;bör vara litet för alla θ som tillhör nollhypotesen&lt;/li&gt;
&lt;li&gt;h(θ) kallas testets styrka för θ&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;how-to-styrkefunktion&quot;&gt;How to styrkefunktion&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;\( X \in N( \theta, 0.04) \) Antag \( H_0: \theta = 2.0 \) och sätt upp villkoret för att förkasta \( H_0 \). e.g. \( | X - 2.0 | \geq 0.04 \lambda_{0.025} \)&lt;/li&gt;
&lt;li&gt;Skapa nu styrkefunktionen \(h(\theta) = P(| X - 2.0 | \geq 0.04 \lambda_{0.025}) = 1 - P(-0.04 \lambda_{0.025} \leq X - 2.0 \leq 0.04 \lambda_{0.025}) \). Denna duger inte än eftersom den inte beror av θ.&lt;/li&gt;
&lt;li&gt;Då styrkefunktionen alltså går ut på att få se sannolikheten att \( H_0 \) förkastas när \( E(X) = \theta \) antar vi att \( E(X) = \theta \) och bildar variabelbytet \( u = \frac{X - \theta}{0.04} \) för att kunna använda den standardiserade normalfördelningen.&lt;/li&gt;
&lt;li&gt;Via enklare räkning byter vi ut \( (X - 2.0)/D \) mot (\( u \) och kan då använda den standardiserade nomralfördelningens fördefördelningsfunktion \[ h( \theta ) = 1 - \Phi ( \lambda_{0.025} + \frac{2.0 - \theta}{0.04}) + \Phi (- \lambda_{0.025} + \frac{2.0 - \theta}{0.04}) \]&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;regressionsanalys&quot;&gt;10. Regressionsanalys&lt;/h3&gt;
&lt;p&gt;När man vill se samband mellan två eller flera storheter.&lt;/p&gt;
&lt;h4 id=&quot;observera&quot;&gt;observera!&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Använd alltid t-fördelningen när standardavvikelsen blivit skattad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Icke linjära samband&lt;/strong&gt; – Logaritmera \[ y_i = c e^{\beta_{t_i}} \epsilon_i \] \[ ln y_i = ln c + \beta t_i + ln \epsilon_i \] Glöm nu inte att använda \( ln y_i \), alltså inte \( y_i \). Samma gäller alla sådana termer.&lt;/p&gt;
&lt;h4 id=&quot;terminologi-2&quot;&gt;Terminologi&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;teoretiska regressionslinjen&lt;/strong&gt; \[ y = \alpha + \beta x \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;parameterskattningar&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ \sum x_i , \quad \sum x_i^2 , \quad S_{xx} = \sum_{i=1}^n (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 - \frac{1}{n} (\sum_{i=1}^n x_i)^2 \]&lt;/p&gt;
&lt;p&gt;\[ \sum y_i , \quad \sum y_i^2 , \quad S_{yy} = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 - \frac{1}{n} (\sum_{i=1}^n y_i)^2 \]&lt;/p&gt;
&lt;p&gt;\[ \sum x_i y_i , \quad S_{xy} = \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y}) = \sum_{i=1}^n x_i y_i - \frac{1}{n} (\sum_{i=1}^n x_i) (\sum_{i=1}^n y_i) \]&lt;/p&gt;
&lt;h4 id=&quot;punktskattningar&quot;&gt;Punktskattningar&lt;/h4&gt;
&lt;p&gt;Remember MK-metoden? Bestäm minimum för&lt;/p&gt;
&lt;p&gt;\[ Q( \alpha , \beta ) = \sum_{i}^n (y_i - \mu_i)^2 \] \[ \mu_i = \alpha + \beta x_i \]&lt;/p&gt;
&lt;p&gt;Genom att sätta partialderivatorna till noll fås&lt;/p&gt;
&lt;p&gt;\[ \beta^* = \frac{S_{xy}}{S_{xx}} \quad \alpha^* = \bar{y} - \beta^* \bar{x} \]&lt;/p&gt;
&lt;p&gt;\[ ( \sigma^2 )^* = s^2 = \frac{Q_0}{n-2}, \quad Q_0 = S_{yy} - S_{xy}^2 / S_{xx} \]&lt;/p&gt;
&lt;p&gt;Observera att&lt;/p&gt;
&lt;p&gt;\[ \mu_0^* = \alpha^* + \beta^* x_0 \in N( \alpha + \beta x_0 , \sigma \sqrt{ \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}}) \]&lt;/p&gt;
&lt;h4 id=&quot;intervallskattningar&quot;&gt;Intervallskattningar&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Prediktionsintervall för observationer&lt;/strong&gt; – När man vill göra ett konfidensintervall för framtida observationer av \( Y \) för \( x = x_0 \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kalibreringsintervall&lt;/strong&gt; – Då man erhållit värde \( y_0 \text{ på } y \), vad blir då \( x_0 \)&lt;/p&gt;
&lt;h4 id=&quot;stokastiska-vektorer&quot;&gt;Stokastiska vektorer&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;stokastisk vektor&lt;/strong&gt; – Kolonnvektor vars element är stokastiska variabler. Den kan alltså representera en n-dimensionell stokastisk variabel. \[ X = [X_1,…,X_n]^T \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;väntevärdesvektorn&lt;/strong&gt; – Elementvis beräknade väntevärden för \( X \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kovariansmatrisen&lt;/strong&gt; – Också en funktion på \( X \). Denna genererar \( C(X_i,X_j) \) på \( X_{ij} \). Då \( C(X,X) = V(X) \) hittar man varianser för de olika s.v. på diagonalelementen.&lt;/p&gt;
&lt;h4 id=&quot;multipel-regression&quot;&gt;Multipel regression&lt;/h4&gt;
&lt;p&gt;För stilrenhet döps \( \alpha \) om till \( \beta_0 \).&lt;/p&gt;
&lt;p&gt;\[ y_i = \beta_0 + \beta_1 x_{i1} + … + \beta_k x_{ik} + \epsilon_i, \quad i=1,…,n \]&lt;/p&gt;
&lt;p&gt;Skriv modellen på matrisform för att generalisera ytterligare. \[ y = X \beta + \epsilon \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;QUICKGUIDE:&lt;/strong&gt; – en guide för formelsamlingsägare: 1. Beräkna \( \beta^* \). 2. Beräkna \( s^2 = \frac{Q_0}{n-(p+1)} \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TIPS:&lt;/strong&gt; – för dig som vill bli regressiv king&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Välj många olika kombinationer&lt;/strong&gt; av \( x_{ij} \). – Om alla \( x_{ik} \) är samma kommer normalekvationen sakna entydlig lösning eftersom normalen då balanserar på en linje av mätdata och och inte är utspridd över axeln tillhörande \( x_{ik} \).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Håll koll på (n - (p + 1))&lt;/strong&gt; – då summan återkommer i variansskattning och som antal frihetsgrader till t-fördelningen. &lt;strong&gt;p&lt;/strong&gt; är antalet olika x-variabler och därav också antalet x-dataserier med &lt;strong&gt;n&lt;/strong&gt; värden i varje serie.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">2018-08-13-Sannolikhetsteori_och_statistikteori DEL 1: Sannolikhet eller hur man beskriver slumpen utfall – resultatet av ett slumpmässigt försök utfallsrummet – mängden möjliga utfall händelse – samling utfall relativ frekvens – kvoten mellan antalet erhållet utfall och hela antalet utförda kast disjunkta händelser – kan inte inträffa samtidigt Kolmogorovs axiomsystem Händelsen P(A) måste ligga mellan 0 &amp;amp; 1 P(utfallsrummet) = 1 om A &amp;amp; B är parvis oförenliga gäller \( P(A) + P(B) = P(A \cup B) \) komplementsatsen P(A*) = 1 - P(A) Additionssatsen P(A or B) = P(A) + P(B) - P(A and B) oberoende händelser – \( P(A \cap B) = P(A)P(B) \) Booles olikhet – \( P(A \cup B) \leq P(A) + P(B) \) De morgans lagar – bra att veta att även boolsk algebra är distributiv. \[ A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \] \[ A \cap (B \cup C) = (A \cap B) \cup (A \cap C) \] Kombinatorik Förutsättningar: n element k av dessa plockas Klassiska sannolikhetsdefinitionen Vid likformigt sannolikhetmått är sannolikheten för en händelse lika med kvoten mellan antalet för händelsen gynsamma fall och antalet möjliga fall. Dragning med återläggning och hänsyn till ordning \[n^k\] Dragning utan återläggning med hänsyn till ordning \[n*(n-1)(n-2) \cdots (n-k)\] Dragning utan återläggning utan hänsyn till ordning \[\binom{n}{k}\] Dragning utan återläggning Urna med kulor av två olika färger. Hur stor är chansen att erhålla k vita? Enl. __Klas. sann._ ges svaret av \[ g/m \] \[ m = \binom{v+s}{n} \] \[ g = \binom{v}{k} \binom{s}{n-k} \] Alltså produkten av sätten att få k stycken vita och alla möjligheter att få resterande svarta. Dragning med återläggning Samma som ovan men med återläggning. \[ m = (v+s)^n \] \[ g = \binom{n}{k} v^k s^{n-k}\] Alltså antalet olika kombinationer det finns av k stora samlingar bland n multiplicerat med sannolikheten för k vita multiplicerat med n-k svarta. Allt detta dividerat med m. Betingade sannolikheten – sannolikheten att något inträffar givet en annan händelse. \[P(B|A) = \frac{P(A \cap B)}{P(A)}\] Ger alltså ett samband mellan betingning och snitt. Lagen om total sannolikhet – genom att summera de olika produkter som ges av sannolikheten för varje möjligt utfall \( H_i \) multiplicerat med sannolikheten att A händer om vi faktiskt fått \( H_i \) får vi den totala sannolikheten att A händer. \[P(A) = \sum_{i=1}^{n} P(H_i)P(A|H_i)\] Bayes sats – när man behöver vända på en betingad sannolikhet. Nämnaren i bråket är alltså högerledet i lagen om total sannolikhet. \[P(H_i|A) = \frac{P(H_i)P(A|H_i)}{\sum_{j=1}^{n} P(H_j)P(A|H_j)}\] Oberoende händelser – \( P(B|A) = P(B) \) sannolikheten att minst en inträffar \[A_1 , A_2 , … , A_n \text{ är oberoende }, \quad P(A_i)=p_i\] \[1-(1-p_1)(1-p_2)…(1-p_n) = 1-(1-p)^n\] 1. Endimensionella stokastiska variabler Den stokastiska variabeln är bron mellan matematiken och slumpen men är inget mer än en reellvärd funktion definierad på ett utfallsrum. Betecknas i texten som versaler från slutet av alfabetet som X, Y, eller Z. diskret stokastisk variabel En s.v. är __diskret_ om den kan anta ett ändligt eller uppräkneligt oändligt antal olika värden. funktionen över värdemängden kallas sannolikhetsfunktionen. Enpunktsfördelning – all massa i ett värde \[p_X(a) = 1\] Tvåpunktsfördelning – om X endast antar två värden a &amp;amp; b med sannolikheterna p respektive 1- p. ex: krona/klave då X tar värdena a = 1 och b = 0 sägs X vara Bernoulli-fördelad. Likformig fördelning – X antar värden 1,2,..,m och alla dessa med samma sannolikhet. \[p_X(k)=1/m, k = 1,2,…,m.\] För-första-gången-fördelning – När samma oberoende försök görs om och om tills ett visst resultat erhålls. Antalet försök t.o.m. resultatet är då en s.v. med ffg-fördelning. \[ p_X(k)=(1-p)^{k-1}p, k=1,2,…,\] \[ X \in ffg(p) \] Geometrisk fördelning – genom att skippa resultatrundan som räknas in i ffg-fördelningen tillhör X Ge(p). \[p_X(k) = (1 - p)^kp, k = 0,1,2,…,\] Binomialfördelning – slumpmässigt försök med en händelse A där P(A) = p upprepas n oberoende ggr. \[ p_X(k) = \binom{ n }{ k } p^k ( 1 - p )^{ n - k } \] \[ X \in Bin(n,p) \] Hypergeometrisk fördelning – uppträdde vid dragning utan återläggning ur urna med vita och svarta kulor. \[ p_X(k) = \frac{\binom{v}{k} \binom{s}{n-k}}{\binom{v+s}{n}}\] \[ X \in Hyp(N,n,p)\] Poisson-fördelning – beskriver antalet företelser som inträffar oberoende av varandra. \[ p_X(k) = \frac{ \mu^k }{ k! }e^{ -e } \] \[ X \in Po(\mu)\] kontinuerlig stokastisk variabel Sannolikhetsfunktionen kallas nu täthetsfunktion och betecknas med f. Likformig fördelning – X antar alla värden mellan a och b med samma sannolikhet \[ f_X(x) = 1/(b-a) \text{ om } a &amp;lt; x &amp;lt; b &amp;gt;\] Exponentialfördelning – beskriver tiderna mellan händelserna i en poissonprocess. \[ f_X(x) = \lambda e^{-\lambda x} \quad E(X) = 1 / \lambda, \quad D(X) = 1 / \lambda \] Normalfördelningen Weibull-fördelning Gammafördelning fördelningsfunktion – Funktion som för varje möjligt utfall beräknar sannolikheten att utfallet blir just detta eller lägre. funktioner av stokastisk variabel – När man vill veta hur en s.v., Y som beror av g(x), ser ut. Nedan följer generellt tillvägagångssätt för att beskriva \( f_y (y) \) i termer av den kända \( f_x (y) \). Med exemplet: \( g(x) = |X| \) Beskriv: \( F_y (y) = P( Y \leq y) \) Byt ut Y mot g(X): \( P( g(X) \leq y) \) Lös ut X: \( P( -y \leq X \leq y) = F_X (y) - F_X (-y) \) \(f_Y (y) = f_X (y) + f_X (-y) \) intensitet 2. Flerdimensionella stokastiska variabler Note to self: \[ p_{X,Y}(i,j) = p_X(i)p_Y(j) = P(j|i)P(i) \] OBS! Dont forget the last P(i) Största och minsta värdet Z = max(X,Y) \[F_Z(z) = F_X(z)F_Y(z)\] Z = min(X,Y) \[F_Z(z) = 1-[1-F_X(z)][1-F_Y(z)]\] Gör först om till fördelningsfunktion om täthetsfunktion Summan av s.v. \[f_Z(z) = \int_{\infty}^{\infty} f_X(x)f_Y(z-x)dx\] 3. Väntevärden Note to self: konstanter inuti väntevärdesfunktioner ser dumt ut så flytta ut dem. Väntevärdet/E(X)/μ Är ett typ av lägesmått, precis som medianen. E(X) är väntevärdet för X. E(X) berättar om vad det väntade (__E__xpected) resultatet blir. DEF: \[ E(X) = \sum_kkp_X(k) \] \[ E(X) = \int\limits_{-\infty}^{\infty} x f_X(x)dx \] Y = g(X) – Väljer du att interfacea funktionen med en ny variabel som beror av X med samma gamla fördelning så kan man trixa enl. följande \[ E(Y) = \sum_kg(k)p_X(k)\] \[ E(X) = \int\limits_{-\infty}^{\infty} g(x) f_X(x)dx \] \[ E(X+Y) = E(X)+E(Y) \] X &amp;amp; Y oberoende \[ E(XY) = E(X)E(Y)\] Samling X med samma väntevärde µ \[ E(\sum_{i=1}^n X_i)=n\mu \] Betingade väntevärden \[ E(X|Y=k) = \sum_{j=0}^\infty jp_{X|Y=k}(j)\] \[ E(X|Y=y) = \int_{-\infty}^\infty xf_{X|Y=y}(x)dx\] Variansen/V(X)/σ² Variansen är en typ av spridningsmått. Vid beräkning av varians av en summa olika s.v. bör man ALDRIG anta att inblandade s.v. är oberoende. GLÖM MED ANDRA ORD INTE KOVARIANSEN. DEF: \[ V(X) = E[(X-\mu)^2] \] Schysta satser: \[ V(X) = E(X^2)-[E(X)]^2 \] \[ V(aX+b) = a^2V(X) \] \[ V(X + Y) = V(X) + V(Y) + 2C(X,Y) \] Om oberoende: \( V(X + Y) = V(X) + V(Y) \) Om oberoende och med samma σ: \( V(\sum_{i=1}^nX_i) = n\sigma^2 \) Om oberoende och med samma σ samt µ: \( V(\bar{X})=\sigma^2/n \) Tänk på att använda formelsamlingen för att snabbt fastställa variansen för de olika fördelningarna. Standardavvikelse D(X) eller σ Schyst mått då man får samma dimension som väntevärdet \[ D(X) = \sqrt{V(X)} \] \[ D(aX + b) = |a|D(X) \] Om oberoende: \[ D(X + Y) = \sqrt{D^2(X) + D^2(Y)} \] Variationskoefficienten uttrycks i procent \[ R(X) = D(X)/E(X) \] fel systematiskt fel/bias är differansen mellan mätvärdets väntevärde och det korrekta värdet. (ett tal) slumpmässigt fel menas differensen mellan mätvärdet och dess väntevärde. (s.v. med E(X) = 0) Beroendemått Kovarians Kovariansen C(X,Y) mellan X &amp;amp; Y bör bli positiv om det finns ett beroende sådant att det finns en tendens hos variablerna att samtidigt avvika åt samma håll från sina väntevärden. \( C(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] \) \( C(X,Y) = E(XY)-E(X)E(Y) \) Om C(X,Y) = 0 är X och Y okorrelerade. \( X \text{ &amp;amp; } Y \text{ oberoende} \to \text{okorrelerade} \) Korrelationskoefficienten DEF: \[ \rho(X,Y) = \frac{C(X,Y)}{D(X)D(Y)} \] Kovarians fast dimensionslös Stora talens lag Ju fler oberoende s.v. med samma µ desto närmre kommer medelvärdet att gå mot µ. Betingade väntevärden och varianser Gauss approximationsformler Har du någonsin känt dig inkapabel? Då är taylorutveckling något för dig! Allt för ofta vill man ha en schyst funktion mitt i väntevärdet men hur räknar man ut E(Y) då!? Du behöver inte vara helt körd i skallen, det kan vara så att du råkat ut för någon av de många fallgropar som kantar väntevägen! En variabel taylorutveckla: \[ g(X) \approx g(\mu) + (X - \mu)g’(\mu) \] g(X) har nu approximativa väntevärdet g(µ) samt [g’(E(X))]²V(X) som varians. Med en rak linje blir det enkelt att räkna med µ och σ². Flera variabler Abandon all hope, ye who enter here taylorutveckla: \[ g(X,Y) \approx g(\mu_X,\mu_Y)+(X-\mu_X)g’_X(\mu_X,\mu_Y)+(Y-\mu_Y)g’_Y(\mu_X,\mu_Y) \] 4. Normalfördelningen Notes to self: ca en tredjedel av massan hamnar utanför en standardavvikelse. normalfördelningar bevaras alltid under linjära transformationer \[ f_X(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \] Standardiserad fördelning Täthetsfunktion: φ Fördelningsfunktion: Φ \[ \Phi(-x) = 1 - \Phi(x) \] Allmän fördelning \[ X \in N(\mu,\sigma) \quad iff \quad Y = (X-\mu)/\sigma \in N(0,1) \] \[ f_X(x) = \frac{1}{\sigma}\varphi(\frac{x-\mu}{\sigma}) \] \[ F_X(x) = \Phi(\frac{x-\mu}{\sigma}) \] Linjärkombinationer Om \[ X \in N(\mu,\sigma) \] så gäller att \[ Y=aX+b \in N(a\mu + b, |a|\sigma) \] Om \[ X_1,X_2,..,X_n \] är oberoende N(µ,σ) och \[ \bar{X} \] är medelvärdet så gäller att \[ \bar{X} \in N(\mu,\sigma/\sqrt{n}) \] 5. De tre vännerna och Binomialfördelning binomialaren (fördelningen med återläggning) E(X) = np V(X) = npq Om oberoende \[ X \in Bin(n_1,p) \quad \&amp;amp; Y \in Bin(n_2,p) \] \[ X + Y \in Bin(n_1+n_2,p) \] Obs! Glöm inte att Binomialfördelningen är diskret, håll därför koll på gränserna (&amp;gt; != &amp;gt;=) Kan approximeras till poissonfördelning – om p är litet normalfördelning – om npq &amp;gt; 10 kan man approximera med N(np,sqrt(npq)). Resultatet blir noggrannare om man vid beräkning av fördelningsfunktion adderar 1/2 till gränsen/gränserna. Skillnad mellan två binomialfördelade s.v. approximeras till \[ Y_1 - Y_2 \in N(p_1 - p_2, \sqrt{ \frac{p_1 (1-p_2)}{n_1} + \frac{ p_2 (1- p_1)}{n_2}} ) \] Hypergeometriske (utan återläggning) E(X) = np V(X) = ((N-n)/(N-1))np(1-p) Kan aproximeras som binomialapproximation om n/N är liten normalapproximation om n är stort Poisson-fördelningen E(X) = µ V(X) = µ \[ X_1 \in Po( \theta_1 ) \quad and \quad X_2 \in Po( \theta_2 ) \quad then \quad X_1+X_2 \in Po(\theta_1+\theta_2) \] Kan approximeras som normalfördelning om µ är stort Multinomial Markovkedjor Stokastiska processer vars nästa värde endast beror på nuvarande värde. övergångsmatris används för att skriva upp “hoppsannolikheterna”. övergångssannolikheter av N:te ordningen härleds genom att matrismultiplicera övergångsmatrisen med sig själv n ggr. alltså sannolikheten att mellanlanda i ett tillstånd. För att simulera sannolikheterna att systemet börjar i de olika tillstånden används matrismultiplikation med en radvektor \[ p^{(0)}=(p_1^{(0)},p_2^{(0)},...) \] \[ \begin{pmatrix} 1 &amp;amp; 2 \end{pmatrix} * \begin{pmatrix} 1to1 &amp;amp; 1to2 \\ 2to1 &amp;amp; 2to2 \end{pmatrix} \] terminologi tillstånd – markovkedja är alltid i ett tillstånd. Den lämnar detta enl. övergångsmatrisen ändlig – ändligt antal tillstånd i kedjan beständigt – om tillstånd där \( p_{ii} = 1 \) (Gäller alla olika ordningars övergångsmatriser) kolla första ordningens sannolikhet att kedjan väljer att hoppa till tillståndet det redan var i, sedan andra ordningens och tredje ordningens. Fortsätt tills du hittat ett samband mellan sannolikheterna, ex. i form av en geometrisk serie. Blir summan 1 har du ett beständigt tillstånd. Använd sedan faktumet att om två tillstånd kommunicerar tvåsidigt är de båda antinge beständiga eller båda inte Använd sedan faktumet att om alla \( p_{ij} = 0 \) så är j inte beständigt (går ju inte att komma dit (om man inte börjar där men inte sedan kan man ändå inte komma dit igen)). obeständigt – tillstånd om P(i-&amp;gt;i) less than 1 Om två tillstånd kommunicerar tvåsidigt är de båda antingen beständinga eller inte. irreducibel – om alla tillstånd kommunicerar tvåsidigt med varandra, indirekta anslutningar räknas också. rita upp markovkedjan och följ pilarna stationär fördelning – sannolikheterna att systemet befinner sig i de olika tillstånden. skapa sannolikhetsvektorn \( \pi = ( \pi_1, \pi_2,..) \) lös ekv. \( \pi = \pi P \) (P är övergångsmatrisen) \[ p^{(n)}=( p_1^{(n)}, p_2^{(n)} ,…) \to \pi, \quad \text{ när } n \to \infty \] asymptotisk fördelning – om man i en ändlig kedja kan finna ett \( r&amp;gt;0 \) så beskaffat att alla element i någon kolonn i matrisen P^r är positiva, existerar det en asymptotisk fördelning periodiska tillstånd – om det alltid krävs ett visst antal hopp för att komma tillbaka till ett tillstånd är tillståndet periodiskt. t.ex. om processen bara kan nå tillbaka till Ei efter 3,6,9,… steg har Ei perioden 3. aperiodiska tillstånd – om det alltid går att komma tillbaka till ett tillstånd direkt.. DEL 2: Statistik eller vilka slutsatser man kan dra av ett datamaterial terminologi parameterrummet – de värden den sökta parametern kan tänkas anta. stickprov – betecknas med lilla x = (x1,x2,…,xn) för n dimensionella s.v. stickprovsvariansen – \( s^2 = \frac{1}{n-1} \sum_{j=1}^n (x_j - \bar{x})^2 \) kovariansen – mellan x- och y-värdena i en datamängd \( ( x_1 , y_1 ),( x_2 , y_2 ),…,( x_n , y_n ) \) \[ c_{xy} = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) \] korrelationskoefficienten – \( r = \frac{c_{xy}}{s_xs_y} \) 7. Punktskattning Lär dig uppskatta saker! punktskattning – den observerade sannolikheten – ett utfall av stickprovsvariabeln \[ \theta_{obs}^*(x_1,x_2,…,x_n) \] stickprovsvariabeln – en s.v. som punktskattningen är ett utfall av \[ \theta^*(X_1,X_2,…,X_n) \] väntevärdesriktig – punktskattning vars tillhörande stickprovsvariabel har väntevärdet θ. dvs om \[ E(\theta^*) = \theta \] MSE – mean square error – medelkvadratfelet för en punktskattning – mått på slumpmässigt fel \[ MSE = E(( \theta^* - \theta)^2) \] effektiv skattning – om variansen för \( V( \theta^* ) \leq V( \hat{\theta} ) \) så är \( \theta^* \) effektivare än den andra. Skattning av μ &amp;amp; σ µ – stickprovsmedelvärdet \[ \bar{x} \] är en väntevärdesriktig och konsistent skattning av µ och gäller för alla fördelningar σ^2 – stickprovsvariansen s^2 är en väntevärdesriktig skattning av σ^2 som gäller för alla fördelningar och ser ut så här om μ är känd \[ \frac{ 1 }{ n } \sum_i^n (x_i - \mu)^2 \] Annars skattas μ med medelvärdet av mätdata och man får efter lite väntevärdesriktighetsjustering \[ \frac{ 1 }{ n - 1 } \sum_i^n (x_i - \bar{x})^2 \] Skattningsfunktioner Maximum-likelihood-metoden – ML-metoden – Om man vill skatta en parameter till en täthets/sannolikhetsfunktion. Genom att sätta in varje mätdata i sin sannolikhetsfunktion och sedan multiplicera alla dessa får vi sannolikheten att utfallen blev just mätdatan. Vi utnyttjar nu att sannolikhetsfunktionen är som störst när avståndet mellan väntevärdet och mätdatan är som minst genom att derivera över den okända parametern och söka maxpunkt. Skapa \[ L(\theta) = P(X_1 = x_1, X_2 = x_2,…,X_n = x_n;\theta) \] alt. \[ L(\theta) = f_{X_1,X_2,…,X_n}(x_1,x_2,…,x_n;\theta) \] (A.k.a. likelihood-funktionen) Finn funktionens maxpunkt genom ex. derivering över theta. Funktionens största värde är det mest sannolika scenariot. Minsta-kvadrat-metoden – MK-metoden – Om man vill skatta en parameter till en täthets/sannolikhetsfunktion. När man vet hur parametern förhåller sig till mätdatan kan man ställa upp en summa där varje term motsvarar \( (x_i - g( \theta ) )^2 \). Genom att finna derivatans minimum får vi reda på det värde på θ som gör differanserna så små som möjligt. Så hur går man då tillväga? Jo genom att skapa funktionen \( Q( \theta )) \) och sedan derivera denna och finna minimum för \[ Q(\theta) = \sum_{i=1}^n [x_i - \mu_i (\theta)]^2 \] \[ \frac{dQ}{d \theta} Q( \theta ) \] Viss mätdata sämre än resten? Använd vikter framför termerna i \( Q ( \theta ) \) så att de sämre mätningarna får mindre betydelse. Flera parametrar? Lös partialderivatorna och sedan ekvationssystemet. Normalfördelningen Två stickprov med samma σ – M.h.a. ML-skattning får vi som väntat \( ( \mu_1 ){obs}^* = \bar{x} \) samt \( \mu_2 ){obs}^* = \bar{y} \). variansen, å andra sidan, skattas av \[ s^2 = \frac{ \sum_{i_1}^{n_1} (x_i - \bar{x} )^2 +\sum_{i_1}^{n_2} (y_i - \bar{y} )^2 }{ (n_1 - 1 ) + (n_2 - 1 ) } \] n stickprov med samma σ – En skattning som gäller oavsett hur många stickprov man blandar in ges av \[ s^2 = \frac{ Q_1 + … + Q_n }{ (n_1 - 1) + … + (n_2 - 1) } \] \( Q_i \) är kvadratsumman kring medelvärdet. 8. Intevallskattning När man vill veta hur stor sannolikhet det är att en okänd parameter ligger inom ett visst interval. Tillämpning på normalfördelningen Ett stickprov µ okänd σ känd \[\mu* = \bar{x} \] μ känd σ okänd \[ (\sigma^2)_{obs}^* = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2 \] Konfidensintervall för väntevärdet σ känd En lämplig skattning av µ är aritmetiska medelvärdet av X. \[ \bar{X} \in N(\mu,D) \] \[ D = \sigma/\sqrt{n} \] \[ I_\mu = (\bar{x}-\lambda_{\alpha/2}D,\bar{x}+\lambda_{\alpha/2}D) \] Allt detta följer av att: \[ \frac{\bar{X}-\mu}{D} \in N(0,1) \] Följaktligen gäller med sannolikheten 1-alfa att: \[ -\lambda_{\alpha/2} &amp;lt; \frac{\bar{X}-\mu}{D} &amp;lt; \lambda_{\alpha/2} &amp;gt;\] Om vi har ett intervall: \[ I_\mu = (16 \pm 2.58 * 0.155) \] där \[ D = 1.2/\sqrt{60} = 0.155 \] och man istället vill ha en mindre standardavvikelse, säg 0.5, så kan man sätta upp följande ekvation: \[ 2 * 2.58 * 1.2/\sqrt{n} = 0.5 \] σ okänd I detta fallet gäller en helt galen lösning eftersom man behöver skatta σ \[ I_\mu = (\bar{x}-t_{\alpha/2}(f)d,\bar{x}+t_{\alpha/2}(f)d) \] \[ d = s/\sqrt{n}, \quad f = n-1 \] Konfidensintervall för standardavvikelsen μ känd Aint gonna happen gurl μ okänd \[ I_\sigma = (k_1s,k_2s) \] \[ k_1 = \sqrt{(f/\chi_{\alpha/2}^2(f)} \] \[ k_2 = \sqrt{(f/\chi_{1-\alpha/2}^2(f)} \] \[ f = n-1 \] Två stickprov När man vill mäta skillnaden mellan två stickprov. Om de två stickproven parvis korrelerar bör metoden tillhörande stickprov i par användas. Om σ1 och σ2 är kända: \[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-\lambda_{\alpha/2}D,\bar{x}-\bar{y}+\lambda_{\alpha/2}D) \] \[ D = \sqrt{ \sigma_{1}^{2} / n_1 + \sigma_{2}^{2} / n_2} \] Om σ1 = σ2 = σ: \[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-t_{\alpha/2}(f)d,\bar{x}-\bar{y}+t_{\alpha/2}(f)d) \] \[ d = \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2}} \] Stickprov i par När det utförs två mätningar på n olika objekt, t.ex. före och efter något har hänt. Då alla objekt kan skilja sig åt är det svårt att göra skattningar om de enskilda objekten men på samma gång perfekt läge för att skatta skillnaden mellan mätningarna. Skapa \( z = y - x \) och använd z för skattning av standardavvikelse. 9. Hypotesprövning nollhypotes – hypotesen att det inte föreligger något fenomen som kräver en förklaring. Betecknas: \( H_0 \) mothypotes – hypotes som kan vara sann om inte nollhypotesen är det. Betecknas: \( H_i \) signifikansnivå/felrisk – sannolikheten att nollhypotesen förkastas trots att den är sann. (Ju lägre desto bättre). signifikant* – 0.05 signifikant** – 0.01 signifikant*** – 0.001 testvariabel/teststorhet – observation av stickprovsvariabel. Tackvare normalapproximation lämpar sig ofta testvariabler på formen \( ( \theta^* - \theta_0 )/D \). Där \( \theta^* \) är det skattade väntevärdet, \( \theta_0 \) är väntevärdet som gäller för nollhypotesen och \( D \) är standardavvikelsen för skattningen. signifikanstest 1. Om \(t_{obs} \in \text{jätteosannolikt område} \) förkasta \( H_0 \) 2. Om \( t_{obs} \) å andra sidan är ett sannolikt utfall, även i vanliga fall så bör \( H_0 \) inte förkastas. direkt- och P-värdesmetoden – anta \( H_0 \) och beräkna sannolikheten att man får det utfall man fått eller något värre. “Värre” betyder alla utfall som är ännu mindre sannolika om \( H_0 \) stämmer. konfidensmetoden – genom att beräkna konfidensintervall för variabel och sedan förkasta nollhypotesen om värdet hamnar utanför. Testkvantitet – använd testvariabel och tabell och se om testvariabeln är större eller mindre än en viss α-kvantil. styrkefunktionen \( h(\theta) = P(H_0 \text{ förkastas}) \) om θ är det rätta värdet. bör vara stort för alla θ som tillhör mothypotesen bör vara litet för alla θ som tillhör nollhypotesen h(θ) kallas testets styrka för θ How to styrkefunktion \( X \in N( \theta, 0.04) \) Antag \( H_0: \theta = 2.0 \) och sätt upp villkoret för att förkasta \( H_0 \). e.g. \( | X - 2.0 | \geq 0.04 \lambda_{0.025} \) Skapa nu styrkefunktionen \(h(\theta) = P(| X - 2.0 | \geq 0.04 \lambda_{0.025}) = 1 - P(-0.04 \lambda_{0.025} \leq X - 2.0 \leq 0.04 \lambda_{0.025}) \). Denna duger inte än eftersom den inte beror av θ. Då styrkefunktionen alltså går ut på att få se sannolikheten att \( H_0 \) förkastas när \( E(X) = \theta \) antar vi att \( E(X) = \theta \) och bildar variabelbytet \( u = \frac{X - \theta}{0.04} \) för att kunna använda den standardiserade normalfördelningen. Via enklare räkning byter vi ut \( (X - 2.0)/D \) mot (\( u \) och kan då använda den standardiserade nomralfördelningens fördefördelningsfunktion \[ h( \theta ) = 1 - \Phi ( \lambda_{0.025} + \frac{2.0 - \theta}{0.04}) + \Phi (- \lambda_{0.025} + \frac{2.0 - \theta}{0.04}) \] 10. Regressionsanalys När man vill se samband mellan två eller flera storheter. observera! Använd alltid t-fördelningen när standardavvikelsen blivit skattad. Icke linjära samband – Logaritmera \[ y_i = c e^{\beta_{t_i}} \epsilon_i \] \[ ln y_i = ln c + \beta t_i + ln \epsilon_i \] Glöm nu inte att använda \( ln y_i \), alltså inte \( y_i \). Samma gäller alla sådana termer. Terminologi teoretiska regressionslinjen \[ y = \alpha + \beta x \] parameterskattningar \[ \sum x_i , \quad \sum x_i^2 , \quad S_{xx} = \sum_{i=1}^n (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 - \frac{1}{n} (\sum_{i=1}^n x_i)^2 \] \[ \sum y_i , \quad \sum y_i^2 , \quad S_{yy} = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 - \frac{1}{n} (\sum_{i=1}^n y_i)^2 \] \[ \sum x_i y_i , \quad S_{xy} = \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y}) = \sum_{i=1}^n x_i y_i - \frac{1}{n} (\sum_{i=1}^n x_i) (\sum_{i=1}^n y_i) \] Punktskattningar Remember MK-metoden? Bestäm minimum för \[ Q( \alpha , \beta ) = \sum_{i}^n (y_i - \mu_i)^2 \] \[ \mu_i = \alpha + \beta x_i \] Genom att sätta partialderivatorna till noll fås \[ \beta^* = \frac{S_{xy}}{S_{xx}} \quad \alpha^* = \bar{y} - \beta^* \bar{x} \] \[ ( \sigma^2 )^* = s^2 = \frac{Q_0}{n-2}, \quad Q_0 = S_{yy} - S_{xy}^2 / S_{xx} \] Observera att \[ \mu_0^* = \alpha^* + \beta^* x_0 \in N( \alpha + \beta x_0 , \sigma \sqrt{ \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}}) \] Intervallskattningar Prediktionsintervall för observationer – När man vill göra ett konfidensintervall för framtida observationer av \( Y \) för \( x = x_0 \) Kalibreringsintervall – Då man erhållit värde \( y_0 \text{ på } y \), vad blir då \( x_0 \) Stokastiska vektorer stokastisk vektor – Kolonnvektor vars element är stokastiska variabler. Den kan alltså representera en n-dimensionell stokastisk variabel. \[ X = [X_1,…,X_n]^T \] väntevärdesvektorn – Elementvis beräknade väntevärden för \( X \) kovariansmatrisen – Också en funktion på \( X \). Denna genererar \( C(X_i,X_j) \) på \( X_{ij} \). Då \( C(X,X) = V(X) \) hittar man varianser för de olika s.v. på diagonalelementen. Multipel regression För stilrenhet döps \( \alpha \) om till \( \beta_0 \). \[ y_i = \beta_0 + \beta_1 x_{i1} + … + \beta_k x_{ik} + \epsilon_i, \quad i=1,…,n \] Skriv modellen på matrisform för att generalisera ytterligare. \[ y = X \beta + \epsilon \] QUICKGUIDE: – en guide för formelsamlingsägare: 1. Beräkna \( \beta^* \). 2. Beräkna \( s^2 = \frac{Q_0}{n-(p+1)} \) TIPS: – för dig som vill bli regressiv king Välj många olika kombinationer av \( x_{ij} \). – Om alla \( x_{ik} \) är samma kommer normalekvationen sakna entydlig lösning eftersom normalen då balanserar på en linje av mätdata och och inte är utspridd över axeln tillhörande \( x_{ik} \). Håll koll på (n - (p + 1)) – då summan återkommer i variansskattning och som antal frihetsgrader till t-fördelningen. p är antalet olika x-variabler och därav också antalet x-dataserier med n värden i varje serie.</summary></entry><entry><title type="html">Emacs cheat sheet</title><link href="http://localhost:4000/2018/07/20/Emacs_shortcuts.html" rel="alternate" type="text/html" title="Emacs cheat sheet" /><published>2018-07-20T00:00:00+02:00</published><updated>2018-07-20T00:00:00+02:00</updated><id>http://localhost:4000/2018/07/20/Emacs_shortcuts</id><content type="html" xml:base="http://localhost:4000/2018/07/20/Emacs_shortcuts.html">&lt;ul&gt;
  &lt;li&gt;C-l – center the line of the cursor&lt;/li&gt;
  &lt;li&gt;C-v – one screen down&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M-v – one screen up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;C-p – previous line&lt;/li&gt;
  &lt;li&gt;C-n – next line&lt;/li&gt;
  &lt;li&gt;C-f – forward one char&lt;/li&gt;
  &lt;li&gt;C-b – backward one char&lt;/li&gt;
  &lt;li&gt;M-f – forward one word&lt;/li&gt;
  &lt;li&gt;M-b – backward one word&lt;/li&gt;
  &lt;li&gt;C-a – beginning of line&lt;/li&gt;
  &lt;li&gt;C-e – end of line&lt;/li&gt;
  &lt;li&gt;M-a – beginning of sentence&lt;/li&gt;
  &lt;li&gt;M-e – end of sentence&lt;/li&gt;
  &lt;li&gt;M-&amp;lt; – beginning of text&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M-&amp;gt; – end of text&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;C-u [n] [command] – do command n times&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;C-g – stop emacs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Windows&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-x 1 – one window - kill all others&lt;/li&gt;
  &lt;li&gt;C-x 2 – two windows - open another&lt;/li&gt;
  &lt;li&gt;C-x o – go to Other window&lt;/li&gt;
  &lt;li&gt;C-M-v – scroll text in other window&lt;/li&gt;
  &lt;li&gt;C-x 3 – vertical window??&lt;/li&gt;
  &lt;li&gt;C-x 4 C-f – file in new window&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Frames&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-x 5 2 – two frames&lt;/li&gt;
  &lt;li&gt;C-x 5 0 – removes selected frame&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deletion&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;backspace – delete char before cursor&lt;/li&gt;
  &lt;li&gt;C-d – delete char under cursor&lt;/li&gt;
  &lt;li&gt;M-backspace – delete word before cursor&lt;/li&gt;
  &lt;li&gt;M-d – delete word under the cursor&lt;/li&gt;
  &lt;li&gt;C-k – kill from cursor to end of line&lt;/li&gt;
  &lt;li&gt;M-k – kill to end of the current sentence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OBS
killing = cutting
yanking = pasting&lt;/p&gt;

&lt;p&gt;Marking&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-&lt;SPC&gt; -- set marker&lt;/SPC&gt;&lt;/li&gt;
  &lt;li&gt;C-w – kills all in marker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;pasting&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-y – yanks back the text killed. C-k’s accumulates.&lt;/li&gt;
  &lt;li&gt;M-y – cycles through earlier kills.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Undo&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-/ – undo last action&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Files&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-x C-f – open file&lt;/li&gt;
  &lt;li&gt;C-x C-s – saves file&lt;/li&gt;
  &lt;li&gt;C-x C-b – list all buffers&lt;/li&gt;
  &lt;li&gt;C-x b – go to some buffer&lt;/li&gt;
  &lt;li&gt;C-x s – save som buffers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kill emacs&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-x C-c – kills emacs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;M-x commands&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;M-x replace-string&lt;/li&gt;
  &lt;li&gt;M-x recover-this-file
*
Autosaving saves in a different file (if computer crashes) – so dont worry ‘bout overwriting&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Major modes&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;M-x modename
Minor modes&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M-x auto-fill-mode – toggles&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;M-q fills the paragraph – no empty space&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Searching&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C-s forward search&lt;/li&gt;
  &lt;li&gt;C-r backward search
*&lt;/li&gt;
&lt;/ul&gt;

&lt;ESC&gt; &lt;ESC&gt; &lt;ESC&gt; -- general get out command

Help
C-h command will display help
C-h c command will display brief help

Help
C-h command will display help
C-h c command will display brief help
&lt;/ESC&gt;&lt;/ESC&gt;&lt;/ESC&gt;</content><author><name></name></author><summary type="html">C-l – center the line of the cursor C-v – one screen down M-v – one screen up</summary></entry><entry><title type="html">Regular expressions - a concise guide</title><link href="http://localhost:4000/2018/06/07/RegExp.html" rel="alternate" type="text/html" title="Regular expressions - a concise guide" /><published>2018-06-07T00:00:00+02:00</published><updated>2018-06-07T00:00:00+02:00</updated><id>http://localhost:4000/2018/06/07/RegExp</id><content type="html" xml:base="http://localhost:4000/2018/06/07/RegExp.html">&lt;h4 id=&quot;anchors&quot;&gt;Anchors&lt;/h4&gt;
&lt;p&gt;^ and $
Anchors are used to define locations within the line. “^A” will match all lines beginning with an “A” while “A$” will match all lines ending with an A. Note that “^” must be the first symbol of the regex, just as “$” has to be last.&lt;/p&gt;

&lt;h4 id=&quot;character-sets&quot;&gt;Character Sets&lt;/h4&gt;
&lt;p&gt;These define whole sets of characters to match. for instance “[abcdefg]” will look out for any of the chars “a-g”.&lt;/p&gt;

&lt;p&gt;As a matter of fact it is possible to use ranges just like this [a-z].&lt;/p&gt;

&lt;p&gt;Negation is done by adding a “^” inside the square brackets. [^a-z] would search for anything but a-z.&lt;/p&gt;

&lt;h4 id=&quot;modifiers&quot;&gt;Modifiers&lt;/h4&gt;
&lt;p&gt;When you want to search for multiples of your character set you use modifiers.&lt;/p&gt;

&lt;p&gt;The most common one is “&lt;em&gt;”. This matches with zero or more multiples of the given character set. [0-9]&lt;/em&gt; will find a match anywhere there is zero or more numbers.&lt;/p&gt;

&lt;h5 id=&quot;-and-&quot;&gt;”{” and “}”&lt;/h5&gt;
&lt;p&gt;Next up is “{” and “}”. The reason for their asymmetry can be found in a strive for backwars compability. “{“ &amp;amp; “}” were already in use and so we were left with “{” and “}”. Since this knowledge doesn’t improve our ability to catch regular expressions lets move on to what the symbols mean.&lt;/p&gt;

&lt;p&gt;When a character set needs to be multiplied a specific number of times or a number of times somewhere in a range of numbers.&lt;/p&gt;

&lt;h5 id=&quot;-and--1&quot;&gt;”&amp;lt;” and “&amp;gt;”&lt;/h5&gt;
&lt;p&gt;Say you want to find all matches of “ilsner”. The regex “ilsner” would however also match “pilsner”. searching for “ ilsner “ would fix it but then an instance of ilsner in the beginning or end of a line or sentence would not return a match. “&amp;lt;[iI]lsner&amp;gt;” is the final solution!&lt;/p&gt;

&lt;h5 id=&quot;-and--2&quot;&gt;”(” and “)”&lt;/h5&gt;
&lt;p&gt;Wanting to find occurrences of two identical character sets requires some way of remembering the previous found instance. The regex “([a-z]{4,9})\1” will find any string of 4 to 9 lower case letters that occurs once more directly after itself.&lt;/p&gt;

&lt;h4 id=&quot;extended-regular-expressions&quot;&gt;Extended Regular Expressions&lt;/h4&gt;
&lt;p&gt;Seemingly most programs today suport extended regular expressions.&lt;/p&gt;

&lt;h5&gt;?&lt;/h5&gt;
&lt;p&gt;Matches 0 or 1 instances of the character set.&lt;/p&gt;

&lt;h5 id=&quot;-1&quot;&gt;+&lt;/h5&gt;
&lt;p&gt;Matches one or more copies of the character set.&lt;/p&gt;

&lt;h5 id=&quot;ab&quot;&gt;(a|b)&lt;/h5&gt;
&lt;p&gt;Searches for either a or b.&lt;/p&gt;

&lt;h4 id=&quot;examples&quot;&gt;Examples&lt;/h4&gt;
&lt;p&gt;[a-z]{4,9} will match 4-9 consecutive lower case letters.
[a-z]{4,} will match 4 or more consecutive lower case letters.
[a-z]{4} will match 4 consecutive lower case letters.&lt;/p&gt;</content><author><name></name></author><summary type="html">Anchors ^ and $ Anchors are used to define locations within the line. “^A” will match all lines beginning with an “A” while “A$” will match all lines ending with an A. Note that “^” must be the first symbol of the regex, just as “$” has to be last.</summary></entry><entry><title type="html">Köteori</title><link href="http://localhost:4000/2018/06/02/queuingsystem.html" rel="alternate" type="text/html" title="Köteori" /><published>2018-06-02T00:00:00+02:00</published><updated>2018-06-02T00:00:00+02:00</updated><id>http://localhost:4000/2018/06/02/queuingsystem</id><content type="html" xml:base="http://localhost:4000/2018/06/02/queuingsystem.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;Köteori&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;Köteorin används för att analysera system där kunder och betjänare interagerar. Hur många kunder kommer det i snitt att finnas i systemet? Hur lång tid kommer de ta att betjäna? Är systemet stabilt eller kommer antalet kunder att öka obehindrat?&lt;/p&gt;
&lt;p&gt;För att kategorisera kösystem används ofta en modell “A/B/x”. A är fördelningen mellan ankomster, B motsvarar betjäningstidernas fördelning och x antalet betjänare. Denna konvention saknar dock information om antalet buffertplatser i systemet. Så länge inget annat anges gäller hursomhelst att antalet sådana platser är oändligt.&lt;/p&gt;
&lt;p&gt;A och B antar ofta ett av tre värden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M - exponentialfördelad&lt;/li&gt;
&lt;li&gt;D - deterministisk (konstant)&lt;/li&gt;
&lt;li&gt;G - godtycklig fördelning (men känd)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;olika-kötyper&quot;&gt;Olika kötyper&lt;/h2&gt;
&lt;h3 id=&quot;markovska-köer&quot;&gt;Markovska köer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Beskrivs av &lt;em&gt;markovkedjor&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Alla tider mellan ankomster samt betjäningstider är exponentialfördelade.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?A%28t%29%20%3D%201%20-%20e%5E%7B-%20%5Clambda%20t%7D&quot; alt=&quot;A(t) = 1 - e^{- \lambda t}&quot; title=&quot;A(t) = 1 - e^{- \lambda t}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?B%28x%29%20%3D%201%20-%20e%5E%7B-%20%5Crho%20x%7D&quot; alt=&quot;B(x) = 1 - e^{- \rho x}&quot; title=&quot;B(x) = 1 - e^{- \rho x}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;standardmall-för-beräkning&quot;&gt;Standardmall för beräkning&lt;/h5&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Rita markovkedjan&lt;/li&gt;
&lt;li&gt;Hitta tillståndsfördelningen med snittmtoden&lt;/li&gt;
&lt;li&gt;Beräkna intressanta performanceparametrar&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;E(N)&lt;/li&gt;
&lt;li&gt;E(T)&lt;/li&gt;
&lt;li&gt;P(Spärr)&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda_%20%7Beff%7D&quot; alt=&quot;\lambda_ {eff}&quot; title=&quot;\lambda_ {eff}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;mm1&quot;&gt;M/M/1&lt;/h4&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7BN%7D%20%3D%20%5Cfrac%7B%5Crho%7D%7B1-%5Crho%7D%20%3D%20%5Cfrac%7B%5Clambda%7D%7B%5Cmu-%5Clambda%7D&quot; alt=&quot;\bar{N} = \frac{\rho}{1-\rho} = \frac{\lambda}{\mu-\lambda}&quot; title=&quot;\bar{N} = \frac{\rho}{1-\rho} = \frac{\lambda}{\mu-\lambda}&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;mmm&quot;&gt;M/M/m&lt;/h4&gt;
&lt;p&gt;Skilnaden här är att vi får multiplar av µ eftersom betjäningstiden beror av antalet betjänare. När det finns &lt;em&gt;en&lt;/em&gt; kund i kösystemet kommer betjäningsintensiteten att vara µ. På samma vis blir betjäningsintensiteten 2µ när det finns &lt;em&gt;två&lt;/em&gt; kunder i systemet, o.s.v. upp till m. Detta förändrar vid uträkning av tillständsfördelningen.&lt;/p&gt;
&lt;h4 id=&quot;mm1k---begränsade-köplatser&quot;&gt;M/M/1/K - begränsade köplatser&lt;/h4&gt;
&lt;p&gt;Denna typen av kösystem gör det möjligt att räkna på &lt;em&gt;P(spärr)&lt;/em&gt;. Dessutom är dessa lättare att räkna på eftersom det blir ett finit antal tillständ.&lt;/p&gt;
&lt;h4 id=&quot;begränsat-antal-kunder&quot;&gt;begränsat antal kunder&lt;/h4&gt;
&lt;p&gt;Här förändras λ istället. Det blir i dessa fall smidigt att räkna med λ som en kunds ankomstintensitet. Har man då fem kunder blir alltså intensiteten till första tillståndet 5λ. I detta tillstånd finns endast fyra kunder utanför systemet och därav följer att ankomstintensiteten till nästa tillstånd blir 4λ.&lt;/p&gt;
&lt;h4 id=&quot;begränsat-antal-kunder-och-begränsat-antal-köplatser&quot;&gt;begränsat antal kunder och begränsat antal köplatser&lt;/h4&gt;
&lt;p&gt;I sådan system kombineras helt enkelt kunskaperna om system med begränsade köplatser och system med begränsat antal kunder.&lt;/p&gt;
&lt;h4 id=&quot;mmm-upptagetsystem-erlangsystemet&quot;&gt;M/M/m * upptagetsystem (Erlangsystemet)&lt;/h4&gt;
&lt;p&gt;I dessa system gäller följande: 1. m betjänter 2. inga köplatser 3. ankomsterna är poissonprocess 4. ankomstintensitet är alltid &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; * Bra apporximation om man har många kunder i förhållande till betjänter. * P(spärr) kallas i Erlangsystem för &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E_m%28%5Crho%29&quot; alt=&quot;E_m(\rho)&quot; title=&quot;E_m(\rho)&quot; /&gt; + räknas ut m.h.a. rekursion eller tabeller * avverkad trafik = &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N%29%20%3D%20%5Clambda_%7Beff%7D%20%5Cbar%7Bx%7D%20%3D%20%5Crho%281-E_m%28%5Crho%29%29&quot; alt=&quot;E(N) = \lambda_{eff} \bar{x} = \rho(1-E_m(\rho))&quot; title=&quot;E(N) = \lambda_{eff} \bar{x} = \rho(1-E_m(\rho))&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D%20%3D%20%5Cfrac%7B1%7D%7B%5Crho%7D&quot; alt=&quot;\bar{x} = \frac{1}{\rho}&quot; title=&quot;\bar{x} = \frac{1}{\rho}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?p_k%20%3D%20%5Crho%2Fk%20%5Cfrac%7B%5Crho%5E%7Bk-1%7D%2F%28k-1%29%21%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Cfrac%7B%5Crho%5Ei%7D%7Bi%21%7D%7D%3D%5Cfrac%7B%5Crho%7D%7Bk%7D%20p_%7Bk-1%7D&quot; alt=&quot;p_k = \rho/k \frac{\rho^{k-1}/(k-1)!}{\sum_{i=0}^{m} \frac{\rho^i}{i!}}=\frac{\rho}{k} p_{k-1}&quot; title=&quot;p_k = \rho/k \frac{\rho^{k-1}/(k-1)!}{\sum_{i=0}^{m} \frac{\rho^i}{i!}}=\frac{\rho}{k} p_{k-1}&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;icke-markovska-köer&quot;&gt;Icke-markovska köer&lt;/h3&gt;
&lt;h4 id=&quot;mg1&quot;&gt;M/G/1&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;E(X) går att beräkna eftersom man vet fördelningen&lt;/li&gt;
&lt;li&gt;E(T) är trixigare då den beror på hur många som redan är i systemet&lt;/li&gt;
&lt;li&gt;se formelsamling.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;könät&quot;&gt;Könät&lt;/h3&gt;
&lt;p&gt;Ankomsterna till nod 2 är lika med output från nod 1&lt;/p&gt;
&lt;h6 id=&quot;howto&quot;&gt;HOWTO&lt;/h6&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Ställ upp ankomstintensiteterna som ekvationssystem&lt;/li&gt;
&lt;li&gt;Räkna ut &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_i%29%20%3D%20%5Cfrac%7B%5Crho%20_i%7D%7B1-%5Crho%20_i%7D&quot; alt=&quot;E(N_i) = \frac{\rho _i}{1-\rho _i}&quot; title=&quot;E(N_i) = \frac{\rho _i}{1-\rho _i}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28T_i%29%20%3D%20%5Cfrac%7BE%28N_i%29%7D%7B%5Clambda%20_i%7D&quot; alt=&quot;E(T_i) = \frac{E(N_i)}{\lambda _i}&quot; title=&quot;E(T_i) = \frac{E(N_i)}{\lambda _i}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_%7Bqi%7D%29%20%3D%20E%28N_i%29%20-%20E%28N_si%29%20%3D%20E%28N_i%29%20-%20%5Crho%20_i&quot; alt=&quot;E(N_{qi}) = E(N_i) - E(N_si) = E(N_i) - \rho _i&quot; title=&quot;E(N_{qi}) = E(N_i) - E(N_si) = E(N_i) - \rho _i&quot; /&gt; Dela med lambda för att få medeltid.&lt;/li&gt;
&lt;/ol&gt;
&lt;h6 id=&quot;att-tänka-på&quot;&gt;Att tänka på&lt;/h6&gt;
&lt;p&gt;Om man vill veta hur lång tid det tar för ett paket genom ett nät som passerar en viss nod så summeras de gemensamma noderna samt sannolikheten för det ena alternativet multiplicerat med tiden för den och samma sak för det andra alternativet. Tiden i ett system beror bara på λ in i systemet och E(N) (summan av alla delsystem).&lt;/p&gt;
&lt;h4 id=&quot;återkoppling&quot;&gt;Återkoppling&lt;/h4&gt;
&lt;h6 id=&quot;exempeluppgifter&quot;&gt;Exempeluppgifter&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Vad är sannolikheten att en kund aldrig betjänas av nod x?
&lt;ul&gt;
&lt;li&gt;geometrisk summa&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Hur många gånger kommer en kund att ha betjänats i nod x?
&lt;ul&gt;
&lt;li&gt;ankomstintensitet för x / ankomstintensitet för hela nätet&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;lexikon&quot;&gt;Lexikon&lt;/h2&gt;
&lt;h5 id=&quot;transformer&quot;&gt;Transformer&lt;/h5&gt;
&lt;p&gt;Z-transformen kan användas för att härleda E(X). I denna kurs har man barnsligt nog valt att definera z-transformen som&lt;br /&gt;
&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?F%28z%29%20%3D%20%5Csum_%7Bn%3D0%7D%5E%7B%5Cinfty%7D%20f_n%20z%5En&quot; alt=&quot;F(z) = \sum_{n=0}^{\infty} f_n z^n&quot; title=&quot;F(z) = \sum_{n=0}^{\infty} f_n z^n&quot; /&gt;&lt;br /&gt;
Alltså med positivt n i exponenten.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Genom att transformera tillståndssannolikheterna får vi&lt;br /&gt;
&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28z%29%20%3D%20%5Csum_%7B0%7D%5E%7B%5Cinfty%7D%20z%5Ek%20p_k&quot; alt=&quot;P(z) = \sum_{0}^{\infty} z^k p_k&quot; title=&quot;P(z) = \sum_{0}^{\infty} z^k p_k&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Genom att derivera med avseende på z och låta z -&amp;gt; 1 så finner man E(X)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;snittmetoden&quot;&gt;Snittmetoden&lt;/h5&gt;
&lt;p&gt;Dra vertikala streck mellan tillstånden. De bågar påväg på ena hållet som strecket korsar måste vara lika med de korsande bågarna på andra hållet.&lt;/p&gt;
&lt;h5 id=&quot;bayes-sats&quot;&gt;Bayes’ sats&lt;/h5&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28B_i%20%7C%20A%29%20%3D%20%5Cfrac%7BP%28A%20%7C%20B_i%29P%28B_i%29%7D%7B%5Csum_%7Bj%7D%20P%28A%20%7C%20B_j%29P%28B_j%29%7D&quot; alt=&quot;P(B_i | A) = \frac{P(A | B_i)P(B_i)}{\sum_{j} P(A | B_j)P(B_j)}&quot; title=&quot;P(B_i | A) = \frac{P(A | B_i)P(B_i)}{\sum_{j} P(A | B_j)P(B_j)}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;erbjuden-trafik-avverkad-trafik-och-spärrad-trafik&quot;&gt;Erbjuden trafik, avverkad trafik och spärrad trafik&lt;/h5&gt;
&lt;p&gt;avverkad trafik = erbjuden trafik - spärrad trafik 1. Erbjuden trafik är ett annat ord för &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Crho%20%3D%20%5Cfrac%7B%5Clambda%7D%7B%5Cmu%7D&quot; alt=&quot;\rho = \frac{\lambda}{\mu}&quot; title=&quot;\rho = \frac{\lambda}{\mu}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;markovkedjan-och-markovprocessen&quot;&gt;Markovkedjan och Markovprocessen&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Stokastisk process där allt som spelar roll för nästa tillstånd är nuvarande tillstånd.&lt;/li&gt;
&lt;li&gt;Tidsdiskret -&amp;gt; Markovkedja&lt;/li&gt;
&lt;li&gt;Tidskontinuerlig -&amp;gt; Markovprocess&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;en&quot;&gt;E(N)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Kan härledas genom definition av medelvärdet eller z-transformera och låta &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?z%20-%3E%201&quot; alt=&quot;z -&amp;gt; 1&quot; title=&quot;z -&amp;gt; 1&quot; /&gt;.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7B0%7D%5E%7B%5Cinfty%7D%20k%20p_k&quot; alt=&quot;\sum_{0}^{\infty} k p_k&quot; title=&quot;\sum_{0}^{\infty} k p_k&quot; /&gt;&lt;/li&gt;
&lt;li&gt;För M/M/1: &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7Bk%3D0%7D%5E%7B%5Cinfty%7D%20kp_k%20%3D%20%5Cfrac%7B%5Crho%7D%7B1-%5Crho%7D&quot; alt=&quot;\sum_{k=0}^{\infty} kp_k = \frac{\rho}{1-\rho}&quot; title=&quot;\sum_{k=0}^{\infty} kp_k = \frac{\rho}{1-\rho}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7BN%7D%20%3D%20%5Cbar%7BN_q%7D%20%2B%20%5Cbar%7BN_s%7D&quot; alt=&quot;\bar{N} = \bar{N_q} + \bar{N_s}&quot; title=&quot;\bar{N} = \bar{N_q} + \bar{N_s}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_s%29&quot; alt=&quot;E(N_s)&quot; title=&quot;E(N_s)&quot; /&gt; fås genom att summera alla tillstånd då betjäning pågår.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;pspärr---spärrsannolikhet&quot;&gt;P(spärr) - spärrsannolikhet&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Är noll om det finns oändligt med buffertplatser&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Clambda%20_Lp_L%7D%7B%5Csum_%7Bk%3D0%7D%5E%7BL%7D%20%5Clambda%20_kp_k%7D&quot; alt=&quot;\frac{\lambda _Lp_L}{\sum_{k=0}^{L} \lambda _kp_k}&quot; title=&quot;\frac{\lambda _Lp_L}{\sum_{k=0}^{L} \lambda _kp_k}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Om &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda%20_i%20%3D%20%5Clambda&quot; alt=&quot;\lambda _i = \lambda&quot; title=&quot;\lambda _i = \lambda&quot; /&gt; så är är &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28sp%C3%A4rr%29%20%3D%20p_L&quot; alt=&quot;P(spärr) = p_L&quot; title=&quot;P(spärr) = p_L&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Medelvärdet av antalet kunder som spärras = &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda%20_L%20p_L&quot; alt=&quot;\lambda _L p_L&quot; title=&quot;\lambda _L p_L&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;effektiva-lambda&quot;&gt;Effektiva lambda&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Är ekvivalent med &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; när buffert är obegränsad&lt;/li&gt;
&lt;li&gt;Medelantalet som får komma in i systemet (alltså alla som inte blir spärrade)&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7Bk%3D0%7D%5E%7BL-1%7D%20%5Clambda%20_kp_k&quot; alt=&quot;\sum_{k=0}^{L-1} \lambda _kp_k&quot; title=&quot;\sum_{k=0}^{L-1} \lambda _kp_k&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;et&quot;&gt;E(T)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Medeltiden i som spenderas i systemet.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?T%20%3D%20W%20%2B%20%5Cbar%7Bx%7D&quot; alt=&quot;T = W + \bar{x}&quot; title=&quot;T = W + \bar{x}&quot; /&gt; (väntetid + betjäningstid)&lt;/li&gt;
&lt;li&gt;Använd Littles sats&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;ew&quot;&gt;E(W)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Crho%7D%7B%5Cmu%20%281-%5Crho%29%7D&quot; alt=&quot;\frac{\rho}{\mu (1-\rho)}&quot; title=&quot;\frac{\rho}{\mu (1-\rho)}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;littles-sats&quot;&gt;Littles sats&lt;/h5&gt;
&lt;p&gt;Antalet genomsnittliga kunder N = produkten av det genomsnittliga antalet icke-blockerade ankomster per tidsenhet och genomsnittliga tiden en kund spenderar i systemet. * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28T%29%20%3D%20%5Cfrac%7BE%28N%29%7D%7B%5Clambda%20_%7Beff%7D%7D&quot; alt=&quot;E(T) = \frac{E(N)}{\lambda _{eff}}&quot; title=&quot;E(T) = \frac{E(N)}{\lambda _{eff}}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N%29%20%3D%20E%28T%29%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N) = E(T) \lambda _{eff}&quot; title=&quot;E(N) = E(T) \lambda _{eff}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_s%29%20%3D%20%5Cbar%7Bx%7D%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N_s) = \bar{x} \lambda _{eff}&quot; title=&quot;E(N_s) = \bar{x} \lambda _{eff}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_q%29%20%3D%20W%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N_q) = W \lambda _{eff}&quot; title=&quot;E(N_q) = W \lambda _{eff}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;ankomstintensitet&quot;&gt;Ankomstintensitet&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; betecknar hur många kunder som kommer per sekund&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Clambda%7D&quot; alt=&quot;\frac{1}{\lambda}&quot; title=&quot;\frac{1}{\lambda}&quot; /&gt; betecknar därför tiden mellan ankomster&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;medelbetjäningstid&quot;&gt;Medelbetjäningstid&lt;/h5&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28x%29%20%3D%20%5Cfrac%7BE%28N_s%29%7D%7B%5Clambda%20_%7Beff%7D%7D&quot; alt=&quot;E(x) = \frac{E(N_s)}{\lambda _{eff}}&quot; title=&quot;E(x) = \frac{E(N_s)}{\lambda _{eff}}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;poissonprocesser&quot;&gt;Poissonprocesser&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Om ankomsterna är exponentialfördelade och med samma medelvärde bildar ankomsterna en Poissonprocess.&lt;/li&gt;
&lt;li&gt;Minneslös precis som markovkedjan och markovprocessen&lt;/li&gt;
&lt;li&gt;sannolikheten för N ankomster är då poissonfördelad och ges av &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28N%20%3D%20k%29%20%3D%20%5Cfrac%7B%28%5Clambda%20t%29%5E%7Bk%7D%7D%7Bk%21%7De%5E%7B-%20%5Clambda%20t%7D&quot; alt=&quot;P(N = k) = \frac{(\lambda t)^{k}}{k!}e^{- \lambda t}&quot; title=&quot;P(N = k) = \frac{(\lambda t)^{k}}{k!}e^{- \lambda t}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;tillståndsdiagram&quot;&gt;Tillståndsdiagram&lt;/h5&gt;
&lt;p&gt;Används för att visualisera kösystemets olika tillstånd. Liknar finite state machines.&lt;/p&gt;
&lt;h3 id=&quot;lösningar&quot;&gt;Lösningar&lt;/h3&gt;
&lt;h4 id=&quot;hur-stor-andel-av-tiden-arbetar-en-betjänare&quot;&gt;Hur stor andel av tiden arbetar en betjänare?&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;def. av medelvärde baserat på states där betjänare arbetar&lt;/li&gt;
&lt;li&gt;E(Ns)/m&lt;/li&gt;
&lt;/ol&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">Köteori Köteorin används för att analysera system där kunder och betjänare interagerar. Hur många kunder kommer det i snitt att finnas i systemet? Hur lång tid kommer de ta att betjäna? Är systemet stabilt eller kommer antalet kunder att öka obehindrat? För att kategorisera kösystem används ofta en modell “A/B/x”. A är fördelningen mellan ankomster, B motsvarar betjäningstidernas fördelning och x antalet betjänare. Denna konvention saknar dock information om antalet buffertplatser i systemet. Så länge inget annat anges gäller hursomhelst att antalet sådana platser är oändligt. A och B antar ofta ett av tre värden: M - exponentialfördelad D - deterministisk (konstant) G - godtycklig fördelning (men känd) Olika kötyper Markovska köer Beskrivs av markovkedjor Alla tider mellan ankomster samt betjäningstider är exponentialfördelade. Standardmall för beräkning Rita markovkedjan Hitta tillståndsfördelningen med snittmtoden Beräkna intressanta performanceparametrar E(N) E(T) P(Spärr) M/M/1 M/M/m Skilnaden här är att vi får multiplar av µ eftersom betjäningstiden beror av antalet betjänare. När det finns en kund i kösystemet kommer betjäningsintensiteten att vara µ. På samma vis blir betjäningsintensiteten 2µ när det finns två kunder i systemet, o.s.v. upp till m. Detta förändrar vid uträkning av tillständsfördelningen. M/M/1/K - begränsade köplatser Denna typen av kösystem gör det möjligt att räkna på P(spärr). Dessutom är dessa lättare att räkna på eftersom det blir ett finit antal tillständ. begränsat antal kunder Här förändras λ istället. Det blir i dessa fall smidigt att räkna med λ som en kunds ankomstintensitet. Har man då fem kunder blir alltså intensiteten till första tillståndet 5λ. I detta tillstånd finns endast fyra kunder utanför systemet och därav följer att ankomstintensiteten till nästa tillstånd blir 4λ. begränsat antal kunder och begränsat antal köplatser I sådan system kombineras helt enkelt kunskaperna om system med begränsade köplatser och system med begränsat antal kunder. M/M/m * upptagetsystem (Erlangsystemet) I dessa system gäller följande: 1. m betjänter 2. inga köplatser 3. ankomsterna är poissonprocess 4. ankomstintensitet är alltid * Bra apporximation om man har många kunder i förhållande till betjänter. * P(spärr) kallas i Erlangsystem för + räknas ut m.h.a. rekursion eller tabeller * avverkad trafik = * * Icke-markovska köer M/G/1 E(X) går att beräkna eftersom man vet fördelningen E(T) är trixigare då den beror på hur många som redan är i systemet se formelsamling. Könät Ankomsterna till nod 2 är lika med output från nod 1 HOWTO Ställ upp ankomstintensiteterna som ekvationssystem Räkna ut Dela med lambda för att få medeltid. Att tänka på Om man vill veta hur lång tid det tar för ett paket genom ett nät som passerar en viss nod så summeras de gemensamma noderna samt sannolikheten för det ena alternativet multiplicerat med tiden för den och samma sak för det andra alternativet. Tiden i ett system beror bara på λ in i systemet och E(N) (summan av alla delsystem). Återkoppling Exempeluppgifter Vad är sannolikheten att en kund aldrig betjänas av nod x? geometrisk summa Hur många gånger kommer en kund att ha betjänats i nod x? ankomstintensitet för x / ankomstintensitet för hela nätet Lexikon Transformer Z-transformen kan användas för att härleda E(X). I denna kurs har man barnsligt nog valt att definera z-transformen som Alltså med positivt n i exponenten. Genom att transformera tillståndssannolikheterna får vi Genom att derivera med avseende på z och låta z -&amp;gt; 1 så finner man E(X) Snittmetoden Dra vertikala streck mellan tillstånden. De bågar påväg på ena hållet som strecket korsar måste vara lika med de korsande bågarna på andra hållet. Bayes’ sats Erbjuden trafik, avverkad trafik och spärrad trafik avverkad trafik = erbjuden trafik - spärrad trafik 1. Erbjuden trafik är ett annat ord för Markovkedjan och Markovprocessen Stokastisk process där allt som spelar roll för nästa tillstånd är nuvarande tillstånd. Tidsdiskret -&amp;gt; Markovkedja Tidskontinuerlig -&amp;gt; Markovprocess E(N) Kan härledas genom definition av medelvärdet eller z-transformera och låta . För M/M/1: fås genom att summera alla tillstånd då betjäning pågår. P(spärr) - spärrsannolikhet Är noll om det finns oändligt med buffertplatser Om så är är Medelvärdet av antalet kunder som spärras = Effektiva lambda Är ekvivalent med när buffert är obegränsad Medelantalet som får komma in i systemet (alltså alla som inte blir spärrade) E(T) Medeltiden i som spenderas i systemet. (väntetid + betjäningstid) Använd Littles sats E(W) Littles sats Antalet genomsnittliga kunder N = produkten av det genomsnittliga antalet icke-blockerade ankomster per tidsenhet och genomsnittliga tiden en kund spenderar i systemet. * * * * Ankomstintensitet betecknar hur många kunder som kommer per sekund betecknar därför tiden mellan ankomster Medelbetjäningstid Poissonprocesser Om ankomsterna är exponentialfördelade och med samma medelvärde bildar ankomsterna en Poissonprocess. Minneslös precis som markovkedjan och markovprocessen sannolikheten för N ankomster är då poissonfördelad och ges av Tillståndsdiagram Används för att visualisera kösystemets olika tillstånd. Liknar finite state machines. Lösningar Hur stor andel av tiden arbetar en betjänare? def. av medelvärde baserat på states där betjänare arbetar E(Ns)/m</summary></entry></feed>