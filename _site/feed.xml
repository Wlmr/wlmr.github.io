<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-08-09T15:21:40+02:00</updated><id>http://localhost:4000/</id><title type="html">wlmr</title><subtitle>This is where I will keep useful info and share my opinions.</subtitle><entry><title type="html">Sannolikhetsteori och statistikteori</title><link href="http://localhost:4000/2018/06/20/statistik.html" rel="alternate" type="text/html" title="Sannolikhetsteori och statistikteori" /><published>2018-06-20T00:00:00+02:00</published><updated>2018-06-20T00:00:00+02:00</updated><id>http://localhost:4000/2018/06/20/statistik</id><content type="html" xml:base="http://localhost:4000/2018/06/20/statistik.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;matematisk statistik&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;header&gt;
&lt;h1 class=&quot;title&quot;&gt;matematisk statistik&lt;/h1&gt;
&lt;/header&gt;
&lt;h3 id=&quot;del-1-sannolikhet-eller-hur-man-beskriver-slumpen&quot;&gt;DEL 1: Sannolikhet eller hur man beskriver slumpen&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;utfall&lt;/strong&gt; – resultatet av ett slumpmässigt försök&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;utfallsrummet&lt;/strong&gt; – mängden möjliga utfall&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;händelse&lt;/strong&gt; – samling utfall&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;relativ frekvens&lt;/strong&gt; – kvoten mellan antalet erhållet utfall och hela antalet utförda kast&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;disjunkta händelser&lt;/strong&gt; – kan inte inträffa samtidigt&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kolmogorovs axiomsystem&lt;/strong&gt;:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Händelsen P(A) måste ligga mellan 0 &amp;amp; 1&lt;/li&gt;
&lt;li&gt;P(utfallsrummet) = 1&lt;/li&gt;
&lt;li&gt;om A &amp;amp; B är parvis oförenliga gäller \( P(A) + P(B) = P(A \cup B) \)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;komplementsatsen&lt;/strong&gt; – \( P(A^*) = 1 - P(A) \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Additionssatsen&lt;/strong&gt; – \( P(A \cup B) = P(A) + P(B) - P(A \cap B) \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Booles olikhet&lt;/strong&gt; – \( P(A \cup B) \leq P(A) + P(B) \)&lt;/p&gt;
&lt;h5 id=&quot;kombinatorik&quot;&gt;Kombinatorik&lt;/h5&gt;
&lt;p&gt;Förutsättningar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n element&lt;/li&gt;
&lt;li&gt;k av dessa plockas&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Klassiska sannolikhetsdefinitionen&lt;/strong&gt; Vid likformigt sannolikhetmått är sannolikheten för en händelse lika med kvoten mellan antalet för händelsen gynsamma fall och antalet möjliga fall.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning med återläggning och hänsyn till ordning&lt;/strong&gt; \[n^k\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning med hänsyn till ordning&lt;/strong&gt; \[n*(n-1)(n-2) \cdots (n-k)\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning utan hänsyn till ordning&lt;/strong&gt; \[\binom{n}{k}\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning utan återläggning&lt;/strong&gt; Urna med kulor av två olika färger. Hur stor är chansen att erhålla k vita? Enl. &lt;em&gt;Klas. sann.&lt;/em&gt; ges svaret av \[ g/m \] \[ m = \binom{v+s}{n} \] \[ g = \binom{v}{k} \binom{s}{n-k} \] Alltså produkten av sätten att få k stycken vita och alla möjligheter att få resterande svarta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragning med återläggning&lt;/strong&gt; Samma som ovan men med återläggning. \[ m = (v+s)^n \] \[ g = \binom{n}{k} v^k s^{n-k}\]&lt;/p&gt;
&lt;p&gt;Alltså antalet olika kombinationer det finns av k stora samlingar bland n multiplicerat med sannolikheten för k vita multiplicerat med n-k svarta. Allt detta dividerat med m.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Betingade sannolikheten&lt;/strong&gt; – sannolikheten att något inträffar givet en annan händelse.&lt;/p&gt;
&lt;p&gt;\[P(B|A) = \frac{P(A \cap B)}{P(A)}\]&lt;/p&gt;
&lt;p&gt;Ger alltså ett samband mellan betingning och snitt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lagen om total sannolikhet&lt;/strong&gt; \[P(A) = \sum_{i=1}^{n} P(H_i)P(A|H_i)\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bayes sats&lt;/strong&gt; \[P(H_i|A) = \frac{P(H_i)P(A|H_i)}{\sum_{j=1}^{n} P(H_j)P(A|H_j)}\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Oberoende händelser&lt;/strong&gt; – P(B|A) = P(B)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sannolikheten att minst en inträffar&lt;/strong&gt; \[A_1 , A_2 , … , A_n \text{ är oberoende och } P(A_i)=p_i\] \[1-(1-p_1)(1-p_2)…(1-p_n) = 1-(1-p)^n\]&lt;/p&gt;
&lt;h3 id=&quot;endimensionella-stokastiska-variabler&quot;&gt;1. Endimensionella stokastiska variabler&lt;/h3&gt;
&lt;p&gt;Den stokastiska variabeln är bron mellan matematiken och slumpen men är inget mer än en reellvärd funktion definierad på ett utfallsrum. Betecknas i texten som versaler från slutet av alfabetet som X, Y, eller Z.&lt;/p&gt;
&lt;h4 id=&quot;diskret-stokastisk-variabel&quot;&gt;diskret stokastisk variabel&lt;/h4&gt;
&lt;p&gt;En s.v. är &lt;em&gt;diskret&lt;/em&gt; om den kan anta ett ändligt eller uppräkneligt oändligt antal olika värden. funktionen över värdemängden kallas sannolikhetsfunktionen.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Enpunktsfördelning&lt;/em&gt; – all massa i ett värde \[p_X(a) = 1\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Tvåpunktsfördelning&lt;/em&gt; – om X endast antar två värden a &amp;amp; b med sannolikheterna p respektive 1- p. ex: krona/klave då X tar värdena a = 1 och b = 0 sägs X vara Bernoulli-fördelad.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Likformig fördelning&lt;/em&gt; – X antar värden 1,2,..,m och alla dessa med samma sannolikhet. \[p_X(k)=1/m, k = 1,2,…,m.\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;För-första-gången-fördelning&lt;/em&gt; \[ p_X(k)=(1-p)^{k-1}p, k=1,2,…,\] När samma oberoende försök görs om och om tills ett visst resultat erhålls. Antalet försök t.o.m. resultatet är då en s.v. med ffg-fördelning. \[ X \in ffg(p) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Geometrisk fördelning&lt;/em&gt; – genom att skippa resultatrundan som räknas in i ffg-fördelningen tillhör X Ge(p) \[p_X(k) = (1 - p)^kp, k = 0,1,2,…,\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Binomialfördelning&lt;/em&gt; – slumpmässigt försök med en händelse A där P(A) = p upprepas n oberoende ggr. \[ p_X (k) = \binom{n}{k} p^k (1 - p)^{n - k} \] \[ X \in Bin(n,p) \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Hypergeometrisk fördelning&lt;/em&gt; – uppträdde vid dragning utan återläggning ur urna med vita och svarta kulor. \[ p_X(k) = \frac{\binom{v}{k} \binom{s}{n-k}}{\binom{v+s}{n}}\] \[ X \in Hyp(N,n,p)\]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Poisson-fördelning&lt;/em&gt; \[ p_X(k) = \frac{ \mu^k }{ k! } e^{- \mu}\] \[ X \in Po(\mu)\]&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;kontinuerlig-stokastisk-variabel&quot;&gt;kontinuerlig stokastisk variabel&lt;/h4&gt;
&lt;p&gt;Sannolikhetsfunktionen kallas nu täthetsfunktion och betecknas med f.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Likformig fördelning&lt;/em&gt; \[ f_X(x) = 1/(b-a) \quad a&amp;lt;x&amp;lt;b \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Exponentialfördelning&lt;/em&gt; \[ f_X(x) = \lambda e^{-\lambda x} \]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Normalfördelningen&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Weibull-fördelning&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Gammafördelning&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;fördelningsfunktion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;intensitet&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;flerdimensionella-stokastiska-variabler&quot;&gt;2. Flerdimensionella stokastiska variabler&lt;/h3&gt;
&lt;h4 id=&quot;note-to-self&quot;&gt;Note to self:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\[ p_{X,Y}(i,j) = p_X(i)p_Y(j) = P(j|i)P(i) \] OBS! Dont forget the last P(i)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;största-och-minsta-värdet&quot;&gt;Största och minsta värdet&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Z = max(X,Y) \[F_Z(z) = F_X(z)F_Y(z)\]&lt;/li&gt;
&lt;li&gt;Z = min(X,Y) \[F_Z(z) = 1-[1-F_X(z)][1-F_Y(z)]\]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gör först om till fördelningsfunktion om täthetsfunktion&lt;/p&gt;
&lt;h4 id=&quot;summan-av-s.v.&quot;&gt;Summan av s.v.&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\[f_Z(z) = \int_{\infty}^{\infty} f_X(x)f_Y(z-x)dx\]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;väntevärden&quot;&gt;3. Väntevärden&lt;/h3&gt;
&lt;h4 id=&quot;note-to-self-1&quot;&gt;Note to self:&lt;/h4&gt;
&lt;p&gt;konstanter inuti väntevärdesfunktioner är korkat.&lt;/p&gt;
&lt;h4 id=&quot;väntevärdet-ex-eller-μ&quot;&gt;Väntevärdet E(X) eller μ&lt;/h4&gt;
&lt;p&gt;Är ett typ av lägesmått, precis som medianen. E(X) är väntevärdet för X. E(X) berättar om vad det väntade resultatet blir.&lt;/p&gt;
&lt;p&gt;DEF: \[ E(X) = \sum_kkp_X(k) \] \[ E(X) = \int\limits_{-\infty}^{\infty} x f_X(x)dx \]&lt;/p&gt;
&lt;p&gt;Y = g(X) \[ E(Y) = \sum_kg(k)p_X(k)\]&lt;/p&gt;
&lt;p&gt;\[ E(X+Y) = E(X)+E(Y) \]&lt;/p&gt;
&lt;p&gt;X &amp;amp; Y oberoende \[ E(XY) = E(X)E(Y)\]&lt;/p&gt;
&lt;p&gt;Samling X med samma väntevärde µ \[ E(\sum_{i=1}^nX_i)=n\mu \]&lt;/p&gt;
&lt;h5 id=&quot;betingade-väntevärden&quot;&gt;Betingade väntevärden&lt;/h5&gt;
&lt;p&gt;\[ E(X|Y=k) = \sum_{j=0}^\infty jp_{X|Y=k}(j)\]&lt;/p&gt;
&lt;p&gt;\[ E(X|Y=y) = \int_{-\infty}^\infty xf_{X|Y=y}(x)dx\]&lt;/p&gt;
&lt;h4 id=&quot;variansen-vx-eller-σ&quot;&gt;Variansen V(X) eller σ²&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Variansen är en typ av spridningsmått.&lt;/li&gt;
&lt;li&gt;DEF: \[ V(X) = E[(X-\mu)^2] \] – alltså ett väntevärde LOL&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;math display&quot;&gt;\[ V(X) = E(X^2)-[E(X)]^2 \]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;\[ V(aX+b) = a^2V(X) \]&lt;/li&gt;
&lt;li&gt;V(X + Y) = V(X) + V(Y) + 2C(X,Y)&lt;/li&gt;
&lt;li&gt;Om oberoende: V(X + Y) = V(X) + V(Y)&lt;/li&gt;
&lt;li&gt;Om oberoende och med samma σ: \[ V(\sum_{i=1}^nX_i) = n\sigma^2 \]&lt;/li&gt;
&lt;li&gt;Om oberoende och med samma σ samt µ: \[ V(\bar{X})=\sigma^2/n \]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;standardavvikelse-dx-eller-σ&quot;&gt;Standardavvikelse D(X) eller σ&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Schyst mått då man får samma dimension som väntevärdet&lt;/li&gt;
&lt;li&gt;\[ D(X) = \sqrt{V(X)} \]&lt;/li&gt;
&lt;li&gt;\[ D(aX + b) = |a|D(X) \]&lt;/li&gt;
&lt;li&gt;Om oberoende: \[ D(X + Y) = \sqrt{D^2(X) + D^2(Y)} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;variationskoefficienten&quot;&gt;Variationskoefficienten&lt;/h4&gt;
&lt;p&gt;uttrycks i procent \[ R(X) = D(X)/E(X) \]&lt;/p&gt;
&lt;h4 id=&quot;fel&quot;&gt;fel&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;systematiskt fel/bias&lt;/em&gt; är differansen mellan mätvärdets väntevärde och det korrekta värdet. (ett tal)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;slumpmässigt fel&lt;/em&gt; menas differensen mellan mätvärdet och dess väntevärde. (s.v. med E(X) = 0)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;beroendemått&quot;&gt;Beroendemått&lt;/h4&gt;
&lt;h5 id=&quot;kovarians&quot;&gt;Kovarians&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Kovariansen C(X,Y) mellan X &amp;amp; Y bör bli positiv om det finns ett beroende sådant att det finns en tendens hos variablerna att samtidigt avvika åt samma håll från sina väntevärden.&lt;/li&gt;
&lt;li&gt;\( C(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] \)&lt;/li&gt;
&lt;li&gt;\( C(X,Y) = E(XY)-E(X)E(Y) \)&lt;/li&gt;
&lt;li&gt;Om C(X,Y) = 0 är X och Y okorrelerade.&lt;/li&gt;
&lt;li&gt;\( X \text{ &amp;amp; } Y \text{ oberoende} \to \text{okorrelerade} \)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;korrelationskoefficienten&quot;&gt;Korrelationskoefficienten&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;DEF: \[ \rho(X,Y) = \frac{C(X,Y)}{D(X)D(Y)} \]&lt;/li&gt;
&lt;li&gt;Kovarians fast dimensionslös&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;stora-talens-lag&quot;&gt;Stora talens lag&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ju fler oberoende s.v. med samma µ desto närmre kommer medelvärdet att gå mot µ.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;betingade-väntevärden-och-varianser&quot;&gt;Betingade väntevärden och varianser&lt;/h4&gt;
&lt;h4 id=&quot;gauss-approximationsformler&quot;&gt;Gauss approximationsformler&lt;/h4&gt;
&lt;p&gt;Har du någonsin känt dig inkapabel? Då är taylorutveckling något för dig! Allt för ofta vill man ha en schyst funktion mitt i väntevärdet men hur räknar man ut E(Y) då!? Du behöver inte vara helt körd i skallen, det kan vara så att du råkat ut för någon av de många fallgropar som kantar väntevägen!&lt;/p&gt;
&lt;h5 id=&quot;en-variabel&quot;&gt;En variabel&lt;/h5&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;taylorutveckla: \[ g(X) \approx g(\mu) + (X - \mu)g’(\mu) \]&lt;/li&gt;
&lt;li&gt;g(X) har nu approximativa väntevärdet g(µ) samt [g’(E(X))]²V(X) som varians. Med en rak linje blir det enkelt att räkna med µ och σ².&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&quot;flera-variabler&quot;&gt;Flera variabler&lt;/h5&gt;
&lt;h6 id=&quot;abandon-all-hope-ye-who-enter-here&quot;&gt;Abandon all hope, ye who enter here&lt;/h6&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;taylorutveckla: \[ g(X,Y) \approx g(\mu_X,\mu_Y)+(X-\mu_X)g’_X(\mu_X,\mu_Y)+(Y-\mu_Y)g’_Y(\mu_X,\mu_Y) \]&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;normalfördelningen&quot;&gt;4. Normalfördelningen&lt;/h3&gt;
&lt;h5 id=&quot;notes-to-self&quot;&gt;Notes to self:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ca en tredjedel av massan hamnar utanför en standardavvikelse.&lt;/li&gt;
&lt;li&gt;normalfördelningar bevaras alltid under linjära transformationer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ f_X(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \]&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;standardiserad-fördelning&quot;&gt;Standardiserad fördelning&lt;/h4&gt;
&lt;p&gt;Täthetsfunktion: φ Fördelningsfunktion: Φ&lt;/p&gt;
&lt;p&gt;\[ \Phi(-x) = 1 - \Phi(x) \]&lt;/p&gt;
&lt;h4 id=&quot;allmän-fördelning&quot;&gt;Allmän fördelning&lt;/h4&gt;
&lt;p&gt;\[ X \in N(\mu,\sigma) \quad iff \quad Y = (X-\mu)/\sigma \in N(0,1) \] \[ f_X(x) = \frac{1}{\sigma}\varphi(\frac{x-\mu}{\sigma}) \] \[ F_X(x) = \Phi(\frac{x-\mu}{\sigma}) \]&lt;/p&gt;
&lt;h4 id=&quot;linjärkombinationer&quot;&gt;Linjärkombinationer&lt;/h4&gt;
&lt;p&gt;Om \[ X \in N(\mu,\sigma) \] så gäller att \[ Y=aX+b \in N(a\mu + b, |a|\sigma) \]&lt;/p&gt;
&lt;p&gt;Om \[ X_1,X_2,..,X_n \] är oberoende N(µ,σ) och \[ \bar{X} \] är medelvärdet så gäller att \[ \bar{X} \in N(\mu,\sigma/\sqrt{n}) \]&lt;/p&gt;
&lt;h3 id=&quot;de-tre-vännerna-och-binomialfördelning&quot;&gt;5. De tre vännerna och Binomialfördelning&lt;/h3&gt;
&lt;h4 id=&quot;binomialaren-med-återläggning&quot;&gt;binomialaren (med återläggning)&lt;/h4&gt;
&lt;p&gt;E(X) = np V(X) = npq&lt;/p&gt;
&lt;p&gt;Om oberoende \[ X \in Bin(n_1,p) \quad \&amp;amp; Y \in Bin(n_2,p) \] \[ X + Y \in Bin(n_1+n_2,p) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Obs! Glöm inte att bin är diskret, håll därför koll på gränserna (&amp;gt; != &amp;gt;=)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kan approximeras som&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;em&gt;poissonfördelning&lt;/em&gt; om p är litet&lt;/li&gt;
&lt;li&gt;&lt;em&gt;normalfördelning&lt;/em&gt; om n är stort N(np,sqrt(npq))&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;hypergeometriske-utan-återläggning&quot;&gt;Hypergeometriske (utan återläggning)&lt;/h4&gt;
&lt;p&gt;E(X) = np V(X) = ((N-n)/(N-1))np(1-p)&lt;/p&gt;
&lt;p&gt;Kan aproximeras som&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;em&gt;binomialapproximation&lt;/em&gt; om n/N är liten&lt;/li&gt;
&lt;li&gt;&lt;em&gt;normalapproximation&lt;/em&gt; om n är stort&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;poisson-fördelningen&quot;&gt;Poisson-fördelningen&lt;/h4&gt;
&lt;p&gt;E(X) = µ V(X) = µ&lt;/p&gt;
&lt;p&gt;\[ X_1 \in Po(\theta_1) \quad and \quad X_2 \in Po(\theta_2) \quad then \quad X_1+X_2 \in Po(\theta_1+\theta_2) \]&lt;/p&gt;
&lt;p&gt;Kan approximeras som&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;em&gt;normalfördelning&lt;/em&gt; om µ är stort&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;multinomial&quot;&gt;Multinomial&lt;/h4&gt;
&lt;h3 id=&quot;slumptal&quot;&gt;6. Slumptal&lt;/h3&gt;
&lt;h3 id=&quot;markovkedjor&quot;&gt;Markovkedjor&lt;/h3&gt;
&lt;p&gt;Stokastiska processer vars nästa värde endast beror på nuvarande värde.&lt;/p&gt;
&lt;p&gt;övergångsmatris används för att skriva upp “hoppsannolikheterna”.&lt;/p&gt;
&lt;p&gt;övergångssannolikheter av 2a ordningen härleds genom att matrismultiplicera övergångsmatrisen med sig själv. alltså sannolikheten att mellanlanda i ett tillstånd.&lt;/p&gt;
&lt;p&gt;För att simulera sannolikheterna att systemet börjar i de olika tillstånden används matrismultiplikation med en radvektor &lt;span class=&quot;math display&quot;&gt;\[ p^{(0)}=(p_1^{(0)},p_2^{(0)},...) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\[ \begin{pmatrix} 1 &amp;amp; 2 \end{pmatrix} * \begin{pmatrix} 1to1 &amp;amp; 1to2 \ 2to1 &amp;amp; 2to2 \end{pmatrix} \]&lt;/p&gt;
&lt;h5 id=&quot;terminologi&quot;&gt;terminologi&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;beständigt&lt;/strong&gt; tillstånd om P(i-&amp;gt;i)=1 &lt;strong&gt;obeständigt&lt;/strong&gt; tillstånd om P(i-&amp;gt;i) less than 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Om två tillstånd kommunicerar tvåsidigt är de båda antingen beständinga eller inte.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;irreducibel&lt;/strong&gt; om alla tillstånd kommunicerar tvåsidigt med varandra, indirekta anslutningar räknas också.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stationär fördelning&lt;/strong&gt; sannolikheterna att systemet befinner sig i de olika tillstånden.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;skapa sannolikhetsvektorn π = (π1,π2,..)&lt;/li&gt;
&lt;li&gt;lös ekv. π = πP (P är övergångsmatrisen)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;när &lt;span class=&quot;math display&quot;&gt;\[ p^{(n)}=(p_1^{(n)},p_2^{(n)},...) \to \pi \]&lt;/span&gt; när \[ n \to \infty \] 1. om man i en ändlig kedja kan finna ett r&amp;gt;0 så beskaffat att alla element i någon kolonn i matrisen P^r är positiva, existerar det en asymptotisk fördelning. 2. se stationär fördelning&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;periodiska tillstånd&lt;/strong&gt; om det alltid krävs ett visst antal hopp för att komma tillbaka till ett tillstånd är tillståndet periodiskt. t.ex. om processen bara kan nå tillbaka till Ei efter 3,6,9,… steg har Ei perioden 3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aperiodiska tillstånd&lt;/strong&gt; om det alltid går att komma tillbaka till ett tillstånd direkt&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;del-2-statistik-eller-vilka-slutsatser-man-kan-dra-av-ett-datamaterial&quot;&gt;DEL 2: Statistik eller vilka slutsatser man kan dra av ett datamaterial&lt;/h3&gt;
&lt;h4 id=&quot;terminologi-1&quot;&gt;terminologi&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;parameterrummet&lt;/strong&gt; - de värden den sökta parametern kan tänkas anta.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprov&lt;/strong&gt; – betecknas med lilla x = (x1,x2,…,xn) för n dimensionella s.v.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprovsvariansen&lt;/strong&gt; \[ s^2 = \frac{1}{n-1} \sum_{j=1}^n (x_j - \bar{x})^2 \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kovariansen mellan x- och y-värdena i en datamängd (x1,y1),(x2,y2),…,(xn,yn)&lt;/strong&gt; \[ c_{xy} = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) \] &lt;strong&gt;korrelationskoefficienten&lt;/strong&gt; \[ r = \frac{c_{xy}}{s_xs_y} \]&lt;/p&gt;
&lt;h3 id=&quot;punktskattning&quot;&gt;7. Punktskattning&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;punktskattning&lt;/strong&gt; – den observerade sannolikheten – ett utfall av stickprovsvariabeln \[ \theta_{obs}^*(x_1,x_2,…,x_n) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stickprovsvariabeln&lt;/strong&gt; – en s.v. som punktskattningen är ett utfall av \[ \theta^*(X_1,X_2,…,X_n) \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;väntevärdesriktig&lt;/strong&gt; – punktskattning vars tillhörande stickprovsvariabel har väntevärdet θ. dvs om \[ E(\theta^*) = \theta \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MSE&lt;/strong&gt; – mean square error – medelkvadratfelet för en punktskattning – mått på slumpmässigt fel \[ MSE = E(( \theta^* - \theta)^2) \]&lt;/p&gt;
&lt;h4 id=&quot;skattning-av-μ-σ&quot;&gt;skattning av μ &amp;amp; σ&lt;/h4&gt;
&lt;h5 id=&quot;µ&quot;&gt;µ&lt;/h5&gt;
&lt;p&gt;stickprovsmedelvärdet \[ \bar{x} \] är en väntevärdesriktig och konsistent skattning av µ&lt;/p&gt;
&lt;h5 id=&quot;σ2&quot;&gt;σ^2&lt;/h5&gt;
&lt;p&gt;stickprovsvariansen s^2 är en väntevärdesriktig skattning av σ^2&lt;/p&gt;
&lt;h4 id=&quot;maximum-likelihood-metoden-ml-metoden&quot;&gt;Maximum-likelihood-metoden – ML-metoden&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Skapa \[ L(\theta) = P(X_1 = x_1, X_2 = x_2,…,X_n = x_n;\theta) \] alt. \[ L(\theta) = f_{X_1,X_2,…,X_n}(x_1,x_2,…,x_n;\theta) \] (A.k.a. likelihood-funktionen)&lt;/li&gt;
&lt;li&gt;Finn funktionens maxpunkt genom ex. derivering över theta.&lt;/li&gt;
&lt;li&gt;Funktionens största värde är det mest sannolika scenariot.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;minsta-kvadrat-metoden-mk-metoden&quot;&gt;Minsta-kvadrat-metoden – MK-metoden&lt;/h4&gt;
&lt;p&gt;\[ Q(\theta) = \sum_{i=1}^n [x_i - \mu_i (\theta)]^2 \] Går ut på att anta att det finns små försöksfel vid varje mätdatum och bara genom att minimera dessa finner man bästa skattning av theta.&lt;/p&gt;
&lt;h4 id=&quot;tillämpning-på-normalfördelningen&quot;&gt;Tillämpning på normalfördelningen&lt;/h4&gt;
&lt;h4 id=&quot;ett-stickprov&quot;&gt;Ett stickprov&lt;/h4&gt;
&lt;h6 id=&quot;µ-okänt-σ-känt&quot;&gt;µ okänt σ känt&lt;/h6&gt;
&lt;p&gt;\[\mu* = \bar{x} \]&lt;/p&gt;
&lt;h6 id=&quot;μ-känt-σ-okänt&quot;&gt;μ känt σ okänt&lt;/h6&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ (\sigma^2)_{obs}^* = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&quot;konfidensintervall-för-väntevärdet&quot;&gt;Konfidensintervall för väntevärdet&lt;/h5&gt;
&lt;h6 id=&quot;känd-standardavvikelse&quot;&gt;Känd standardavvikelse&lt;/h6&gt;
&lt;p&gt;En lämplig skattning av µ är aritmetiska medelvärdet av X. \[ \bar{X} \in N(\mu,D) \] \[ D = \sigma/\sqrt{n} \] \[ I_\mu = (\bar{x}-\lambda_{\alpha/2}D,\bar{x}+\lambda_{\alpha/2}D) \]&lt;/p&gt;
&lt;p&gt;Allt detta följer av att:&lt;/p&gt;
&lt;p&gt;\[ \frac{\bar{X}-\mu}{D} \in N(0,1) \]&lt;/p&gt;
&lt;p&gt;Följaktligen gäller med sannolikheten 1-alfa att:&lt;/p&gt;
&lt;p&gt;\[ -\lambda_{\alpha/2} &amp;lt; \frac{ \bar{X}-\mu}{D} &amp;lt; \lambda_{\alpha/2} \] &amp;gt; standardized&lt;/p&gt;
&lt;p&gt;Om vi har ett intervall:&lt;/p&gt;
&lt;p&gt;\[ I_\mu = (16 \pm 2.58 * 0.155) \]&lt;/p&gt;
&lt;p&gt;där&lt;/p&gt;
&lt;p&gt;\[ D = 1.2/\sqrt{60} = 0.155 \]&lt;/p&gt;
&lt;p&gt;och man istället vill ha en mindre standardavvikelse, säg 0.5, så kan man sätta upp följande ekvation:&lt;/p&gt;
&lt;p&gt;\[ 2 * 2.58 * 1.2/\sqrt{n} = 0.5 \]&lt;/p&gt;
&lt;h6 id=&quot;okänd-standardavvikelse&quot;&gt;Okänd standardavvikelse&lt;/h6&gt;
&lt;p&gt;I detta fallet gäller en helt galen lösning eftersom man behöver skatta σ&lt;/p&gt;
&lt;p&gt;\[ I_\mu = (\bar{x}-t_{\alpha/2}(f)d,\bar{x}+t_{\alpha/2}(f)d) \] \[ d = s/\sqrt{n}, \quad f = n-1 \]&lt;/p&gt;
&lt;h5 id=&quot;konfidensintervall-för-standardavvikelsen&quot;&gt;Konfidensintervall för standardavvikelsen&lt;/h5&gt;
&lt;h6 id=&quot;μ-känt&quot;&gt;μ känt&lt;/h6&gt;
&lt;p&gt;Aint gonna happen gurl&lt;/p&gt;
&lt;h6 id=&quot;µ-okänt&quot;&gt;µ okänt&lt;/h6&gt;
&lt;p&gt;\[ I_\sigma = (k_1s,k_2s) \] \[ k_1 = \sqrt{(f/\chi_{\alpha/2}^2(f)} \] \[ k_2 = \sqrt{(f/\chi_{1-\alpha/2}^2(f)} \] \[ f = n-1 \]&lt;/p&gt;
&lt;h5 id=&quot;två-stickprov&quot;&gt;Två stickprov&lt;/h5&gt;
&lt;p&gt;Om σ1 och σ2 är kända:&lt;/p&gt;
&lt;p&gt;\[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-\lambda_{\alpha/2}D,\bar{x}-\bar{y}+\lambda_{\alpha/2}D) \] \[ D = \sqrt{ \sigma_{1}^{2} / n_1 + \sigma_{2}^{2} / n_2} \]&lt;/p&gt;
&lt;p&gt;Om σ1 = σ2 = σ:&lt;/p&gt;
&lt;p&gt;\[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-t_{\alpha/2}(f)d,\bar{x}-\bar{y}+t_{\alpha/2}(f)d) \] \[ d = \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2}} \]&lt;/p&gt;
&lt;h5 id=&quot;stickprov-i-par&quot;&gt;Stickprov i par&lt;/h5&gt;
&lt;p&gt;Skapa \[ z = y - x \]&lt;/p&gt;
&lt;h3 id=&quot;intevallskattning&quot;&gt;8. Intevallskattning&lt;/h3&gt;
&lt;p&gt;När man vill veta hur stor sannolikhet det är att en okänd parameter ligger inom ett visst interval.&lt;/p&gt;
&lt;h4 id=&quot;tillämpning-på-normalfördelningen-1&quot;&gt;Tillämpning på normalfördelningen&lt;/h4&gt;
&lt;h5 id=&quot;känd-standardavvikelse-1&quot;&gt;Känd standardavvikelse&lt;/h5&gt;
&lt;h3 id=&quot;hypotesprövning&quot;&gt;9. Hypotesprövning&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;nollhypotes&lt;/strong&gt; – hypotesen att det inte föreligger något fenomen som kräver en förklaring. Betecknas: \( H_0 \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mothypotes&lt;/strong&gt; – hypotes som kan vara sann om inte nollhypotesen är det. Betecknas: \( H_i \)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;signifikansnivå/felrisk&lt;/strong&gt; – sannolikheten att nollhypotesen förkastas trots att den är sann. (Ju lägre desto bättre).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;signifikant* – 0.05&lt;/li&gt;
&lt;li&gt;signifikant** – 0.01&lt;/li&gt;
&lt;li&gt;signifikant*** – 0.001&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;testvariabel/teststorhet&lt;/strong&gt; – observation av stickprovsvariabel&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;signifikanstest&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;styrkefunktionen&lt;/strong&gt; \[ h(\theta) = P(H_0 \text{ förkastas}) \] om θ är det rätta värdet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bör vara stort för alla θ som tillhör mothypotesen&lt;/li&gt;
&lt;li&gt;bör vara litet för alla θ som tillhör nollhypotesen&lt;/li&gt;
&lt;li&gt;h(θ) kallas testets styrka för θ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;konfidensmetoden&lt;/strong&gt; – genom att beräkna konfidensintervall för det faktiska värdet och sedan förkasta nollhypotesen om nollhypotesens hypotetiska värde hamnar utanför&lt;/p&gt;
&lt;h4 id=&quot;how-to-styrkefunktion&quot;&gt;How to styrkefunktion&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;create \( u = \frac{x - \mu}{\sigma} \)&lt;/li&gt;
&lt;li&gt;make sure \( u &amp;gt; \lambda_\alpha \) as this means that it is less likely it happens than α&lt;/li&gt;
&lt;li&gt;solve for x&lt;/li&gt;
&lt;li&gt;create \( h(\theta) = P(x &amp;gt; \lambda_\alpha \sigma + \mu) \)&lt;/li&gt;
&lt;li&gt;normalize h(θ) by adding -μ and dividing it all by σ&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;regressionsanalys&quot;&gt;10. Regressionsanalys&lt;/h3&gt;
&lt;p&gt;När man vill se samband mellan två eller flera storheter.&lt;/p&gt;
&lt;h4 id=&quot;terminologi-2&quot;&gt;Terminologi&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;teoretiska regressionslinjen&lt;/strong&gt; \[ y = \alpha + \beta x \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;parameterskattningar&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\[ \sum x_i , \quad \sum x_i^2 , \quad S_{xx} = \sum_{i=1}^n (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 - n \bar{x}^2 \]&lt;/p&gt;
&lt;p&gt;\[ \sum y_i , \quad \sum y_i^2 , \quad S_{yy} = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 - n \bar{y}^2 \]&lt;/p&gt;
&lt;p&gt;\[ \sum x_i y_i , \quad S_{xy} = \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y}) = \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} \]&lt;/p&gt;
&lt;h4 id=&quot;punktskattningar&quot;&gt;Punktskattningar&lt;/h4&gt;
&lt;p&gt;Remember MK-metoden? Bestäm minimum för&lt;/p&gt;
&lt;p&gt;\[ Q( \alpha , \beta ) = \sum_{i}^n (y_i - \mu_i)^2 \] \[ \mu_i = \alpha + \beta x_i \]&lt;/p&gt;
&lt;p&gt;Genom att sätta partialderivatorna till noll fås&lt;/p&gt;
&lt;p&gt;\[ \beta^* = \frac{S_{xy}}{S_{xx}} \quad \alpha^* = \bar{y} - \beta^* \bar{x} \]&lt;/p&gt;
&lt;h5 id=&quot;skattning-av-σ&quot;&gt;Skattning av σ&lt;/h5&gt;
&lt;p&gt;\[ ( \sigma^2 )^* = s^2 = \frac{Q_0}{n-2}, \quad Q_0 = S_{yy} - S_{xy}^2 / S_{xx} \]&lt;/p&gt;
&lt;p&gt;Observera att&lt;/p&gt;
&lt;p&gt;\[ \mu_0^* = \alpha^* + \beta^* x_0 \in N( \alpha + \beta x_0 , \sigma \sqrt{ \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}}) \]&lt;/p&gt;
&lt;h4 id=&quot;intervallskattningar&quot;&gt;Intervallskattningar&lt;/h4&gt;
&lt;h3 id=&quot;fallgropar&quot;&gt;11. Fallgropar&lt;/h3&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">matematisk statistik matematisk statistik DEL 1: Sannolikhet eller hur man beskriver slumpen utfall – resultatet av ett slumpmässigt försök utfallsrummet – mängden möjliga utfall händelse – samling utfall relativ frekvens – kvoten mellan antalet erhållet utfall och hela antalet utförda kast disjunkta händelser – kan inte inträffa samtidigt Kolmogorovs axiomsystem: Händelsen P(A) måste ligga mellan 0 &amp;amp; 1 P(utfallsrummet) = 1 om A &amp;amp; B är parvis oförenliga gäller \( P(A) + P(B) = P(A \cup B) \) komplementsatsen – \( P(A^*) = 1 - P(A) \) Additionssatsen – \( P(A \cup B) = P(A) + P(B) - P(A \cap B) \) Booles olikhet – \( P(A \cup B) \leq P(A) + P(B) \) Kombinatorik Förutsättningar: n element k av dessa plockas Klassiska sannolikhetsdefinitionen Vid likformigt sannolikhetmått är sannolikheten för en händelse lika med kvoten mellan antalet för händelsen gynsamma fall och antalet möjliga fall. Dragning med återläggning och hänsyn till ordning \[n^k\] Dragning utan återläggning med hänsyn till ordning \[n*(n-1)(n-2) \cdots (n-k)\] Dragning utan återläggning utan hänsyn till ordning \[\binom{n}{k}\] Dragning utan återläggning Urna med kulor av två olika färger. Hur stor är chansen att erhålla k vita? Enl. Klas. sann. ges svaret av \[ g/m \] \[ m = \binom{v+s}{n} \] \[ g = \binom{v}{k} \binom{s}{n-k} \] Alltså produkten av sätten att få k stycken vita och alla möjligheter att få resterande svarta. Dragning med återläggning Samma som ovan men med återläggning. \[ m = (v+s)^n \] \[ g = \binom{n}{k} v^k s^{n-k}\] Alltså antalet olika kombinationer det finns av k stora samlingar bland n multiplicerat med sannolikheten för k vita multiplicerat med n-k svarta. Allt detta dividerat med m. Betingade sannolikheten – sannolikheten att något inträffar givet en annan händelse. \[P(B|A) = \frac{P(A \cap B)}{P(A)}\] Ger alltså ett samband mellan betingning och snitt. Lagen om total sannolikhet \[P(A) = \sum_{i=1}^{n} P(H_i)P(A|H_i)\] Bayes sats \[P(H_i|A) = \frac{P(H_i)P(A|H_i)}{\sum_{j=1}^{n} P(H_j)P(A|H_j)}\] Oberoende händelser – P(B|A) = P(B) sannolikheten att minst en inträffar \[A_1 , A_2 , … , A_n \text{ är oberoende och } P(A_i)=p_i\] \[1-(1-p_1)(1-p_2)…(1-p_n) = 1-(1-p)^n\] 1. Endimensionella stokastiska variabler Den stokastiska variabeln är bron mellan matematiken och slumpen men är inget mer än en reellvärd funktion definierad på ett utfallsrum. Betecknas i texten som versaler från slutet av alfabetet som X, Y, eller Z. diskret stokastisk variabel En s.v. är diskret om den kan anta ett ändligt eller uppräkneligt oändligt antal olika värden. funktionen över värdemängden kallas sannolikhetsfunktionen. Enpunktsfördelning – all massa i ett värde \[p_X(a) = 1\] Tvåpunktsfördelning – om X endast antar två värden a &amp;amp; b med sannolikheterna p respektive 1- p. ex: krona/klave då X tar värdena a = 1 och b = 0 sägs X vara Bernoulli-fördelad. Likformig fördelning – X antar värden 1,2,..,m och alla dessa med samma sannolikhet. \[p_X(k)=1/m, k = 1,2,…,m.\] För-första-gången-fördelning \[ p_X(k)=(1-p)^{k-1}p, k=1,2,…,\] När samma oberoende försök görs om och om tills ett visst resultat erhålls. Antalet försök t.o.m. resultatet är då en s.v. med ffg-fördelning. \[ X \in ffg(p) \] Geometrisk fördelning – genom att skippa resultatrundan som räknas in i ffg-fördelningen tillhör X Ge(p) \[p_X(k) = (1 - p)^kp, k = 0,1,2,…,\] Binomialfördelning – slumpmässigt försök med en händelse A där P(A) = p upprepas n oberoende ggr. \[ p_X (k) = \binom{n}{k} p^k (1 - p)^{n - k} \] \[ X \in Bin(n,p) \] Hypergeometrisk fördelning – uppträdde vid dragning utan återläggning ur urna med vita och svarta kulor. \[ p_X(k) = \frac{\binom{v}{k} \binom{s}{n-k}}{\binom{v+s}{n}}\] \[ X \in Hyp(N,n,p)\] Poisson-fördelning \[ p_X(k) = \frac{ \mu^k }{ k! } e^{- \mu}\] \[ X \in Po(\mu)\] kontinuerlig stokastisk variabel Sannolikhetsfunktionen kallas nu täthetsfunktion och betecknas med f. Likformig fördelning \[ f_X(x) = 1/(b-a) \quad a&amp;lt;x&amp;lt;b \] Exponentialfördelning \[ f_X(x) = \lambda e^{-\lambda x} \] Normalfördelningen Weibull-fördelning Gammafördelning fördelningsfunktion intensitet 2. Flerdimensionella stokastiska variabler Note to self: \[ p_{X,Y}(i,j) = p_X(i)p_Y(j) = P(j|i)P(i) \] OBS! Dont forget the last P(i) Största och minsta värdet Z = max(X,Y) \[F_Z(z) = F_X(z)F_Y(z)\] Z = min(X,Y) \[F_Z(z) = 1-[1-F_X(z)][1-F_Y(z)]\] Gör först om till fördelningsfunktion om täthetsfunktion Summan av s.v. \[f_Z(z) = \int_{\infty}^{\infty} f_X(x)f_Y(z-x)dx\] 3. Väntevärden Note to self: konstanter inuti väntevärdesfunktioner är korkat. Väntevärdet E(X) eller μ Är ett typ av lägesmått, precis som medianen. E(X) är väntevärdet för X. E(X) berättar om vad det väntade resultatet blir. DEF: \[ E(X) = \sum_kkp_X(k) \] \[ E(X) = \int\limits_{-\infty}^{\infty} x f_X(x)dx \] Y = g(X) \[ E(Y) = \sum_kg(k)p_X(k)\] \[ E(X+Y) = E(X)+E(Y) \] X &amp;amp; Y oberoende \[ E(XY) = E(X)E(Y)\] Samling X med samma väntevärde µ \[ E(\sum_{i=1}^nX_i)=n\mu \] Betingade väntevärden \[ E(X|Y=k) = \sum_{j=0}^\infty jp_{X|Y=k}(j)\] \[ E(X|Y=y) = \int_{-\infty}^\infty xf_{X|Y=y}(x)dx\] Variansen V(X) eller σ² Variansen är en typ av spridningsmått. DEF: \[ V(X) = E[(X-\mu)^2] \] – alltså ett väntevärde LOL \[ V(X) = E(X^2)-[E(X)]^2 \] \[ V(aX+b) = a^2V(X) \] V(X + Y) = V(X) + V(Y) + 2C(X,Y) Om oberoende: V(X + Y) = V(X) + V(Y) Om oberoende och med samma σ: \[ V(\sum_{i=1}^nX_i) = n\sigma^2 \] Om oberoende och med samma σ samt µ: \[ V(\bar{X})=\sigma^2/n \] Standardavvikelse D(X) eller σ Schyst mått då man får samma dimension som väntevärdet \[ D(X) = \sqrt{V(X)} \] \[ D(aX + b) = |a|D(X) \] Om oberoende: \[ D(X + Y) = \sqrt{D^2(X) + D^2(Y)} \] Variationskoefficienten uttrycks i procent \[ R(X) = D(X)/E(X) \] fel systematiskt fel/bias är differansen mellan mätvärdets väntevärde och det korrekta värdet. (ett tal) slumpmässigt fel menas differensen mellan mätvärdet och dess väntevärde. (s.v. med E(X) = 0) Beroendemått Kovarians Kovariansen C(X,Y) mellan X &amp;amp; Y bör bli positiv om det finns ett beroende sådant att det finns en tendens hos variablerna att samtidigt avvika åt samma håll från sina väntevärden. \( C(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] \) \( C(X,Y) = E(XY)-E(X)E(Y) \) Om C(X,Y) = 0 är X och Y okorrelerade. \( X \text{ &amp;amp; } Y \text{ oberoende} \to \text{okorrelerade} \) Korrelationskoefficienten DEF: \[ \rho(X,Y) = \frac{C(X,Y)}{D(X)D(Y)} \] Kovarians fast dimensionslös Stora talens lag Ju fler oberoende s.v. med samma µ desto närmre kommer medelvärdet att gå mot µ. Betingade väntevärden och varianser Gauss approximationsformler Har du någonsin känt dig inkapabel? Då är taylorutveckling något för dig! Allt för ofta vill man ha en schyst funktion mitt i väntevärdet men hur räknar man ut E(Y) då!? Du behöver inte vara helt körd i skallen, det kan vara så att du råkat ut för någon av de många fallgropar som kantar väntevägen! En variabel taylorutveckla: \[ g(X) \approx g(\mu) + (X - \mu)g’(\mu) \] g(X) har nu approximativa väntevärdet g(µ) samt [g’(E(X))]²V(X) som varians. Med en rak linje blir det enkelt att räkna med µ och σ². Flera variabler Abandon all hope, ye who enter here taylorutveckla: \[ g(X,Y) \approx g(\mu_X,\mu_Y)+(X-\mu_X)g’_X(\mu_X,\mu_Y)+(Y-\mu_Y)g’_Y(\mu_X,\mu_Y) \] 4. Normalfördelningen Notes to self: ca en tredjedel av massan hamnar utanför en standardavvikelse. normalfördelningar bevaras alltid under linjära transformationer \[ f_X(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \] Standardiserad fördelning Täthetsfunktion: φ Fördelningsfunktion: Φ \[ \Phi(-x) = 1 - \Phi(x) \] Allmän fördelning \[ X \in N(\mu,\sigma) \quad iff \quad Y = (X-\mu)/\sigma \in N(0,1) \] \[ f_X(x) = \frac{1}{\sigma}\varphi(\frac{x-\mu}{\sigma}) \] \[ F_X(x) = \Phi(\frac{x-\mu}{\sigma}) \] Linjärkombinationer Om \[ X \in N(\mu,\sigma) \] så gäller att \[ Y=aX+b \in N(a\mu + b, |a|\sigma) \] Om \[ X_1,X_2,..,X_n \] är oberoende N(µ,σ) och \[ \bar{X} \] är medelvärdet så gäller att \[ \bar{X} \in N(\mu,\sigma/\sqrt{n}) \] 5. De tre vännerna och Binomialfördelning binomialaren (med återläggning) E(X) = np V(X) = npq Om oberoende \[ X \in Bin(n_1,p) \quad \&amp;amp; Y \in Bin(n_2,p) \] \[ X + Y \in Bin(n_1+n_2,p) \] Obs! Glöm inte att bin är diskret, håll därför koll på gränserna (&amp;gt; != &amp;gt;=) Kan approximeras som poissonfördelning om p är litet normalfördelning om n är stort N(np,sqrt(npq)) Hypergeometriske (utan återläggning) E(X) = np V(X) = ((N-n)/(N-1))np(1-p) Kan aproximeras som binomialapproximation om n/N är liten normalapproximation om n är stort Poisson-fördelningen E(X) = µ V(X) = µ \[ X_1 \in Po(\theta_1) \quad and \quad X_2 \in Po(\theta_2) \quad then \quad X_1+X_2 \in Po(\theta_1+\theta_2) \] Kan approximeras som normalfördelning om µ är stort Multinomial 6. Slumptal Markovkedjor Stokastiska processer vars nästa värde endast beror på nuvarande värde. övergångsmatris används för att skriva upp “hoppsannolikheterna”. övergångssannolikheter av 2a ordningen härleds genom att matrismultiplicera övergångsmatrisen med sig själv. alltså sannolikheten att mellanlanda i ett tillstånd. För att simulera sannolikheterna att systemet börjar i de olika tillstånden används matrismultiplikation med en radvektor \[ p^{(0)}=(p_1^{(0)},p_2^{(0)},...) \] \[ \begin{pmatrix} 1 &amp;amp; 2 \end{pmatrix} * \begin{pmatrix} 1to1 &amp;amp; 1to2 \ 2to1 &amp;amp; 2to2 \end{pmatrix} \] terminologi beständigt tillstånd om P(i-&amp;gt;i)=1 obeständigt tillstånd om P(i-&amp;gt;i) less than 1 Om två tillstånd kommunicerar tvåsidigt är de båda antingen beständinga eller inte. irreducibel om alla tillstånd kommunicerar tvåsidigt med varandra, indirekta anslutningar räknas också. stationär fördelning sannolikheterna att systemet befinner sig i de olika tillstånden. skapa sannolikhetsvektorn π = (π1,π2,..) lös ekv. π = πP (P är övergångsmatrisen) när \[ p^{(n)}=(p_1^{(n)},p_2^{(n)},...) \to \pi \] när \[ n \to \infty \] 1. om man i en ändlig kedja kan finna ett r&amp;gt;0 så beskaffat att alla element i någon kolonn i matrisen P^r är positiva, existerar det en asymptotisk fördelning. 2. se stationär fördelning periodiska tillstånd om det alltid krävs ett visst antal hopp för att komma tillbaka till ett tillstånd är tillståndet periodiskt. t.ex. om processen bara kan nå tillbaka till Ei efter 3,6,9,… steg har Ei perioden 3. aperiodiska tillstånd om det alltid går att komma tillbaka till ett tillstånd direkt DEL 2: Statistik eller vilka slutsatser man kan dra av ett datamaterial terminologi parameterrummet - de värden den sökta parametern kan tänkas anta. stickprov – betecknas med lilla x = (x1,x2,…,xn) för n dimensionella s.v. stickprovsvariansen \[ s^2 = \frac{1}{n-1} \sum_{j=1}^n (x_j - \bar{x})^2 \] kovariansen mellan x- och y-värdena i en datamängd (x1,y1),(x2,y2),…,(xn,yn) \[ c_{xy} = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) \] korrelationskoefficienten \[ r = \frac{c_{xy}}{s_xs_y} \] 7. Punktskattning punktskattning – den observerade sannolikheten – ett utfall av stickprovsvariabeln \[ \theta_{obs}^*(x_1,x_2,…,x_n) \] stickprovsvariabeln – en s.v. som punktskattningen är ett utfall av \[ \theta^*(X_1,X_2,…,X_n) \] väntevärdesriktig – punktskattning vars tillhörande stickprovsvariabel har väntevärdet θ. dvs om \[ E(\theta^*) = \theta \] MSE – mean square error – medelkvadratfelet för en punktskattning – mått på slumpmässigt fel \[ MSE = E(( \theta^* - \theta)^2) \] skattning av μ &amp;amp; σ µ stickprovsmedelvärdet \[ \bar{x} \] är en väntevärdesriktig och konsistent skattning av µ σ^2 stickprovsvariansen s^2 är en väntevärdesriktig skattning av σ^2 Maximum-likelihood-metoden – ML-metoden Skapa \[ L(\theta) = P(X_1 = x_1, X_2 = x_2,…,X_n = x_n;\theta) \] alt. \[ L(\theta) = f_{X_1,X_2,…,X_n}(x_1,x_2,…,x_n;\theta) \] (A.k.a. likelihood-funktionen) Finn funktionens maxpunkt genom ex. derivering över theta. Funktionens största värde är det mest sannolika scenariot. Minsta-kvadrat-metoden – MK-metoden \[ Q(\theta) = \sum_{i=1}^n [x_i - \mu_i (\theta)]^2 \] Går ut på att anta att det finns små försöksfel vid varje mätdatum och bara genom att minimera dessa finner man bästa skattning av theta. Tillämpning på normalfördelningen Ett stickprov µ okänt σ känt \[\mu* = \bar{x} \] μ känt σ okänt \[ (\sigma^2)_{obs}^* = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2 \] Konfidensintervall för väntevärdet Känd standardavvikelse En lämplig skattning av µ är aritmetiska medelvärdet av X. \[ \bar{X} \in N(\mu,D) \] \[ D = \sigma/\sqrt{n} \] \[ I_\mu = (\bar{x}-\lambda_{\alpha/2}D,\bar{x}+\lambda_{\alpha/2}D) \] Allt detta följer av att: \[ \frac{\bar{X}-\mu}{D} \in N(0,1) \] Följaktligen gäller med sannolikheten 1-alfa att: \[ -\lambda_{\alpha/2} &amp;lt; \frac{ \bar{X}-\mu}{D} &amp;lt; \lambda_{\alpha/2} \] &amp;gt; standardized Om vi har ett intervall: \[ I_\mu = (16 \pm 2.58 * 0.155) \] där \[ D = 1.2/\sqrt{60} = 0.155 \] och man istället vill ha en mindre standardavvikelse, säg 0.5, så kan man sätta upp följande ekvation: \[ 2 * 2.58 * 1.2/\sqrt{n} = 0.5 \] Okänd standardavvikelse I detta fallet gäller en helt galen lösning eftersom man behöver skatta σ \[ I_\mu = (\bar{x}-t_{\alpha/2}(f)d,\bar{x}+t_{\alpha/2}(f)d) \] \[ d = s/\sqrt{n}, \quad f = n-1 \] Konfidensintervall för standardavvikelsen μ känt Aint gonna happen gurl µ okänt \[ I_\sigma = (k_1s,k_2s) \] \[ k_1 = \sqrt{(f/\chi_{\alpha/2}^2(f)} \] \[ k_2 = \sqrt{(f/\chi_{1-\alpha/2}^2(f)} \] \[ f = n-1 \] Två stickprov Om σ1 och σ2 är kända: \[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-\lambda_{\alpha/2}D,\bar{x}-\bar{y}+\lambda_{\alpha/2}D) \] \[ D = \sqrt{ \sigma_{1}^{2} / n_1 + \sigma_{2}^{2} / n_2} \] Om σ1 = σ2 = σ: \[ I_{\mu_1-\mu_2} = (\bar{x}-\bar{y}-t_{\alpha/2}(f)d,\bar{x}-\bar{y}+t_{\alpha/2}(f)d) \] \[ d = \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2}} \] Stickprov i par Skapa \[ z = y - x \] 8. Intevallskattning När man vill veta hur stor sannolikhet det är att en okänd parameter ligger inom ett visst interval. Tillämpning på normalfördelningen Känd standardavvikelse 9. Hypotesprövning nollhypotes – hypotesen att det inte föreligger något fenomen som kräver en förklaring. Betecknas: \( H_0 \) mothypotes – hypotes som kan vara sann om inte nollhypotesen är det. Betecknas: \( H_i \) signifikansnivå/felrisk – sannolikheten att nollhypotesen förkastas trots att den är sann. (Ju lägre desto bättre). signifikant* – 0.05 signifikant** – 0.01 signifikant*** – 0.001 testvariabel/teststorhet – observation av stickprovsvariabel signifikanstest styrkefunktionen \[ h(\theta) = P(H_0 \text{ förkastas}) \] om θ är det rätta värdet bör vara stort för alla θ som tillhör mothypotesen bör vara litet för alla θ som tillhör nollhypotesen h(θ) kallas testets styrka för θ konfidensmetoden – genom att beräkna konfidensintervall för det faktiska värdet och sedan förkasta nollhypotesen om nollhypotesens hypotetiska värde hamnar utanför How to styrkefunktion create \( u = \frac{x - \mu}{\sigma} \) make sure \( u &amp;gt; \lambda_\alpha \) as this means that it is less likely it happens than α solve for x create \( h(\theta) = P(x &amp;gt; \lambda_\alpha \sigma + \mu) \) normalize h(θ) by adding -μ and dividing it all by σ 10. Regressionsanalys När man vill se samband mellan två eller flera storheter. Terminologi teoretiska regressionslinjen \[ y = \alpha + \beta x \] parameterskattningar \[ \sum x_i , \quad \sum x_i^2 , \quad S_{xx} = \sum_{i=1}^n (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 - n \bar{x}^2 \] \[ \sum y_i , \quad \sum y_i^2 , \quad S_{yy} = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 - n \bar{y}^2 \] \[ \sum x_i y_i , \quad S_{xy} = \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y}) = \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} \] Punktskattningar Remember MK-metoden? Bestäm minimum för \[ Q( \alpha , \beta ) = \sum_{i}^n (y_i - \mu_i)^2 \] \[ \mu_i = \alpha + \beta x_i \] Genom att sätta partialderivatorna till noll fås \[ \beta^* = \frac{S_{xy}}{S_{xx}} \quad \alpha^* = \bar{y} - \beta^* \bar{x} \] Skattning av σ \[ ( \sigma^2 )^* = s^2 = \frac{Q_0}{n-2}, \quad Q_0 = S_{yy} - S_{xy}^2 / S_{xx} \] Observera att \[ \mu_0^* = \alpha^* + \beta^* x_0 \in N( \alpha + \beta x_0 , \sigma \sqrt{ \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}}}) \] Intervallskattningar 11. Fallgropar</summary></entry><entry><title type="html">Regular expressions - a concise guide</title><link href="http://localhost:4000/2018/06/07/RegExp.html" rel="alternate" type="text/html" title="Regular expressions - a concise guide" /><published>2018-06-07T00:00:00+02:00</published><updated>2018-06-07T00:00:00+02:00</updated><id>http://localhost:4000/2018/06/07/RegExp</id><content type="html" xml:base="http://localhost:4000/2018/06/07/RegExp.html">&lt;h4 id=&quot;anchors&quot;&gt;Anchors&lt;/h4&gt;
&lt;p&gt;^ and $
Anchors are used to define locations within the line. “^A” will match all lines beginning with an “A” while “A$” will match all lines ending with an A. Note that “^” must be the first symbol of the regex, just as “$” has to be last.&lt;/p&gt;

&lt;h4 id=&quot;character-sets&quot;&gt;Character Sets&lt;/h4&gt;
&lt;p&gt;These define whole sets of characters to match. for instance “[abcdefg]” will look out for any of the chars “a-g”.&lt;/p&gt;

&lt;p&gt;As a matter of fact it is possible to use ranges just like this [a-z].&lt;/p&gt;

&lt;p&gt;Negation is done by adding a “^” inside the square brackets. [^a-z] would search for anything but a-z.&lt;/p&gt;

&lt;h4 id=&quot;modifiers&quot;&gt;Modifiers&lt;/h4&gt;
&lt;p&gt;When you want to search for multiples of your character set you use modifiers.&lt;/p&gt;

&lt;p&gt;The most common one is “&lt;em&gt;”. This matches with zero or more multiples of the given character set. [0-9]&lt;/em&gt; will find a match anywhere there is zero or more numbers.&lt;/p&gt;

&lt;h5 id=&quot;-and-&quot;&gt;”{” and “}”&lt;/h5&gt;
&lt;p&gt;Next up is “{” and “}”. The reason for their asymmetry can be found in a strive for backwars compability. “{“ &amp;amp; “}” were already in use and so we were left with “{” and “}”. Since this knowledge doesn’t improve our ability to catch regular expressions lets move on to what the symbols mean.&lt;/p&gt;

&lt;p&gt;When a character set needs to be multiplied a specific number of times or a number of times somewhere in a range of numbers.&lt;/p&gt;

&lt;h5 id=&quot;-and--1&quot;&gt;”&amp;lt;” and “&amp;gt;”&lt;/h5&gt;
&lt;p&gt;Say you want to find all matches of “ilsner”. The regex “ilsner” would however also match “pilsner”. searching for “ ilsner “ would fix it but then an instance of ilsner in the beginning or end of a line or sentence would not return a match. “&amp;lt;[iI]lsner&amp;gt;” is the final solution!&lt;/p&gt;

&lt;h5 id=&quot;-and--2&quot;&gt;”(” and “)”&lt;/h5&gt;
&lt;p&gt;Wanting to find occurrences of two identical character sets requires some way of remembering the previous found instance. The regex “([a-z] {4,9})\1” will find&lt;/p&gt;

&lt;h4 id=&quot;extended-regular-expressions&quot;&gt;Extended Regular Expressions&lt;/h4&gt;
&lt;p&gt;Seemingly most programs today suport extended regular expressions.&lt;/p&gt;

&lt;h5&gt;?&lt;/h5&gt;
&lt;p&gt;Matches 0 or 1 instances of the character set.&lt;/p&gt;

&lt;h5 id=&quot;-1&quot;&gt;+&lt;/h5&gt;
&lt;p&gt;Matches one or more copies of the character set.&lt;/p&gt;

&lt;h5 id=&quot;ab&quot;&gt;(a|b)&lt;/h5&gt;
&lt;p&gt;Searches for either a or b.&lt;/p&gt;

&lt;h4 id=&quot;examples&quot;&gt;Examples&lt;/h4&gt;
&lt;p&gt;[a-z]{4,9} will match 4-9 consecutive lower case letters.
[a-z]{4,} will match 4 or more consecutive lower case letters.
[a-z]{4} will match 4 consecutive lower case letters.&lt;/p&gt;</content><author><name></name></author><summary type="html">Anchors ^ and $ Anchors are used to define locations within the line. “^A” will match all lines beginning with an “A” while “A$” will match all lines ending with an A. Note that “^” must be the first symbol of the regex, just as “$” has to be last.</summary></entry><entry><title type="html">Köteori</title><link href="http://localhost:4000/2018/06/02/queuingsystem.html" rel="alternate" type="text/html" title="Köteori" /><published>2018-06-02T00:00:00+02:00</published><updated>2018-06-02T00:00:00+02:00</updated><id>http://localhost:4000/2018/06/02/queuingsystem</id><content type="html" xml:base="http://localhost:4000/2018/06/02/queuingsystem.html">&lt;!DOCTYPE html&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; lang=&quot;&quot; xml:lang=&quot;&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, user-scalable=yes&quot; /&gt;
  &lt;title&gt;Köteori&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  &lt;/style&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&quot;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;Köteorin används för att analysera system där kunder och betjänare interagerar. Hur många kunder kommer det i snitt att finnas i systemet? Hur lång tid kommer de ta att betjäna? Är systemet stabilt eller kommer antalet kunder att öka obehindrat?&lt;/p&gt;
&lt;p&gt;För att kategorisera kösystem används ofta en modell “A/B/x”. A är fördelningen mellan ankomster, B motsvarar betjäningstidernas fördelning och x antalet betjänare. Denna konvention saknar dock information om antalet buffertplatser i systemet. Så länge inget annat anges gäller hursomhelst att antalet sådana platser är oändligt.&lt;/p&gt;
&lt;p&gt;A och B antar ofta ett av tre värden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M - exponentialfördelad&lt;/li&gt;
&lt;li&gt;D - deterministisk (konstant)&lt;/li&gt;
&lt;li&gt;G - godtycklig fördelning (men känd)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;olika-kötyper&quot;&gt;Olika kötyper&lt;/h2&gt;
&lt;h3 id=&quot;markovska-köer&quot;&gt;Markovska köer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Beskrivs av &lt;em&gt;markovkedjor&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Alla tider mellan ankomster samt betjäningstider är exponentialfördelade.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?A%28t%29%20%3D%201%20-%20e%5E%7B-%20%5Clambda%20t%7D&quot; alt=&quot;A(t) = 1 - e^{- \lambda t}&quot; title=&quot;A(t) = 1 - e^{- \lambda t}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?B%28x%29%20%3D%201%20-%20e%5E%7B-%20%5Crho%20x%7D&quot; alt=&quot;B(x) = 1 - e^{- \rho x}&quot; title=&quot;B(x) = 1 - e^{- \rho x}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;standardmall-för-beräkning&quot;&gt;Standardmall för beräkning&lt;/h5&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Rita markovkedjan&lt;/li&gt;
&lt;li&gt;Hitta tillståndsfördelningen med snittmtoden&lt;/li&gt;
&lt;li&gt;Beräkna intressanta performanceparametrar&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;E(N)&lt;/li&gt;
&lt;li&gt;E(T)&lt;/li&gt;
&lt;li&gt;P(Spärr)&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda_%20%7Beff%7D&quot; alt=&quot;\lambda_ {eff}&quot; title=&quot;\lambda_ {eff}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;mm1&quot;&gt;M/M/1&lt;/h4&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7BN%7D%20%3D%20%5Cfrac%7B%5Crho%7D%7B1-%5Crho%7D%20%3D%20%5Cfrac%7B%5Clambda%7D%7B%5Cmu-%5Clambda%7D&quot; alt=&quot;\bar{N} = \frac{\rho}{1-\rho} = \frac{\lambda}{\mu-\lambda}&quot; title=&quot;\bar{N} = \frac{\rho}{1-\rho} = \frac{\lambda}{\mu-\lambda}&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;mmm&quot;&gt;M/M/m&lt;/h4&gt;
&lt;p&gt;Skilnaden här är att vi får multiplar av µ eftersom betjäningstiden beror av antalet betjänare. När det finns &lt;em&gt;en&lt;/em&gt; kund i kösystemet kommer betjäningsintensiteten att vara µ. På samma vis blir betjäningsintensiteten 2µ när det finns &lt;em&gt;två&lt;/em&gt; kunder i systemet, o.s.v. upp till m. Detta förändrar vid uträkning av tillständsfördelningen.&lt;/p&gt;
&lt;h4 id=&quot;mm1k---begränsade-köplatser&quot;&gt;M/M/1/K - begränsade köplatser&lt;/h4&gt;
&lt;p&gt;Denna typen av kösystem gör det möjligt att räkna på &lt;em&gt;P(spärr)&lt;/em&gt;. Dessutom är dessa lättare att räkna på eftersom det blir ett finit antal tillständ.&lt;/p&gt;
&lt;h4 id=&quot;begränsat-antal-kunder&quot;&gt;begränsat antal kunder&lt;/h4&gt;
&lt;p&gt;Här förändras λ istället. Det blir i dessa fall smidigt att räkna med λ som en kunds ankomstintensitet. Har man då fem kunder blir alltså intensiteten till första tillståndet 5λ. I detta tillstånd finns endast fyra kunder utanför systemet och därav följer att ankomstintensiteten till nästa tillstånd blir 4λ.&lt;/p&gt;
&lt;h4 id=&quot;begränsat-antal-kunder-och-begränsat-antal-köplatser&quot;&gt;begränsat antal kunder och begränsat antal köplatser&lt;/h4&gt;
&lt;p&gt;I sådan system kombineras helt enkelt kunskaperna om system med begränsade köplatser och system med begränsat antal kunder.&lt;/p&gt;
&lt;h4 id=&quot;mmm-upptagetsystem-erlangsystemet&quot;&gt;M/M/m * upptagetsystem (Erlangsystemet)&lt;/h4&gt;
&lt;p&gt;I dessa system gäller följande: 1. m betjänter 2. inga köplatser 3. ankomsterna är poissonprocess 4. ankomstintensitet är alltid &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; * Bra apporximation om man har många kunder i förhållande till betjänter. * P(spärr) kallas i Erlangsystem för &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E_m%28%5Crho%29&quot; alt=&quot;E_m(\rho)&quot; title=&quot;E_m(\rho)&quot; /&gt; + räknas ut m.h.a. rekursion eller tabeller * avverkad trafik = &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N%29%20%3D%20%5Clambda_%7Beff%7D%20%5Cbar%7Bx%7D%20%3D%20%5Crho%281-E_m%28%5Crho%29%29&quot; alt=&quot;E(N) = \lambda_{eff} \bar{x} = \rho(1-E_m(\rho))&quot; title=&quot;E(N) = \lambda_{eff} \bar{x} = \rho(1-E_m(\rho))&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D%20%3D%20%5Cfrac%7B1%7D%7B%5Crho%7D&quot; alt=&quot;\bar{x} = \frac{1}{\rho}&quot; title=&quot;\bar{x} = \frac{1}{\rho}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?p_k%20%3D%20%5Crho%2Fk%20%5Cfrac%7B%5Crho%5E%7Bk-1%7D%2F%28k-1%29%21%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%20%5Cfrac%7B%5Crho%5Ei%7D%7Bi%21%7D%7D%3D%5Cfrac%7B%5Crho%7D%7Bk%7D%20p_%7Bk-1%7D&quot; alt=&quot;p_k = \rho/k \frac{\rho^{k-1}/(k-1)!}{\sum_{i=0}^{m} \frac{\rho^i}{i!}}=\frac{\rho}{k} p_{k-1}&quot; title=&quot;p_k = \rho/k \frac{\rho^{k-1}/(k-1)!}{\sum_{i=0}^{m} \frac{\rho^i}{i!}}=\frac{\rho}{k} p_{k-1}&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;icke-markovska-köer&quot;&gt;Icke-markovska köer&lt;/h3&gt;
&lt;h4 id=&quot;mg1&quot;&gt;M/G/1&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;E(X) går att beräkna eftersom man vet fördelningen&lt;/li&gt;
&lt;li&gt;E(T) är trixigare då den beror på hur många som redan är i systemet&lt;/li&gt;
&lt;li&gt;se formelsamling.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;könät&quot;&gt;Könät&lt;/h3&gt;
&lt;p&gt;Ankomsterna till nod 2 är lika med output från nod 1&lt;/p&gt;
&lt;h6 id=&quot;howto&quot;&gt;HOWTO&lt;/h6&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Ställ upp ankomstintensiteterna som ekvationssystem&lt;/li&gt;
&lt;li&gt;Räkna ut &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_i%29%20%3D%20%5Cfrac%7B%5Crho%20_i%7D%7B1-%5Crho%20_i%7D&quot; alt=&quot;E(N_i) = \frac{\rho _i}{1-\rho _i}&quot; title=&quot;E(N_i) = \frac{\rho _i}{1-\rho _i}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28T_i%29%20%3D%20%5Cfrac%7BE%28N_i%29%7D%7B%5Clambda%20_i%7D&quot; alt=&quot;E(T_i) = \frac{E(N_i)}{\lambda _i}&quot; title=&quot;E(T_i) = \frac{E(N_i)}{\lambda _i}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_%7Bqi%7D%29%20%3D%20E%28N_i%29%20-%20E%28N_si%29%20%3D%20E%28N_i%29%20-%20%5Crho%20_i&quot; alt=&quot;E(N_{qi}) = E(N_i) - E(N_si) = E(N_i) - \rho _i&quot; title=&quot;E(N_{qi}) = E(N_i) - E(N_si) = E(N_i) - \rho _i&quot; /&gt; Dela med lambda för att få medeltid.&lt;/li&gt;
&lt;/ol&gt;
&lt;h6 id=&quot;att-tänka-på&quot;&gt;Att tänka på&lt;/h6&gt;
&lt;p&gt;Om man vill veta hur lång tid det tar för ett paket genom ett nät som passerar en viss nod så summeras de gemensamma noderna samt sannolikheten för det ena alternativet multiplicerat med tiden för den och samma sak för det andra alternativet. Tiden i ett system beror bara på λ in i systemet och E(N) (summan av alla delsystem).&lt;/p&gt;
&lt;h4 id=&quot;återkoppling&quot;&gt;Återkoppling&lt;/h4&gt;
&lt;h6 id=&quot;exempeluppgifter&quot;&gt;Exempeluppgifter&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Vad är sannolikheten att en kund aldrig betjänas av nod x?
&lt;ul&gt;
&lt;li&gt;geometrisk summa&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Hur många gånger kommer en kund att ha betjänats i nod x?
&lt;ul&gt;
&lt;li&gt;ankomstintensitet för x / ankomstintensitet för hela nätet&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;lexikon&quot;&gt;Lexikon&lt;/h2&gt;
&lt;h5 id=&quot;transformer&quot;&gt;Transformer&lt;/h5&gt;
&lt;p&gt;Z-transformen kan användas för att härleda E(X). I denna kurs har man barnsligt nog valt att definera z-transformen som&lt;br /&gt;
&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?F%28z%29%20%3D%20%5Csum_%7Bn%3D0%7D%5E%7B%5Cinfty%7D%20f_n%20z%5En&quot; alt=&quot;F(z) = \sum_{n=0}^{\infty} f_n z^n&quot; title=&quot;F(z) = \sum_{n=0}^{\infty} f_n z^n&quot; /&gt;&lt;br /&gt;
Alltså med positivt n i exponenten.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Genom att transformera tillståndssannolikheterna får vi&lt;br /&gt;
&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28z%29%20%3D%20%5Csum_%7B0%7D%5E%7B%5Cinfty%7D%20z%5Ek%20p_k&quot; alt=&quot;P(z) = \sum_{0}^{\infty} z^k p_k&quot; title=&quot;P(z) = \sum_{0}^{\infty} z^k p_k&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Genom att derivera med avseende på z och låta z -&amp;gt; 1 så finner man E(X)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;snittmetoden&quot;&gt;Snittmetoden&lt;/h5&gt;
&lt;p&gt;Dra vertikala streck mellan tillstånden. De bågar påväg på ena hållet som strecket korsar måste vara lika med de korsande bågarna på andra hållet.&lt;/p&gt;
&lt;h5 id=&quot;bayes-sats&quot;&gt;Bayes’ sats&lt;/h5&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28B_i%20%7C%20A%29%20%3D%20%5Cfrac%7BP%28A%20%7C%20B_i%29P%28B_i%29%7D%7B%5Csum_%7Bj%7D%20P%28A%20%7C%20B_j%29P%28B_j%29%7D&quot; alt=&quot;P(B_i | A) = \frac{P(A | B_i)P(B_i)}{\sum_{j} P(A | B_j)P(B_j)}&quot; title=&quot;P(B_i | A) = \frac{P(A | B_i)P(B_i)}{\sum_{j} P(A | B_j)P(B_j)}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;erbjuden-trafik-avverkad-trafik-och-spärrad-trafik&quot;&gt;Erbjuden trafik, avverkad trafik och spärrad trafik&lt;/h5&gt;
&lt;p&gt;avverkad trafik = erbjuden trafik - spärrad trafik 1. Erbjuden trafik är ett annat ord för &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Crho%20%3D%20%5Cfrac%7B%5Clambda%7D%7B%5Cmu%7D&quot; alt=&quot;\rho = \frac{\lambda}{\mu}&quot; title=&quot;\rho = \frac{\lambda}{\mu}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;markovkedjan-och-markovprocessen&quot;&gt;Markovkedjan och Markovprocessen&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Stokastisk process där allt som spelar roll för nästa tillstånd är nuvarande tillstånd.&lt;/li&gt;
&lt;li&gt;Tidsdiskret -&amp;gt; Markovkedja&lt;/li&gt;
&lt;li&gt;Tidskontinuerlig -&amp;gt; Markovprocess&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;en&quot;&gt;E(N)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Kan härledas genom definition av medelvärdet eller z-transformera och låta &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?z%20-%3E%201&quot; alt=&quot;z -&amp;gt; 1&quot; title=&quot;z -&amp;gt; 1&quot; /&gt;.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7B0%7D%5E%7B%5Cinfty%7D%20k%20p_k&quot; alt=&quot;\sum_{0}^{\infty} k p_k&quot; title=&quot;\sum_{0}^{\infty} k p_k&quot; /&gt;&lt;/li&gt;
&lt;li&gt;För M/M/1: &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7Bk%3D0%7D%5E%7B%5Cinfty%7D%20kp_k%20%3D%20%5Cfrac%7B%5Crho%7D%7B1-%5Crho%7D&quot; alt=&quot;\sum_{k=0}^{\infty} kp_k = \frac{\rho}{1-\rho}&quot; title=&quot;\sum_{k=0}^{\infty} kp_k = \frac{\rho}{1-\rho}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cbar%7BN%7D%20%3D%20%5Cbar%7BN_q%7D%20%2B%20%5Cbar%7BN_s%7D&quot; alt=&quot;\bar{N} = \bar{N_q} + \bar{N_s}&quot; title=&quot;\bar{N} = \bar{N_q} + \bar{N_s}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_s%29&quot; alt=&quot;E(N_s)&quot; title=&quot;E(N_s)&quot; /&gt; fås genom att summera alla tillstånd då betjäning pågår.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;pspärr---spärrsannolikhet&quot;&gt;P(spärr) - spärrsannolikhet&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Är noll om det finns oändligt med buffertplatser&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Clambda%20_Lp_L%7D%7B%5Csum_%7Bk%3D0%7D%5E%7BL%7D%20%5Clambda%20_kp_k%7D&quot; alt=&quot;\frac{\lambda _Lp_L}{\sum_{k=0}^{L} \lambda _kp_k}&quot; title=&quot;\frac{\lambda _Lp_L}{\sum_{k=0}^{L} \lambda _kp_k}&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Om &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda%20_i%20%3D%20%5Clambda&quot; alt=&quot;\lambda _i = \lambda&quot; title=&quot;\lambda _i = \lambda&quot; /&gt; så är är &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28sp%C3%A4rr%29%20%3D%20p_L&quot; alt=&quot;P(spärr) = p_L&quot; title=&quot;P(spärr) = p_L&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Medelvärdet av antalet kunder som spärras = &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda%20_L%20p_L&quot; alt=&quot;\lambda _L p_L&quot; title=&quot;\lambda _L p_L&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;effektiva-lambda&quot;&gt;Effektiva lambda&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Är ekvivalent med &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; när buffert är obegränsad&lt;/li&gt;
&lt;li&gt;Medelantalet som får komma in i systemet (alltså alla som inte blir spärrade)&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Csum_%7Bk%3D0%7D%5E%7BL-1%7D%20%5Clambda%20_kp_k&quot; alt=&quot;\sum_{k=0}^{L-1} \lambda _kp_k&quot; title=&quot;\sum_{k=0}^{L-1} \lambda _kp_k&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;et&quot;&gt;E(T)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Medeltiden i som spenderas i systemet.&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?T%20%3D%20W%20%2B%20%5Cbar%7Bx%7D&quot; alt=&quot;T = W + \bar{x}&quot; title=&quot;T = W + \bar{x}&quot; /&gt; (väntetid + betjäningstid)&lt;/li&gt;
&lt;li&gt;Använd Littles sats&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;ew&quot;&gt;E(W)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Crho%7D%7B%5Cmu%20%281-%5Crho%29%7D&quot; alt=&quot;\frac{\rho}{\mu (1-\rho)}&quot; title=&quot;\frac{\rho}{\mu (1-\rho)}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;littles-sats&quot;&gt;Littles sats&lt;/h5&gt;
&lt;p&gt;Antalet genomsnittliga kunder N = produkten av det genomsnittliga antalet icke-blockerade ankomster per tidsenhet och genomsnittliga tiden en kund spenderar i systemet. * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28T%29%20%3D%20%5Cfrac%7BE%28N%29%7D%7B%5Clambda%20_%7Beff%7D%7D&quot; alt=&quot;E(T) = \frac{E(N)}{\lambda _{eff}}&quot; title=&quot;E(T) = \frac{E(N)}{\lambda _{eff}}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N%29%20%3D%20E%28T%29%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N) = E(T) \lambda _{eff}&quot; title=&quot;E(N) = E(T) \lambda _{eff}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_s%29%20%3D%20%5Cbar%7Bx%7D%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N_s) = \bar{x} \lambda _{eff}&quot; title=&quot;E(N_s) = \bar{x} \lambda _{eff}&quot; /&gt; * &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28N_q%29%20%3D%20W%20%5Clambda%20_%7Beff%7D&quot; alt=&quot;E(N_q) = W \lambda _{eff}&quot; title=&quot;E(N_q) = W \lambda _{eff}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;ankomstintensitet&quot;&gt;Ankomstintensitet&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Clambda&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; /&gt; betecknar hur många kunder som kommer per sekund&lt;/li&gt;
&lt;li&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Clambda%7D&quot; alt=&quot;\frac{1}{\lambda}&quot; title=&quot;\frac{1}{\lambda}&quot; /&gt; betecknar därför tiden mellan ankomster&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;medelbetjäningstid&quot;&gt;Medelbetjäningstid&lt;/h5&gt;
&lt;p&gt;&lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?E%28x%29%20%3D%20%5Cfrac%7BE%28N_s%29%7D%7B%5Clambda%20_%7Beff%7D%7D&quot; alt=&quot;E(x) = \frac{E(N_s)}{\lambda _{eff}}&quot; title=&quot;E(x) = \frac{E(N_s)}{\lambda _{eff}}&quot; /&gt;&lt;/p&gt;
&lt;h5 id=&quot;poissonprocesser&quot;&gt;Poissonprocesser&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Om ankomsterna är exponentialfördelade och med samma medelvärde bildar ankomsterna en Poissonprocess.&lt;/li&gt;
&lt;li&gt;Minneslös precis som markovkedjan och markovprocessen&lt;/li&gt;
&lt;li&gt;sannolikheten för N ankomster är då poissonfördelad och ges av &lt;img style=&quot;vertical-align:middle&quot; src=&quot;https://latex.codecogs.com/png.latex?P%28N%20%3D%20k%29%20%3D%20%5Cfrac%7B%28%5Clambda%20t%29%5E%7Bk%7D%7D%7Bk%21%7De%5E%7B-%20%5Clambda%20t%7D&quot; alt=&quot;P(N = k) = \frac{(\lambda t)^{k}}{k!}e^{- \lambda t}&quot; title=&quot;P(N = k) = \frac{(\lambda t)^{k}}{k!}e^{- \lambda t}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;tillståndsdiagram&quot;&gt;Tillståndsdiagram&lt;/h5&gt;
&lt;p&gt;Används för att visualisera kösystemets olika tillstånd. Liknar finite state machines.&lt;/p&gt;
&lt;h3 id=&quot;lösningar&quot;&gt;Lösningar&lt;/h3&gt;
&lt;h4 id=&quot;hur-stor-andel-av-tiden-arbetar-en-betjänare&quot;&gt;Hur stor andel av tiden arbetar en betjänare?&lt;/h4&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;def. av medelvärde baserat på states där betjänare arbetar&lt;/li&gt;
&lt;li&gt;E(Ns)/m&lt;/li&gt;
&lt;/ol&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name></name></author><summary type="html">Köteori Köteorin används för att analysera system där kunder och betjänare interagerar. Hur många kunder kommer det i snitt att finnas i systemet? Hur lång tid kommer de ta att betjäna? Är systemet stabilt eller kommer antalet kunder att öka obehindrat? För att kategorisera kösystem används ofta en modell “A/B/x”. A är fördelningen mellan ankomster, B motsvarar betjäningstidernas fördelning och x antalet betjänare. Denna konvention saknar dock information om antalet buffertplatser i systemet. Så länge inget annat anges gäller hursomhelst att antalet sådana platser är oändligt. A och B antar ofta ett av tre värden: M - exponentialfördelad D - deterministisk (konstant) G - godtycklig fördelning (men känd) Olika kötyper Markovska köer Beskrivs av markovkedjor Alla tider mellan ankomster samt betjäningstider är exponentialfördelade. Standardmall för beräkning Rita markovkedjan Hitta tillståndsfördelningen med snittmtoden Beräkna intressanta performanceparametrar E(N) E(T) P(Spärr) M/M/1 M/M/m Skilnaden här är att vi får multiplar av µ eftersom betjäningstiden beror av antalet betjänare. När det finns en kund i kösystemet kommer betjäningsintensiteten att vara µ. På samma vis blir betjäningsintensiteten 2µ när det finns två kunder i systemet, o.s.v. upp till m. Detta förändrar vid uträkning av tillständsfördelningen. M/M/1/K - begränsade köplatser Denna typen av kösystem gör det möjligt att räkna på P(spärr). Dessutom är dessa lättare att räkna på eftersom det blir ett finit antal tillständ. begränsat antal kunder Här förändras λ istället. Det blir i dessa fall smidigt att räkna med λ som en kunds ankomstintensitet. Har man då fem kunder blir alltså intensiteten till första tillståndet 5λ. I detta tillstånd finns endast fyra kunder utanför systemet och därav följer att ankomstintensiteten till nästa tillstånd blir 4λ. begränsat antal kunder och begränsat antal köplatser I sådan system kombineras helt enkelt kunskaperna om system med begränsade köplatser och system med begränsat antal kunder. M/M/m * upptagetsystem (Erlangsystemet) I dessa system gäller följande: 1. m betjänter 2. inga köplatser 3. ankomsterna är poissonprocess 4. ankomstintensitet är alltid * Bra apporximation om man har många kunder i förhållande till betjänter. * P(spärr) kallas i Erlangsystem för + räknas ut m.h.a. rekursion eller tabeller * avverkad trafik = * * Icke-markovska köer M/G/1 E(X) går att beräkna eftersom man vet fördelningen E(T) är trixigare då den beror på hur många som redan är i systemet se formelsamling. Könät Ankomsterna till nod 2 är lika med output från nod 1 HOWTO Ställ upp ankomstintensiteterna som ekvationssystem Räkna ut Dela med lambda för att få medeltid. Att tänka på Om man vill veta hur lång tid det tar för ett paket genom ett nät som passerar en viss nod så summeras de gemensamma noderna samt sannolikheten för det ena alternativet multiplicerat med tiden för den och samma sak för det andra alternativet. Tiden i ett system beror bara på λ in i systemet och E(N) (summan av alla delsystem). Återkoppling Exempeluppgifter Vad är sannolikheten att en kund aldrig betjänas av nod x? geometrisk summa Hur många gånger kommer en kund att ha betjänats i nod x? ankomstintensitet för x / ankomstintensitet för hela nätet Lexikon Transformer Z-transformen kan användas för att härleda E(X). I denna kurs har man barnsligt nog valt att definera z-transformen som Alltså med positivt n i exponenten. Genom att transformera tillståndssannolikheterna får vi Genom att derivera med avseende på z och låta z -&amp;gt; 1 så finner man E(X) Snittmetoden Dra vertikala streck mellan tillstånden. De bågar påväg på ena hållet som strecket korsar måste vara lika med de korsande bågarna på andra hållet. Bayes’ sats Erbjuden trafik, avverkad trafik och spärrad trafik avverkad trafik = erbjuden trafik - spärrad trafik 1. Erbjuden trafik är ett annat ord för Markovkedjan och Markovprocessen Stokastisk process där allt som spelar roll för nästa tillstånd är nuvarande tillstånd. Tidsdiskret -&amp;gt; Markovkedja Tidskontinuerlig -&amp;gt; Markovprocess E(N) Kan härledas genom definition av medelvärdet eller z-transformera och låta . För M/M/1: fås genom att summera alla tillstånd då betjäning pågår. P(spärr) - spärrsannolikhet Är noll om det finns oändligt med buffertplatser Om så är är Medelvärdet av antalet kunder som spärras = Effektiva lambda Är ekvivalent med när buffert är obegränsad Medelantalet som får komma in i systemet (alltså alla som inte blir spärrade) E(T) Medeltiden i som spenderas i systemet. (väntetid + betjäningstid) Använd Littles sats E(W) Littles sats Antalet genomsnittliga kunder N = produkten av det genomsnittliga antalet icke-blockerade ankomster per tidsenhet och genomsnittliga tiden en kund spenderar i systemet. * * * * Ankomstintensitet betecknar hur många kunder som kommer per sekund betecknar därför tiden mellan ankomster Medelbetjäningstid Poissonprocesser Om ankomsterna är exponentialfördelade och med samma medelvärde bildar ankomsterna en Poissonprocess. Minneslös precis som markovkedjan och markovprocessen sannolikheten för N ankomster är då poissonfördelad och ges av Tillståndsdiagram Används för att visualisera kösystemets olika tillstånd. Liknar finite state machines. Lösningar Hur stor andel av tiden arbetar en betjänare? def. av medelvärde baserat på states där betjänare arbetar E(Ns)/m</summary></entry></feed>